---
title: "AI Engineering con Alex di backlog.md, mentre anche topolino si interessa di AI generativa #31"
categories:
  - Puntate
tags:

  - AI
layout: single
author_profile: true
---

{% include video id="NclkrRdh-cs" provider="youtube" %}

ðŸ‘‰ [Ascolta su Spotify](https://open.spotify.com/show/16dTKEEtKkIzhr1JJNMmSF?si=900902f2dca8442e)<br/>
ðŸ‘‰ [Guarda su YouTube](https://www.youtube.com/channel/UCYQgzIby7QHkXBonTWk-2Fg)<br/>
ðŸ‘‰ [Segui su LinkedIn](https://www.linkedin.com/company/risorseartificiali)<br/>


## INTRO E PRESENTAZIONE OSPITE: ALEX GAVRILESCU

**Stefano Maestri**

> Ciao a tutte e tutti e bentornati a Risorse Artificiali oggi con gradito ospite e dunque Alex, pronuncia tu il tuo cognome per favore perchÃ© io sicuramente lo pronuncio male.
> 
> 

**Alex Gavrilescu**

> Alex Gavrilescu, ok? 
> 
> 

**Stefano Maestri**

> Autore e creatore di Backlog MD. Mi avete sentito piÃ¹ volte parlarne qui in podcast, mi avete letto probabilmente sui social, ho fatto anche un paio di corsi su Vibe Coding e AI assisted coding in cui io uso Backlog MD perchÃ© mi piace parecchio. Da quando ho conosciuto Alex â€” in realtÃ  prima non lo conoscevo â€” sono andato ad una conferenza che era il Devoxx Belgium, ho sentito lui che ne parlava e mi Ã¨ piaciuto molto ed Ã¨ diventato uno dei miei tool.
> 
> 

**Paolo**

> Praticamente scusami Stefano stai dicendo che sei un suo stalker? 
> 
> 

**Stefano Maestri**

> Io sono un suo fan, non stalker. No, Alex non ti scrivo cosÃ¬ tanto. Ti ho mandato un paio di contribution e basta. Il tool Ã¨ molto bello e poi Alex Ã¨ molto bravo, nonostante dal cognome abbiate capito probabilmente che non Ã¨ italiano, Alex parla benissimo lâ€™italiano e quindi noi lâ€™abbiamo invitato a fare due chiacchiere in italiano sul suo tool in generale, su che cosa pensa delle AI in generale, direi. Abbiamo chiacchierato molto in aeroporto e ne sa anche piÃ¹ di noi, per cui Ã¨ un gradito ospite.
> 
> 

**Paolo**

> Risorse artificiali da oggi con ospiti internazionali.
> 
> 

**Stefano Maestri**

> Da oggi con Ã¨ vero, primo ospite internazionale perchÃ© tu sei basato a Vienna, giusto Alex? 
> 
> 

**Alex Gavrilescu**

> SÃ¬, corretto. SÃ¬, sÃ¬, sÃ¬. Infatti Ã¨ la prima volta che parlo del mio tool in italiano perchÃ© qua a Vienna parlo solo inglese e poi alle varie conferenze ovviamente parlo in inglese, quindi se oggi mi sentirete dire qualche parola italianinglizzata e beh, non preoccuparti.
> 
> 

**Stefano Maestri**

> Beh non preoccuparti, lo facciamo sempre anche noi.
> 
> 

**Paolo**

> Quindi le parolacce in che lingua escono? 
> 
> 

**Alex Gavrilescu**

> Vediamo, vediamo un po' a caso.
> 
> 

**Alessio Soldano**

> Problema tipico quando vai alle conferenze e dici "Va bene, faccio uno speech in italiano", appunto, uno speech non una presentazione, e inizi a parlare e dici "come si dice questo in italiano?" 
> 
> 

**Stefano Maestri**

> Ah, vabbÃ¨, lo dico in inglese. SÃ¬, ma Ã¨ classico che poi c'hai le slide in inglese in qualunque lingua. Poi tu presenti perchÃ© le fai una volta sola e poi le riutilizzi.
> 
> 

---

## DISNEY, OPENAI E L'ACCORDO SUI DIRITTI PER SORA

**Stefano Maestri**

> Ma allora, prima di venire a tutte le cose che dicevo prima di Alex, lasciatemi prima aprire con una notizia che mi ha fatto sorridere. Avete visto che Disney si Ã¨ comprata un bilion di OpenAI pagando con i diritti dei suoi personaggi? Stupendo. Praticamente hanno ceduto i diritti dei personaggi di Guerre Stellari, Disney proprio e Marvel credo, su Sora per il valore di un miliardo di dollari, ma non hanno voluto i soldi, hanno voluto azioni, che Ã¨ un affare per tutti e due, probabilmente.
> 
> 

**Paolo**

> Hanno praticamente pagato i ticket.
> 
> 

**Stefano Maestri**

> Hanno pagato i ticket, sÃ¬. Che poi succederÃ  quello che dicevi tu Paolo che l'utilizzo di Sora sarÃ  fare se stessi che lottano contro Luke Skywalker, queste cose qua.
> 
> 

**Alessio Soldano**

> E la cosa piÃ¹ figa tra l'altro, non Ã¨ neanche che si potrÃ  fare quella roba lÃ¬, ma che Disney puÃ² volendo decidere di riutilizzare quel filmato che tu hai fatto con te che lotti con Luke Skywalker.
> 
> 

**Alex Gavrilescu**

> SÃ¬, sÃ¬, sÃ¬, Ã¨ vero. Ma sai che non sapevo di questo partnership, perÃ² in realtÃ  l'altro giorno quando Ã¨ uscito il nuovo â€” c'Ã¨ GPT Image 1.5 â€” ho provato a fare la caricatura dei miei gatti e me li ha fatti i character Marvel. Di solito con i character Marvel dice "ops questo contenuto viola le regole del copyright", quindi lo annulla. Invece in questo caso l'ha fatto passare. Avevo il mio gatto Captain America e secondo me Ã¨ basato su questo accordo qua perchÃ© Ã¨ palese Captain America.
> 
> 

**Paolo**

> Non credo che possiamo andare avanti con la puntata senza che ce lo mostri. Sappilo il gatto.
> 
> 

**Alex Gavrilescu**

> Ah, sÃ¬, sÃ¬, dopo ve lo mando.
> 
> 

**Stefano Maestri**

> No, no, facciamolo pure vedere agli utenti se ce l'hai sottomano. CioÃ¨, se condividi lo schermo, queste sono cose che piacciono.
> 
> 

---

## STRATEGIE MEDIA: NETFLIX, WARNER BROS E LA FINE DELLA PIRATERIA

**Paolo**

> Sapete che queste storie mi fanno sempre partire scenari alternativi nella mente e adesso ho lo scenario ispirato da Netflix. Se siete dei genitori di bambini, sapete che la sfida principale dell'utilizzare Netflix Ã¨ che Netflix ogni tanto toglie i film dal catalogo e quindi se tuo figlio si aspetta di vedere tutti i giorni Alla ricerca di Nemo e a un certo punto non c'Ã¨ piÃ¹, Ã¨ la fine del mondo. Mi immagino un futuro di OpenAI Disney in cui nel mese di dicembre puoi avere i personaggi Star Wars, perÃ² vanno via a fine dicembre e quello dopo c'Ã¨ solo quelli di Frozen e quindi ti attacchi, puoi fare solo Elsa se vuoi.
> 
> 

**Stefano Maestri**

> Eh beh, ma quando la generazione spingerÃ  un po' di piÃ¹, io immagino che Netflix partirÃ  con qualche accordo per forza, Ã¨ lÃ¬ pronto per partire. Anche perchÃ© tra l'altro quello Ã¨ di settimana scorsa, non c'entra niente con l'AI, ma lo diciamo lo stesso: Netflix ha fatto una offerta pubblica di acquisto per Warner Bros, no? E quindi tanta roba, compresa CNN e tutto quello che Ã¨ il mondo Warner, che Ã¨ notevole perchÃ© Ã¨ la prima volta che si invertono le parti. Loro erano solo distributori di contenuti importanti e quello che veniva prodotto da Netflix era considerato roba di secondo livello. E loro han detto: "Sapete cosa c'Ã¨? Chi Ã¨ quel produttore piÃ¹ grosso dopo Disney? Ah, va bene, lo compriamo".
> 
> 

**Alessio Soldano**

> SÃ¬, tornando al discorso di Disney ed OpenAI, a parte le battute su generiamoci i nostri filmatini con Elsa piuttosto che Captain America eccetera, io ci ho visto una specie di ritorno al passato con la grande multinazionale che si rende conto che non puÃ² combattere il progresso, che in questo caso Ã¨ l'intelligenza artificiale e dice "VabbÃ¨, se non posso sconfiggerla allora mi ci alleo." E mi sembra un po' quando c'erano gli MP3 con i file audio su Napster e c'era la musica pirata, poi a un certo punto siamo arrivati allo streaming legale.
> 
> 

**Stefano Maestri**

> Esatto. No e hai ragione, hai ragione a quella roba lÃ¬.
> 
> 

**Alessio Soldano**

> E poi quello che diceva Alex: una volta mi usciva che non potevo generare un filmatino con un personaggio particolare, che ne so, un politico piuttosto che un qualche tipo di character coperto da copyright e invece stiamo trasformando quello che se vuoi era pirateria in una feature premium, per cui basta che tu usi Sora che tâ€™ha pagato i diritti alla fonte con Disney e allora paghi e quindi puoi farti il tuo personaggio. Magari un domani hai che per Disney devi usare OpenAI, per un'altra major devi usare Grok, e quindi abbiamo trasformato il mercato in questo modo.
> 
> 

**Stefano Maestri**

> A me la cosa che ha fatto piÃ¹ ridere di questa notizia Ã¨ un post che ho letto su X o su LinkedIn di uno che diceva "Non vedo l'ora di farmi dentro dopo questa notizia". Commentava la notizia dice "No, non vedo l'ora di fare me stesso dentro a Sora come Spider-Man." E io al momento ho detto "VabbÃ¨, ci sta". Poi ho pensato, vabbÃ¨, ma ti riconoscono da cosa? Dalla pancetta? PerchÃ© sul cappuccio Spider-Man Ã¨ tutto vestito. Uno Spider-Man vale l'altro. Come fanno a sapere che sei tu forse per la pancia? Ãˆ l'unica spiegazione. PerÃ² vabbÃ¨.
> 
> 

---

## REPORT DA NEW YORK: LE NUOVE FRONTIERE DELLO SVILUPPO AI

**Stefano Maestri**

> No ma torniamo seri e approfittiamo del fatto di avere qui Alex. Allora, prima di parlare del tuo tool, parlaci un po' delle ultime conferenze a cui sei stato. Ci dicevi prima di partire con la puntata che sei tornato da poco da New York, hai fatto due conferenze molto importanti sullo sviluppo AI proprio, raccontaci un po' le impressioni, cosa hai visto lÃ¬.
> 
> 

**Alex Gavrilescu**

> SÃ¬, allora le due conferenze erano in fila praticamente da martedÃ¬ a sabato. La prima era AI Native Devcon ed Ã¨ praticamente una community conference di persone che parlano di AI, hanno un blog, hanno dei podcast e per la prima volta hanno deciso di fare una conferenza. Il tema era spec driven development maggiormente e anche tipo le novitÃ  con le best practices di AI al giorno d'oggi. Quella Ã¨ stata per me molto interessante perchÃ© era piccola perÃ² molto compatta, molte persone che ne sapevano un sacco con cui ho avuto l'occasione di parlare. Ad esempio c'era l'inventore di AWS Kiro, quell'editor per Spec Driven Development. Ho parlato con lui, mi ha detto quali sono stati i motivi per cui ha voluto fare Kiro e adesso in quale direzione sta andando.
> 
> 

**Alex Gavrilescu**

> E poi c'era il famoso AI Engineer Code Summit, che Ã¨ una conferenza un po' esclusiva perchÃ© ti mandano loro l'invito, devi comunque pagare il ticket ma solo se ti invitano. E lÃ¬ praticamente c'Ã¨ una sola traccia, cioÃ¨ c'Ã¨ una sola stanza dove gli speaker vanno avanti ogni 20 minuti uno dopo l'altro, quindi non puoi anche scegliere il tema o niente. Tu sei lÃ¬ seduto per un paio d'ore di fila e senti tutte le novitÃ  dal mondo AI e lÃ¬ hanno scelto come speaker praticamente il meglio del meglio, c'era Google, OpenAI, Anthropic, di tutto. Praticamente questo formato Ã¨ fatto apposta per massimizzare la novitÃ , cioÃ¨ tutto quello che viene presentato lÃ¬ Ã¨ il top del top.
> 
> 

**Alex Gavrilescu**

> Praticamente l'anno scorso in questa conferenza Ã¨ stato presentato lo standard MCP e quest'anno sono stati presentati Sub agents â€” che Ã¨ un nuovo modo di lavorare con AI â€” e Replit, che Ã¨ questa azienda che ti permette di sviluppare senza saperne molto di codice con AI, e hanno presentato in anteprima la Replit V4 che dovrebbe essere una nuova rivoluzione su poter lavorare con AI e lasciarlo lavorare in autonomia per delle ore. In entrambe le conferenze ho parlato di Backlog e di che cosa vuol dire lavorare con Backlog e vi racconterÃ² un pochino i contenuti.
> 
> 

**Stefano Maestri**

> Ma Ã¨ quella conferenza lÃ¬ dove hanno fatto anche il talk quelli di Anthropic sulle skills? Quella che commentavamo con Paolo e Alessio. Poi magari ci torniamo perchÃ© a noi quella era piaciuta molto. L'abbiamo vista ovviamente online non eravamo lÃ¬, perÃ² era molto interessante.
> 
> 

---

## BACKLOG MD: GESTIONE TASK E SPEC DRIVEN DEVELOPMENT

**Stefano Maestri**

> No dai, raccontaci un po' di piÃ¹ di backlog, perchÃ© io l'ho raccontato tante volte questa cosa, che Ã¨ un po' la tua idea, no? Ãˆ lo spec driven mischiato un po' alla Agile e all'AI, ma raccontacelo tu che Ã¨ piÃ¹ interessante saperlo da te.
> 
> 

**Alex Gavrilescu**

> SÃ¬, allora parto un po' da zero perchÃ© magari c'Ã¨ qualcuno che non ha mai sentito parlare di backlog. Che cosa vuol dire backlog? Ãˆ un tool che tu installi sul tuo computer prima di tutto e fai accedere l'AI a questo tool in modo da amplificare il tuo modo di progettare task e funzionalitÃ  su un tuo software. CioÃ¨ cosa vuol dire? Tu vuoi implementare una funzionalitÃ  o un progetto da zero oppure una nuova funzionalitÃ  sul tuo progetto, hai l'idea in mente ma Ã¨ un qualcosa di complesso che faresti fatica a dire a Claude Code "implementami questa feature" giÃ¹ dalla tua testa. Devi avere un minimo di feedback che l'AI ha capito quello che vuoi fare.
> 
> 

**Alex Gavrilescu**

> Quindi backlog Ã¨ un tool che si inserisce un po' in mezzo a questa comunicazione tra te e l'agent dove tu praticamente spieghi la tua idea all'agent e l'agent si connette a backlog tramite standard MCP e comincia a creare task dalla tua idea e dividere la tua idea in tante piccole task che per me sono tipo Jira o Linear o questi tool di project management. Tu puoi verificare che l'AI ha capito cosa vuoi fare. Diciamo ad esempio una cosa assurda, voglio creare Facebook da zero. Ãˆ un progetto complesso, c'Ã¨ il database, l'autenticazione, login, condivisione con amici, Ã¨ comunque una complessitÃ  assurda. Ovviamente non riusciremmo a fare una cosa del genere, perÃ² se volessimo andare in quella direzione lÃ¬ tu spiegheresti questa cosa all'AI e lei comincia a creare tante task nel tuo progetto e poi le verifichi una a una e vedi se ha capito.
> 
> 

**Alex Gavrilescu**

> Backlog diciamo fa questo, dÃ  una certa struttura ai task cosÃ¬ l'agent va ad inserire i perchÃ© vogliamo fare questa feature, che cosa abbiamo in mente, quali sono i criteri di accettabilitÃ  (acceptance criteria). Questi ti permettono anche di verificare con Unit test o con altri metodi di testing se Ã¨ stato implementato in modo corretto. Diciamo che Backlog Ã¨ un tool che ti fa andare un po' via dal vibe coding, da fare le cose un po' a casaccio finchÃ© vengono piÃ¹ o meno bene, a un processo dove ho un'idea, la metto giÃ¹, verifico cosa ha capito l'agent e poi ho modo di perfezionare anche a mano questi requisiti. Quando decido che i requisiti sono pronti dico "AI Ok, adesso vai a implementare il task 10" e poi parto col mio sviluppo normale.
> 
> 

**Stefano Maestri**

> Ma praticamente Ã¨ uno spec Driven development questo o come differisce dallo spec driven development cosÃ¬ come lo definiscono in questo momento? 
> 
> 

**Alex Gavrilescu**

> Allora, lo spec driven Ã¨ utilizzato in tantissimi scenari e quindi Ã¨ un po' difficile dire che questo Ã¨ spec driven development perchÃ© ci sono tante definizioni. Ne sentivo parlare anche alle conferenze: "questo Ã¨ lo spec driven secondo AWS", "questo Ã¨ lo spec driven secondo Anthropic" eccetera. Secondo me Ã¨ meglio dire fare le cose non a casaccio, dove prima pensi a cosa vuoi fare, cerchi di capire i tuoi obiettivi e poi li dai in pasto all'AI. Backlog ti permette di fare questo spec driven development ma in maniera un po' piÃ¹ semplificata perchÃ© ci sono vari tool molto piÃ¹ complessi dove hai security specs, requisiti production, scalabilitÃ , che tipi di deployment vogliamo fare su Kubernetes eccetera. Tutte queste cose qua sono tutte spec driven development, perÃ² con Backlog non Ã¨ che ti do a gratis tutte queste informazioni, sei tu che devi accertarti che questi requisiti sono giusti.
> 
> 

**Alessio Soldano**

> I requisiti li scrivi tu o li scrive lâ€™AI su tuo prompting? 
> 
> 

**Alex Gavrilescu**

> Esatto. E backlog Ã¨ praticamente un contenitore dove tu puoi visualizzare tutti questi task con i vari requisiti. Hai la kanban board, quindi Ã¨ facile capire cosa abbiamo finito di fare, cosa c'Ã¨ in progress e cosa dobbiamo ancora iniziare.
> 
> 

**Stefano Maestri**

> Allora dico un secondo come lo uso io cosÃ¬ se faccio cose sbagliate me lo dici. Io mediamente mischio un po' le due cose, cioÃ¨ scrivo una specifica vera e propria con l'aiuto dell'AI. Poi me la ricontrollo quando tutto torna per una feature complessa e passo al CLI â€” a Claude Code nel mio caso su cui ho installato Backlog â€” e gli dico "Ok, lÃ¬ c'Ã¨ la spec, questo Ã¨ il progetto, creami i task di backlog e creami tutti gli acceptance test." Lui macchina per un po' e alla fine mi crea l'elenco dei miei task che io ricontrollo soprattutto per gli acceptance criteria che sono una delle cose che a me piace di piÃ¹: il fatto che sia ben specificato che cosa determina che quel task Ã¨ correttamente implementato.
> 
> 

**Stefano Maestri**

> E poi uso sempre il CLI per fargli implementare uno o piÃ¹ task usando i sub agent di Claude Code utilizzando Backlog. Cosa a me piace molto anche di Backlog Ã¨ che questi task evolvono, cioÃ¨ cambiano stato, mi dice che sono completati e anche che la descrizione dell'implementazione viene aggiornata all'interno dei task. Questa cosa mi permette di tenere sotto controllo quello che sta facendo l'agent. Questo Ã¨ l'utilizzo piÃ¹ o meno che faccio io del tuo tool, che io dico quando ne parlo che Ã¨ una versione agile dell'uso degli agent dei coding agent. Non so se piÃ¹ o meno sto facendo quello che tu avevi in mente o mi sono inventato un processo tutto mio.
> 
> 

**Alex Gavrilescu**

> No, no, questo Ã¨ l'utilizzo ideale e questo Ã¨ lo stesso modo in cui lavoro anch'io. Ãˆ il modo piÃ¹ efficace di utilizzare backlog. Parlando con varie persone mi rendo conto che non Ã¨ lo strumento ideale per tutti i casi. Ci sono alcune persone che hanno questo approccio tipo babysitter con l'AI dove vogliono seguire passo passo quello che viene fatto oppure non conoscono bene quello che l'AI sta facendo, allora stanno attenti a guardare ogni singolo comando e poi gli danno l'ok. Secondo me quell'approccio lÃ¬ non Ã¨ compatibile con backlog. Con backlog Ã¨ piÃ¹ una modalitÃ  di delegare il lavoro all'AI partendo dagli spec.
> 
> 

**Alex Gavrilescu**

> Io so esattamente dove voglio arrivare, scrivo gli spec e poi do in pasto ai sub agent queste task e poi verifico alla fine guardando un po' le note che l'AI lascia nei task oppure guardo il codice, perÃ² in mezzo non sto lÃ¬ ad accettare "leggi file" o altro. In quella fase lÃ¬ sei completamente YOLO.
> 
> 

---

## CONTEXT ENGINEERING E I LIMITI DELLA CONTEXT WINDOW

**Stefano Maestri**

> YOLO per gli ascoltatori vuol dire che accettiamo di default qualunque cosa lâ€™AI faccia a monte.
> 
> 

**Alex Gavrilescu**

> You only live once. SÃ¬, hai una sola vita, quindi vai come vuoi, non ti preoccupare se poi mi cancelli il database di produzione o la root del computer. Infatti siamo un po' agli inizi di questo processo, perÃ² io vedo giÃ  che la direzione Ã¨ quella giusta. L'AI sta diventando sempre piÃ¹ capace di scrivere codice, quello che non Ã¨ tanto capace Ã¨ capire che cosa vogliamo fare. Siamo umani, vogliamo creare un software per gestire il menÃ¹ di un ristorante, quello l'AI non se lo puÃ² inventare da sola. Noi saremo sempre quelli che partono con l'iniziativa, con il goal. Poi lei scrive il codice che sta diventando sempre piÃ¹ una routine autonoma e verifichiamo alla fine se coincide con quello che vogliamo. Non deve essere necessariamente dal punto di vista dello sviluppatore, ma anche un manager di un ristorante che si fa fare il menÃ¹ digitale poi guarda se contiene gli allergeni, i prezzi e gli ingredienti giusti.
> 
> 

**Stefano Maestri**

> Alla fine quello che poi anche a me piace di backlog Ã¨ ridurre la dimensione del singolo task che sia il piÃ¹ piccolo possibile purchÃ© abbia un senso. PerchÃ© chiaramente se facciamo YOLO su "fai tutto il codice" quello che ne esce Ã¨ un mezzo disastro. Invece spezzettando il lavoro in tanti task piccoli di cui io posso controllare gli acceptance criteria, il tipo di implementazione e le scelte architetturali, mantengo la complessitÃ  sotto controllo e assegno all'AI soltanto il fatto di scrivere un codice che abbia una complessitÃ  relativamente bassa perchÃ© Ã¨ solo quel pezzettino lÃ¬. E poi un'altra cosa importante Ã¨ che i task di backlog possono avere delle dipendenze: questa cosa qui Ã¨ un'indicazione forte che dai all'AI. Fai il task 15 ma non devi rompermi quello che hai fatto nel task 2 perchÃ© tra di loro hanno una dipendenza. La sensazione Ã¨ che il livello di successo finale sia molto piÃ¹ alto che non andare in puro vibe coding.
> 
> 

**Alessio Soldano**

> Ma tra un task e l'altro resetti il contesto? 
> 
> 

**Alex Gavrilescu**

> Dipende un po' dall'utilizzo che ne fai. Su questo ho un paio di input dalle ultime conferenze perchÃ© gestire il contesto Ã¨ una cosa abbastanza nuova per gli sviluppatori. L'anno scorso parlavamo di prompt engineering, quest'anno invece parliamo di context engineering. Quest'estate hanno fatto dei test su quante istruzioni riesce a eseguire Claude Code efficacemente. Hanno visto che Claude 3 Opus aveva all'incirca 100-120 istruzioni che riusciva ad eseguire efficacemente. Ma le istruzioni non sono solo quelle che tu gli dai: appena fai partire una nuova sessione hanno un system prompt enorme di circa 60 istruzioni base tipo "se l'utente ti chiede una specifica su un file devi utilizzare questo tool".
> 
> 

**Alex Gavrilescu**

> Se tu ti immagini questo limite di 120 istruzioni in una sessione, tu non puoi andare avanti ad oltranza. Ad un certo punto vedi che l'efficacia peggiora. Vari studi hanno visto che quasi tutti i modelli sotto dopo il 30% di utilizzo del context window cominciano a peggiorare. Ed Ã¨ pochissimo il 30%: di solito appena gli chiedi qualcosa l'agente va a pescare un paio di file, cerca di capire che cosa vuoi fare e sei giÃ  quasi al 30%. PiÃ¹ ti avvicini alla fine del context window piÃ¹ i risultati degradano. Quindi, cosa facciamo con i backlog task? Facciamo tanti task in una context window o per ogni task partiamo con una sessione pulita? Idealmente parti con una sessione pulita cosÃ¬ hai la massima efficienza possibile per ogni task.
> 
> 

**Alex Gavrilescu**

> Da un lato uno potrebbe dire "vabbÃ¨ ma quel task che ho fatto prima dopo se lo perde di vista". Se parto con una sessione nuova devo ridargli tutto il contesto da zero. Ma allora vuol dire che hai creato il task sbagliato in backlog, vuol dire che non hai fatto una divisione giusta e che magari quelle istruzioni in comune tra vari task dovresti metterle nel file `agents.md` o `claude.md` invece di metterle nel task. Quest'anno invece di parlare di prompt engineering parliamo di context engineering: qual Ã¨ il contesto che l'agente ha bisogno per eseguire i task in maniera efficace, senza dargli troppe istruzioni perchÃ© abbiamo visto che se gli diamo troppe informazioni si perdono. Ãˆ una nuova skill che stiamo imparando un po' tutti quanti.
> 
> 

---

## IL PROBLEMA DEL COMPACTION E DELLA DELEGAZIONE ALL'AI

**Alessio Soldano**

> Se vuoi Ã¨ anche un po' l'arte del riassumere un task che tu hai fatto e tirar fuori soltanto il risultato che ti serve eventualmente per dare quell'informazione nella definizione dei contesti successivi e scremare tutti i dettagli che una volta completato il task non ti interessano piÃ¹.
> 
> 

**Alex Gavrilescu**

> Esatto, poi su questo topic ci colleghiamo anche col compaction. Compaction con gli AI agents vuol dire che quando arrivi alla fine del context window fai partire questa funzione che comprime tutta la conversazione passata in un riassunto da utilizzare all'inizio di una specie di nuova sessione, come continuazione della precedente. Il problema Ã¨ che in questi giorni Claude Code ha rilasciato un nuovo sistema di compaction e gli utenti hanno fatto un casino perchÃ© in realtÃ  funziona solo nei casi facili e brevi. Quando lavori su piÃ¹ ore nella stessa sessione questo compaction comincia a delirare, comincia a scrivere allucinazioni e dopo Ã¨ molto peggio. Adesso hanno fatto rollback e sono ancora alla versione vecchia.
> 
> 

**Stefano Maestri**

> SÃ¬ che perÃ² non era tanto meglio. Il problema Ã¨ che quando fai un riassunto di un'informazione complessa e densa scritta con un linguaggio formale di programmazione, cosa puÃ² andare storto? PiÃ¹ o meno tutto. Ed Ã¨ quello che succede. Infatti uno dei vantaggi di usare backlog Ã¨ proprio quello di non perdere traccia del goal di lungo termine ma riuscendo a mantenere ogni singola sessione focalizzata su degli obiettivi piÃ¹ semplici da realizzare. Di nuovo, ritorno sul fatto che le dipendenze che Backlog definisce tra i task sono fondamentali perchÃ© servono all'agente per sapere che deve leggersi che cosa Ã¨ successo prima per non andare in conflitto. Questa parte qui funziona molto bene nella mia esperienza.
> 
> 

**Stefano Maestri**

> Ecco una domanda per te Alex: tu stai lavorando anche su questa cosa qua? Fare in modo che l'MCP server di backlog aiuti in qualche modo il context engineering in maniera trasparente per l'utente o non Ã¨ un tuo obiettivo? 
> 
> 

**Alex Gavrilescu**

> Ãˆ una cosa complessa da gestire. C'Ã¨ un tool che si chiama Repompt che ti aiuta appunto a partire da quello che vuoi fare: tu hai un'interfaccia tipo chat GPT dove spieghi l'idea e Repompt guarda il tuo repository e cerca di capire il contesto e arricchisce il prompt con puntatori ai file di cui hai bisogno. Secondo me questa dovrebbe essere la direzione in cui mi piacerebbe andare anche a me. L'unica cosa Ã¨ che Ã¨ una parte molto complessa da sviluppare e backlog Ã¨ un tool che sviluppo nel mio tempo libero. Con l'MCP ad esempio sono stato lÃ¬ un mesetto perchÃ© Ã¨ una cosa nuova e ho dovuto capire tutte le specifiche finchÃ© fosse davvero utile. Quindi sÃ¬, il context engineering per adesso lo lascio agli utenti insieme all'agent.
> 
> 

**Stefano Maestri**

> Backlog Ã¨ open source, contribuite senza creare delle pull request tutte generate enormi che poi Alex ci mette piÃ¹ tempo a rivederle che a scriversele da solo. Questa la dico io cosÃ¬: non usate Backlog MD per contribuire a Backlog MD.
> 
> 

---

## LE CLAUDE SKILLS E L'INTEGRAZIONE CON BACKLOG

**Alex Gavrilescu**

> Esatto. Un altro suggerimento Ã¨ fare issues perchÃ© quando prendo in considerazione cosa sviluppare guardo le issues. Ad esempio da un po' di mesi la gente mi chiedeva le swimlanes per la kanban board suddivise per milestone. Mi sono messo a lavorarci provando Opus 4.5 e devo dire che ha fatto un gran lavoro ed Ã¨ appena stata rilasciata questa feature.
> 
> 

**Stefano Maestri**

> Allora ti faccio l'ultima domanda super verticale prima di alleggerire: Skills di Claude. Claude sta spingendo molto su questo concetto delle skills che vanno al di lÃ  del tooling, loro le chiamano "applicazioni per l'AI" perchÃ© sono una serie di prompt scritti bene che usano anche tool per raggiungere un obiettivo. Hai mai pensato di ragionare su skills che usino backlog o addirittura che backlog diventi una skill? 
> 
> 

**Alex Gavrilescu**

> Bella domanda perchÃ© ieri sera, quasi mezzanotte, ho creato il push su main del task per gestire le skill. L'idea Ã¨ molto fresca. Cosa sono le skill? Sono un modo di fare packaging. CosÃ¬ come installi un tool con npm o Brew, le skills sono adesso uno standard perchÃ© Anthropic l'ha rilasciato cosÃ¬ e Google, GitHub Copilot e Codex lo stanno integrando. Anche a me piacerebbe integrare queste skills ed Ã¨ un sistema per distribuire applicazioni fatte apposta per l'AI. Creare una skill a partire da backlog Ã¨ un altro modo nativo di distribuirlo cosÃ¬ la gente puÃ² fare `npm install backlog` o skill.
> 
> 

**Stefano Maestri**

> Ma quindi alternativo allâ€™MCP server per te? 
> 
> 

**Alex Gavrilescu**

> Non Ã¨ un'alternativa. Le skill sono praticamente un packaging dove butti dentro istruzioni per le icone, un file `skill.md`, un MCP server o entrambi. Quindi non c'Ã¨ tanto bisogno di creare una skill per backlog nel vero senso perchÃ© puoi giÃ  installarlo in altri modi, perÃ² mi piacerebbe andare in questa direzione perchÃ© Ã¨ piÃ¹ nativo. Quando fai il `backlog init` ti chiederÃ² se vuoi integrarlo tramite MCP, CLI o skill. Con le skill posso dare le istruzioni base, come il task creation o completion, in maniera nativa senza fare accrocchi nel file `agents.md` per forzarlo a leggerle. Ãˆ piÃ¹ nativo senza utilizzare dei work around.
> 
> 

---

## MUSICA E AI: WARNER MUSIC, SUNO E IL FUTURO DEL COPYRIGHT

**Alessio Soldano**

> SÃ¬, come se queste skill diventassero le specifiche per questo tipo di comunicazione e tu ti adeguassi a questo.
> 
> 

**Stefano Maestri**

> Uscendo un attimo dal nostro mondo, un'altra notizia che mi ha colpito Ã¨ quella di Warner Music che ha fatto un accordo con Suno per la generazione della musica. Il nuovo modello di business che propongono Ã¨ cedere i diritti degli autori cosÃ¬ che tu puoi chiedere all'AI di generarti ad esempio i Beatles che cantano una canzone death metal o fare dei featuring che non esistono. Ãˆ interessante per il modello di business diverso: non Ã¨ solo l'utilizzo dei diritti per trainare il modello ma per trainarlo con uno scopo. Se non posso batterli mi alleo.
> 
> 

**Alessio Soldano**

> Io credo perÃ² che partiranno prima con una cosa un po' piÃ¹ soft. All'inizio faranno leva sul fatto di dire "ok ci sono questi artisti di Warner, in particolar modo quelli che decidono di fare Optin" â€” perchÃ© un artista potrebbe decidere di no. Quelli che accettano prendono i guadagni legati alla concessione dei diritti e addestrano i modelli di Suno che presumibilmente saranno migliori rispetto a quelli trainati su una qualunque traccia audio trovata in internet. L'utente di Suno potrÃ  usare una feature premium per utilizzare un modello che Ã¨ trainato solo su roba figa, solo sulle canzoni dei principali cantanti di Warner, per generare musica di sottofondo che non sia spazzatura perchÃ© il modello Ã¨ trainato su dati buoni.
> 
> 

**Alex Gavrilescu**

> Ma sai che mi Ã¨ capitata una cosa stranissima l'altro giorno a Vienna? C'Ã¨ il pattinaggio famoso davanti al municipio e stavo pattinando e sentivo la musica nel sottofondo. Ho detto "ma sai che queste canzoni sembrano tutte piÃ¹ o meno uguali?". Poi ho ascoltato bene e stavano proprio parlando di pattinare sul ghiaccio. Sono canzoni fatte benissimo ma parlano di pattinaggio. Non Ã¨ che hanno usato Suno per fare delle soundtrack natalizie a tema cosÃ¬ non devono pagare i diritti agli autori? Ho fatto lo Shazam di una decina di canzoni e non Ã¨ venuto fuori niente. Secondo me sono generate tramite Suno o alternative.
> 
> 

---

## MERCATO DEI CHIP: NVIDIA, LA CINA E I NUOVI EQUILIBRI GEOPOLITICI

**Alessio Soldano**

> Ãˆ probabile. Dal momento che non li posso battere e che questa cosa ci sarÃ  sempre come la pirateria, diciamo "va bene trainate i vostri modelli sui nostri dati e poi tutte le piattaforme che possiamo controllare con accordi legali si accordano con noi oppure vi bloccheranno la generazione dicendo che state cercando di fare qualcosa che viola i diritti".
> 
> 

**Stefano Maestri**

> L'altra notizia che mi ha fatto sorridere Ã¨ che a Nvidia e AMD era vietato vendere i loro chip in Cina per sicurezza nazionale degli Stati Uniti. Questo era il proclama di Trump. Adesso Ã¨ un problema di sicurezza nazionale a meno che paghino il 30% dei dazi. Se pagano il 30% il problema Ã¨ un filo meno pressante.
> 
> 

**Alex Gavrilescu**

> Il problema Ã¨ quello inverso: questo blocco ha fatto sÃ¬ che la Cina decidesse di svilupparsi i chip in casa. Ha investito miliardi di yen in Huawei e adesso questi modelli vengono trainati tramite questi chip a basso costo Huawei che perÃ² se ne butti milioni vengono fuori dei modelli competitivi. A quel punto l'America o l'Europa dicono "aspetta un attimo, non gli diamo il modo di competere con noi, facciamo sÃ¬ che almeno noi ci guadagniamo qualcosa da questo".
> 
> 

**Stefano Maestri**

> Esatto e l'altro problema era che comunque chi voleva comprarli sti chip li stava comunque comprando con giri di mercato globale da Taiwan e cosÃ¬. Per cui alla fine l'idea Ã¨ "vabbÃ¨ ma perchÃ© dobbiamo anche perderci i soldi dai dazi? Almeno guadagniamo con i dazi".
> 
> 

---

## LA NUOVA VISION DI GOOGLE E IL RITORNO DI SERGEY BRIN

**Stefano Maestri**

> Legato a questo, la notizia di ieri Ã¨ che PyTorch â€” quindi Meta â€” ha rilasciato PyTorch for TPU, ovvero i processori per l'AI fatti da Google. C'Ã¨ stato questo accordo perchÃ© prima PyTorch supportava di fatto soltanto AMD e Nvidia. Adesso esiste una versione per le TPU che prima erano usate praticamente solo per l'inferenza e questo dÃ  ancora piÃ¹ forza a Google. Se penso a quello che pensavamo di Google all'inizio dell'anno, che era indietro anni luce, diciamo che in un anno ha fatto vedere al mondo che stava andando in prima e adesso ha messo la seconda e la terza.
> 
> 

**Alessio Soldano**

> Infatti stavo pensando, ma perchÃ© non siamo sicuri che non se l'erano giÃ  forcato PyTorch loro quelli di Google? 
> 
> 

**Alex Gavrilescu**

> Ma secondo te cos'Ã¨ stato lo scatto in Google a parte la paura di rimanere indietro e fallire? Ho sentito tanti rumor anche a New York.
> 
> 

**Stefano Maestri**

> Lo scatto Ã¨ che ci hanno visto un business. Tecnicamente erano fortissimi anche prima, DeepMind non Ã¨ che l'hanno scoperta quest'anno. Ma dimmi dei rumor che hai sentito tu.
> 
> 

**Alex Gavrilescu**

> I rumor che ho sentito sono che Sergey Brin, il vecchio CEO di Google, Ã¨ tornato e ha preso in carico tutta la parte AI. Essendo ingegnere ha capito il valore dell'AI e come riposizionare i team in maniera che non combattano tra di loro ma che vadano nella stessa direzione. E un po' si vede perchÃ© adesso Google sta uscendo con un sacco di tool: Google Stitch, Google Jewels, Google AI Studio e per la prima volta câ€™Ã¨ convergenza tra le varie cose. Con un solo account puoi passare da uno all'altro e funziona. Prima avevi account e API key diverse che non funzionavano con niente, invece adesso sembra davvero che sia quasi lo stesso team.
> 
> 

**Stefano Maestri**

> Questo te lo posso confermare lavorando parecchio con loro nell'ultimo anno. C'Ã¨ una vision indubbiamente. Questa settimana hanno dato al pubblico la notizia di A2I UI, che Ã¨ questo progetto per generare UI direttamente da un agente. Il fatto che un agente non sia piÃ¹ soltanto conversazionale Ã¨ positivo perchÃ© nell'industria Ã¨ piÃ¹ facile schiacciare un bottone che digitare e riduci il numero di token scambiati. Stitch e A2I UI vanno a braccetto. Stitch arriva da Google Labs dallo stesso team che ha fatto Jewels, con la stessa persona a capo del progetto. C'Ã¨ tutta una vision comune che magari arriva dall'alto da Sergey Brin o da Demis Hassabis che Ã¨ molto presente.
> 
> 

---

## GEMMA FUNCTION CALLING E AI LOCALE

**Alex Gavrilescu**

> Collegandomi alle novitÃ  Google, ieri sera Ã¨ uscito il nuovo Gemma Function Calling. Sembra un bel modello e forse quello che ci manca un po' nei telefoni perchÃ© Ã¨ piccolissimo â€” 270 milioni di parametri â€” e sui telefoni non Ã¨ ancora scoppiata l'orchestrazione dei modelli perchÃ© hai bisogno di app particolari che scaricano modelli da 2-3 GB e sono lentissimi. Io sul mio iPhone ho Virtual AI dove mi scarico i modelli e posso farli girare in locale ma i risultati non sono un granchÃ©. Invece questo Gemma essendo cosÃ¬ piccolo sbloccherÃ  un sacco di utilizzi perchÃ© Ã¨ pensato proprio solo per orchestrare chiamando funzioni.
> 
> 

**Stefano Maestri**

> E poi hanno annunciato gli occhiali e probabilmente potrebbe essere lÃ¬ lo use case: la capacitÃ  di invocare i tool giusti a seconda di dove guardi. Ãˆ un'informazione ricca ma facilmente comprimibile. Ci sono possibilitÃ  che abbia assolutamente le gambe.
> 
> 

---

## TOOLING E MODELLI PREFERITI PER LA PROGRAMMAZIONE

**Stefano Maestri**

> Volevo farti un'ultima domanda tecnica: tu che modello usi per programmare in questo momento? 
> 
> 

**Alex Gavrilescu**

> In questo momento sto andando un po' pazzo perchÃ© mi sono comprato sia il Claude Max sia il ChatGPT Pro e li sto passando uno all'altro. Quello che utilizzo piÃ¹ frequentemente Ã¨ Opus 4.5. Di solito Ã¨ il modello piÃ¹ affidabile a parte i problemi di compressione di questi giorni. Poi utilizzo un sacco Codex per fare la review perchÃ© ti trova dei bug incredibili che nessun altro trova. Scrivere codice con Opus e fare la code review con Codex per me funziona molto bene. A volte con Codex faccio anche la pianificazione di feature grandi perchÃ© mi sembra che ti "freni" un attimo e non va col tuo entusiasmo, ti dice "aspetta un attimo, secondo me non Ã¨ una grande idea perchÃ© non la fai cosÃ¬?".
> 
> 

**Alex Gavrilescu**

> Sto provando anche Gemini 1.0 e recentemente mi hanno mergiato un paio di pull request per MCP Resources quindi sono ufficialmente contributor. PerÃ² faccio un po' fatica ad utilizzarlo perchÃ© sembra che il training sia stato fatto in maniera spinta per completare i task e quando gli chiedo un parere tra A e B lui parte subito a scrivere il codice immediatamente e non si ferma mai. Per lui il goal Ã¨ scrivere il codice il prima possibile e mi dÃ  un po' da fare.
> 
> 

**Stefano Maestri**

> Ho avuto esattamente la stessa sensazione parlando di generazione di immagini. Chiedevo a Gemini di scrivermi solo il prompt partendo da un'immagine ma lui mi faceva direttamente l'immagine. Glielo ripetevo e lui di nuovo l'immagine. Da ieri non c'Ã¨ verso: beccati l'immagine e questo Ã¨ quanto. Modelli cinesi hai provato qualcosa? 
> 
> 

**Alex Gavrilescu**

> Ogni tanto provo su LM Studio sul mio Mac con i modelli cinesi come GLM 4.6 che non Ã¨ per niente male. Mi dÃ  risultati soddisfacenti offline. Anche con dei modelli da 30 billion un po' piÃ¹ leggeri backlog funziona bene e puoi creare task tutto completamente offline.
> 
> 

**Stefano Maestri**

> Mi hai dato un'idea perchÃ© io mi sto divertendo negli ultimi mesi a provare i modelli in locale. Ho un computer con 128 GB di RAM condivisa e si presta. Probabilmente l'idea di lavorare spezzettando i task con backlog puÃ² essere che assottigli la differenza nel risultato finale tra il modello remoto e quello locale. Soprattutto nella fase di creazione dei task che Ã¨ un lavoro piÃ¹ semplice che non scrivere il codice vero e proprio.
> 
> 

**Alex Gavrilescu**

> E poi un task da verificare Ã¨ facile perchÃ© leggi quello che l'AI vuole fare e non devi guardare 50 file di codice. Quindi ci sta lavorare offline in questo modo. Un altro modello di cui sento parlare spesso Ã¨ il Composer One di Cursor che gira su questi chip Cerebras che sono giganteschi e pesantissimi. Ne ho tenuto uno in mano a New York ed Ã¨ un cubo da 40 cm molto pesante. Rispetto ad una GPU Nvidia dove il core sta nel tuo palmo, questo Ã¨ piÃ¹ grosso della tua testa e costa un milione e mezzo di dollari. Fa molta impressione.
> 
> 

---

## CONCLUSIONI E SALUTI

**Stefano Maestri**

> Allora noi siamo giÃ  oltre il nostro tempo target quindi chiuderei ringraziando tantissimo Alex per essere venuto a trovarci. Spero che tu venga a trovarci ancora l'anno prossimo tra qualche mese cosÃ¬ ci racconti come backlog Ã¨ evoluto.
> 
> 

**Alex Gavrilescu**

> Grazie a voi, ci vediamo probabilmente ad un Devoxx Day vicino Lugano.
> 
> 

**Stefano Maestri**

> Ciao, grazie ancora davvero. Ciao buona serata.
> 
> 

**Alessio Soldano**

> Ciao ciao Ã¨ stato un piacere. Stay online.
> 
> 

---