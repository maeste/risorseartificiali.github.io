---
title: "Oltre la Chat: Gemini, Agenti e la corsa allâ€™AGI tra Hassabis, Amodei e il futuro del lavoro #37"
categories:
  - Puntate
tags:

  - AI
  - Agenti
  - AGI
layout: single
author_profile: true
---

{% include video id="Xbi1FBoADto" provider="youtube" %}

ðŸ‘‰ [Ascolta su Spotify](https://open.spotify.com/show/16dTKEEtKkIzhr1JJNMmSF?si=900902f2dca8442e)<br/>
ðŸ‘‰ [Guarda su YouTube](https://www.youtube.com/channel/UCYQgzIby7QHkXBonTWk-2Fg)<br/>
ðŸ‘‰ [Segui su LinkedIn](https://www.linkedin.com/company/risorseartificiali)<br/>



# Trascrizione: Risorse Artificiali - Puntata 37

## Introduzione e Panoramica del Mercato

**Stefano Maestri**

> Eccoci, bentornati e bentornate nel podcast Risorse Artificiali per una puntata del sabato. Ciao a tutti. Allora, questa settimana tante cose da dire, in teoria riusciremo a dirne poche come al solito, perchÃ© comunque sono tutte di discussione e che hanno fatto anche, vorrei dire, un po' di notizia.

**Alessio Soldano**

> Ciao!

**Paolo Antinori**

> Out!

**Stefano Maestri**

> Allora, io partirei da una che Ã¨ forse una delle piÃ¹ semplici da affrontare, ma che io ho trovato significativa. Usciti dei dati da PPC Land sul cambiamento del mercato, in particolare la quota del traffico internet, si intende negli ultimi 12 mesi. SÃ¬, 12 mesi. Per quanto riguarda i chatbot, si passa da un ChatGPT che nei 12 mesi precedenti faceva l'86,6% di mercato che Ã¨ sceso al 64,6%, mentre salgono tutti gli altri, in particolare Gemini, che va dal 5,3 al 22%, che Ã¨ quattro volte tanto. Dati in sÃ© interessanti, tutto sommato non mi hanno stupito piÃ¹ di tanto, soprattutto la crescita di Gemini.

## Crescita di Gemini e Confronto con ChatGPT

**Stefano Maestri**

> CioÃ¨, se vi ricordate, quando abbiamo iniziato questo podcast, che Ã¨ un po' meno di un anno fa, siamo alla 37Âª settimana, dicevamo: "Ma Google dov'Ã¨? Google Ã¨ indietro. Google sta recuperando". E ancora prima, quando io ho iniziato la newsletter settimane prima, il tema sulla bocca di tutti era la crisi di Google perchÃ© il loro revenue viene dalla ricerca e sono indietro sull'intelligenza artificiale, anche se l'hanno iniziata e tutto. E poi in quest'anno abbiamo visto Google, l'abbiamo detto tante volte, accelerare tantissimo e questa cosa qua sta pagando.

**Alessio Soldano**

> Ma infatti, tra l'altro, adesso la mia sensazione quasi mi colpisce solo il 22% di Gemini. Adesso non so se questi dati che dici sono la media dell'ultimo anno o se sono solo dell'ultimo quarter.

**Stefano Maestri**

> Eh no, credo siano la media dell'ultimo anno 2025 perchÃ© il trend Ã¨ sicuramente in crescita per Gemini. Il trend Ã¨ sicuramente in crescita e poi bisogna vedere perÃ² perchÃ© lÃ¬ parla del traffico internet solo del chatbot. Non so se Ã¨ compresa l'app e non so, probabilmente no. E di sicuro non Ã¨ compreso l'AI Mode che invece praticamente tutti, volente o nolente, stanno utilizzando ormai quando ricercano su Google.

**Alessio Soldano**

> Magari quello lo contano ancora come traffico normale browser o del motore di ricerca.

**Stefano Maestri**

> Boh, puÃ² essere. SÃ¬.

**Paolo Antinori**

> Aiutatemi a ricordare perchÃ© non ho ben presente: sono entrambi gratis sia ChatGPT che Gemini o hanno solo accesso a pagamento?

**Stefano Maestri**

> Hanno un tier gratis entrambi. Ce l'hanno tutti e due? SÃ¬, tutte e due. Forse quella di Gemini Ã¨ un po' piÃ¹ generosa.

**Alessio Soldano**

> Forse, esatto. Sto dicendo lo stesso, nel senso che io di Gemini ho il gratis e onestamente, per quanto non lo usi tantissimo, non sono mai arrivato a vedere "Ok, aspetta un attimo, basta". ChatGPT ho quello a pagamento e lÃ¬ ci arrivavo tranquillamente alla soglia.

**Paolo Antinori**

> Magari c'Ã¨ un elemento di questo tipo.

**Stefano Maestri**

> Con Gemini arrivi facile se fai immagini. Dopo un paio di immagini, sÃ¬. PerÃ², sÃ¬, probabilmente c'Ã¨ anche questo aspetto che dice Paolo. Io adesso non ho qua davanti l'articolo, ma stavo scorrendo velocemente: parla solo di traffico internet, quindi non c'Ã¨ distinzione pagamento o non pagamento. E poi nell'articolo si parla di una percentuale molto bassa, ad esempio, di Anthropic. Ma perchÃ© Anthropic secondo me non fa tanto traffico sul chatbot, ma fa tanto traffico sul cloud con le API.

**Alessio Soldano**

> SÃ¬, con le API eccetera.

## Traffico Internet e Utilizzo delle API

**Paolo Antinori**

> Peraltro mi avete fatto venire in mente una domanda interessante in cui sarebbe curioso andare a cercare la risposta. Cosa ci aspettiamo che sia la parte maggiore del traffico? Quello gratis o quello a pagamento? E il motivo per cui lo chiedo Ã¨ perchÃ© l'aspettativa naive potrebbe essere quello gratis, ci sono piÃ¹ utenti non paganti che utenti paganti, ma poi di contro gli utenti paganti hanno un incentivo ad usarlo perchÃ© se lo stanno pagando e magari lo usano anche dentro programmi e quindi genera ulteriormente piÃ¹ traffico che si autoincrementa.

**Stefano Maestri**

> Eh perÃ² dentro i programmi sono le API, che dentro quei numeri qua non c'erano. No, sarebbe interessante fare un paragone di quanto viene usato per le API, quanto per le API specifiche di coding, quindi con gli abbonamenti di coding, le varie offerte Anthropic, GPT e Gemini, magari qualche cinese. PerchÃ© probabilmente oggi si comincia a spostare il traffico fuori dai chatbot. Nel senso, per quanto abbiano migliorato l'offerta interna del chatbot che fa anche cose, comincia a esserci altro: le app sul telefonino, Anthropic ha rilasciato Claude Cowork, che Ã¨, diciamo, la versione per non programmatori di Claude Code. Code Ã¨ giÃ  molto utilizzato, noi per primi lo stiamo usando parecchio.

**Stefano Maestri**

> Per me Ã¨ il modo per andare, benchÃ© io abbia sempre usato Claude volentieri, lo sapete piÃ¹ di altri, lo usavo di piÃ¹ nel browser, mi sono accorto che nel browser praticamente non ci vado piÃ¹. Apro la CLI, Claude Code anche per fargli una domanda secca, non necessariamente per fare codice o fare cose. Tra l'altro non sono sicurissimo che potrei, nel senso che in teoria quell'abbonamento che paghi per Claude Code Ã¨ per codificare. Non so se l'interazione da chatbot Ã¨ nei limiti, cioÃ¨ Ã¨ accettata, perÃ² Ã¨ borderline.

**Alessio Soldano**

> Mi hai fatto venire in mente una cosa che ho visto giusto ieri sera. Stavo reinstallando alcune cose sul mio ambiente di sviluppo e mi Ã¨ uscito un pop-up di Klein, l'agente per sviluppare software, che mi diceva che adesso hanno un'integrazione con ChatGPT, per cui tu puoi usare la tua subscription ChatGPT diretta per fare coding dentro lÃ¬ senza prendere le API. Non so se avete letto questa news o cosa.

**Stefano Maestri**

> Allora, so che Klein e altri, quasi tutti ormai, usano le subscription tipo quella di Claude Code.

**Alessio Soldano**

> E va bene, fin lÃ¬ ci sta.

**Stefano Maestri**

> Ma il punto Ã¨ che... allora, un passo indietro. La maggior parte delle subscription per fare coding sono compatibili con l'API Claude, non con le API OpenAI. OpenAI di suo, quando fai una subscription al chatbot di turno, hai anche una subscription a Codex, che Ã¨ il loro agente per codificare. Il problema Ã¨ che le API di Codex sono diverse da quelle di Claude. Probabilmente quello che hanno fatto Ã¨ di supportare le API di Codex e quindi di conseguenza l'account. Io la leggo cosÃ¬, non ho letto niente, perÃ² a senso logico dovrebbe essere successo quello.

**Paolo Antinori**

> Che Ã¨ lo stesso mestiere che fa ZAI con GLM, di cui abbiamo parlato in passato e di cui siamo utenti. Loro hanno un API layer di compatibilitÃ , due ne hanno addirittura, almeno due ne ho incontrati io. Hanno quello di Claude e hanno quello di OpenAI.

**Stefano Maestri**

> Di Codex anche, sÃ¬. E OpenAI invece guardandolo dall'altro punto di vista, cioÃ¨ dal punto di vista del client, Open Code supporta, ad esempio, il layer di compatibilitÃ  al contrario da client, sia per Claude Code che per Codex che per Mistral che ha un suo specifico. Oltre a supportare quello di Claude Code, Mistral ha anche il suo specifico, e quelli di Open Code hanno tutti questi layer di compatibilitÃ , quindi immagino che Klein abbia aggiunto il layer di compatibilitÃ  con Codex. Vado solo a logica.

**Alessio Soldano**

> SÃ¬, ma guarda, stavo leggendo adesso la news, effettivamente parla di quello di OpenAI Codex. A sto punto mi domando se questo tipo di traffico finirebbe in quella statistica di cui parlavamo prima.

**Stefano Maestri**

> Secondo me no, perchÃ© quelli sono API, comunque qui parlano di traffico HTTP internet standard.

## Regole e Limitazioni nell'Uso dei Modelli AI

**Paolo Antinori**

> Fammi condividere con voi una riflessione, Stefano, sulla tua confessione di un attimo fa in cui dicevi forse non dovrei usarlo come motore di ricerca ma solo per il coding. Ãˆ una cosa che tendenzialmente faccio anche io, nel senso fai le cose nello strumento piÃ¹ vicino a te, ti dÃ  lo stesso risultato, che te ne frega di cambiare finestra? Non ti sembra di fare niente di male e sono d'accordo con te, per quanto ufficialmente, probabilmente nei termini di contratto, ci potrebbe essere scritto di non farlo cosÃ¬ e quindi noi potremmo star violando, perÃ² ci diciamo ragionevolmente che non stiamo facendo nulla di troppo male.

**Paolo Antinori**

> E sono d'accordo con te, non ti voglio dire che sei cattivo, ma giusto ieri ero in una call di lavoro in cui qualcuno ricordava che invece uno dei termini ben definiti nel contratto di questi modelli, che ben ci guardiamo di violare, Ã¨ quello di non utilizzare questi modelli per fare training di altri modelli. Se vi ricordate anche quella Ã¨ una riga scritta dentro lÃ . Tecnicamente possiamo farlo, cioÃ¨ con pazienza e un po' di malizia potremmo anche non farci beccare. Non lo stiamo facendo, sto dicendo che ci sono alcune di queste regole che hanno un valore decisamente piÃ¹ forte rispetto alle altre, come questa qua di non usarlo per cercare.

**Stefano Maestri**

> SÃ¬, allora infatti, e peraltro i vendor si tutelano da questa cosa perchÃ© comunque c'Ã¨ un'analisi del traffico e notizia di qualche settimana fa, ad esempio, Ã¨ che Anthropic aveva bannato Open Router, credo, perchÃ© utilizzava il traffico HTTP standard, quello del chatbot, per fare coding, usato come API. Che Ã¨ il duale rispetto a quello che dico io. Ma Anthropic su Opus mi pare, cosÃ¬ saltiamo a piÃ¨ pari in un'altra discussione, ha bannato alcuni utenti che usavano Cloud Bot o adesso si chiama Open Claude. Prima si chiamava Moltbot, ha cambiato tre nomi nel giro di pochi giorni.

**Stefano Maestri**

> Comunque un agente che fa tante cose, dopo ne parliamo, non solo coding, fa tutt'altro, fa un po' quello che promette di fare Claude Cowork, quindi lavorare con automazione di task. Ho letto nel loro Discord che qualche utente Ã¨ stato bannato. Curiosamente solo quelli che usavano Opus invece che usare Sonnet, probabilmente perchÃ© questi hanno detto "ci costa un sacco e quindi questo lo monitoriamo di piÃ¹ che non facciate cose strane". Credo che vada piÃ¹ o meno cosÃ¬. PerÃ² Ã¨ interessante vedere anche come hanno fatto.

**Stefano Maestri**

> Allora, io poi sono andato a leggermi un po' in giro, in generale su come hanno fatto i banning di altri. Ad esempio, vi ricordate che avevano bannato alcune aziende competitor dall'usare le API di Claude perchÃ© lo usavano per codificare e qualcuno dice anche per aiutarsi a trainare i propri modelli. C'Ã¨ un'analisi sofisticata del traffico, cioÃ¨ non Ã¨ soltanto le chiamate. Loro hanno, da quello che ho letto, un modello che Ã¨ un Haiku, il modello piÃ¹ piccolo di Claude, fuintunato apposta per analizzare il traffico eventualmente malizioso sull'utilizzo di certi tipi di API.

**Alessio Soldano**

> AI che guarda l'uso delle AI.

**Stefano Maestri**

> Esatto, perÃ² Ã¨ interessante. Non Ã¨ soltanto guardare dove Ã¨ arrivato con l'HTTP, se il traffico sale oltre un certo livello fanno un'analisi molto piÃ¹ dettagliata di che cosa sta succedendo. Mi ha aperto anche casi d'uso esterni alle AI, cioÃ¨ come si potrebbe fare un'analisi di traffico che vada molto piÃ¹ nel merito di quanto non abbiamo fatto in passato.

**Paolo Antinori**

> Beh ci sta, Ã¨ il futuro dei firewall. Mi sono perso nell'ironia in cui i vendor sostengono che loro possono utilizzare l'informazione dei libri di pubblico dominio e non di pubblico dominio per trainare i loro modelli, ma noi non possiamo usare i loro modelli per trainare altri modelli. Colgo l'ironia della proprietÃ  transitiva che non vale.

**Stefano Maestri**

> SÃ¬, la proprietÃ  transitiva non vale. Sai che quella roba lÃ¬ del trainare altri modelli non c'era in molti dei loro disclaimer, dei loro contratti. Ãˆ stata aggiunta dopo l'effetto DeepSeek l'anno scorso. DeepSeek Ã¨ stata velatamente, non tanto velatamente, accusata da Altman di aver usato ChatGPT per fare distillazione di informazione e creare soprattutto dati sintetici.

**Paolo Antinori**

> Trovo strane queste license agreement di utilizzo in generale, nel senso che poi so che esistono da sempre, ancora prima dei modelli. Una delle piÃ¹ classiche Ã¨ la SIAE in Italia. Se tu hai l'abbonamento a Sky e hai un bar non puoi farlo vedere a tutti quanti, devi comprare l'abbonamento apposta. Solo che poi mi vengono in mente dei casi estremi per cui, che ne so, l'Uniposca potrebbe dire che non mi vende il pennarello se ci disegno in metropolitana. SÃ¬, va bene, perÃ² come fai a fare enforcing di sta roba? Mi sembra senza senso.

## Standardizzazione e Innovazioni di Anthropic

**Stefano Maestri**

> Poi, stando nel mondo Anthropic, non so se avete visto che hanno rilasciato la prima estensione ad MCP. MCP, ricordiamo il protocollo per integrare applicazioni terze come API con un modello. Ed Ã¨ interessante perchÃ© Ã¨ l'estensione che va insieme un po' a un MCP UI che nominavamo qualche settimana fa, invece queste qua sono vere e proprie app. Quindi io posso, attraverso l'estensione del protocollo MCP, definire delle interfacce utente che si aprano all'interno di Claude Web, Claude Cowork, Claude Desktop, eccetera. Ovviamente non code perchÃ© essendo solo una interfaccia...

**Stefano Maestri**

> Che Ã¨ un po', cioÃ¨ non Ã¨ un'idea nuovissima, nel senso OpenAI ce l'ha giÃ  con le ChatGPT app. Giusto ieri mi stavo programmando il viaggio in Giappone e nel chiedergli le cose degli hotel lui mi ha tirato su una app con la mappa dove mi faceva vedere gli hotel e la loro valutazione, che era assolutamente l'equivalente di quella cosa lÃ¬. E la stessa cosa Gemini da Gemini 3 ha questo concetto di app che possono partire per generare un'esperienza piÃ¹ evoluta, tipo ti aggiunge video, ti aggiunge foto. Mi Ã¨ capitato qualche volta.

**Stefano Maestri**

> La parte interessante qui Ã¨ che Anthropic tenta di farlo diventare uno standard, se vuoi un po' mungendo la loro posizione di forza in questo momento sullo standard MCP che Ã¨ stato poi adottato da tutti, perchÃ© OpenAI ce l'ha, Gemini ce l'ha, tutti quanti ce l'hanno. Sta dicendo "Va bene, vogliamo fare le app, facciamole che vadano in qualunque chatbot o applicazione che supporta MCP", evidentemente perchÃ© loro sono molto interessati a posizionarsi bene a livello enterprise. Quello Ã¨ il loro target, continuano a dirlo, ma non hanno in questo momento la stessa forza che hanno gli altri due, soprattutto di generare accordi con chi magari le app le fa. Mi viene in mente Figma piuttosto che chi tratta le immagini, e quindi spingere su un protocollo che standardizza questa cosa gli permette di usufruire di accordi che fanno anche altri. Io l'ho letta cosÃ¬, perÃ² bravi loro che standardizzano.

**Alessio Soldano**

> SÃ¬, perÃ² in generale benvenga la standardizzazione.

## SpiegabilitÃ  dei Modelli e Adozione nell'Enterprise

**Paolo Antinori**

> Non ci stavo pensando ed Ã¨ interessante quello che dici. Sto pensando al fatto che ho ascoltato anche un video di Amodei che parlava con Hassabis questa settimana e il video ricordava che comunque nella visione di Amodei c'Ã¨ una certa e discreta etica o quantomeno volontÃ  di fare delle cose nel bene, a seconda di quanto gli si voglia credere fino in fondo. E quindi mi chiedo se decisioni di questo tipo open non abbiano in realtÃ  anche una componente di fare del bene e basta, piÃ¹ che non di fare del business.

**Stefano Maestri**

> No, no, c'Ã¨ sicuramente quell'aspetto lÃ¬ che Ã¨ abbastanza forte da sempre nella storia da loro raccontata, sia sulla spiegabilitÃ  dei modelli. Tutta la ricerca che viene fatta sulla spiegabilitÃ  dei modelli per cercare di capire che cosa succede all'interno Ã¨ quasi tutta trainata da Anthropic. Ci sono sempre le doppie valenze in realtÃ . Uno dei motivi per cui l'adozione nel mondo enterprise Ã¨ piÃ¹ difficile Ã¨ proprio perchÃ© i modelli non sono spiegabili. Quindi se immagini una banca o un'assicurazione che fanno fare delle scelte al modello, immaginiamo una versione agentica molto piÃ¹ evoluta tra un paio d'anni, che proprio prende la decisione: ti do o non ti do il mutuo? Che sia spiegabile Ã¨ fondamentale poter dire il perchÃ© Ã¨ stata presa una decisione, anche per una tutela legale. E il fatto che questi strumenti vengano visti a volte come una black box Ã¨ un attrito nell'adozione.

**Paolo Antinori**

> Scusami, mi viene da dire, io la definirei un po' cosÃ¬ la mia banca: so che cosa entra, non so che cosa esce, non ho capito con quale regola, quindi parliamone.

**Stefano Maestri**

> Sono d'accordo, perÃ² fino a quando non c'Ã¨ qualcuno che li denuncia e allora al giudice devono dire che cosa Ã¨ successo. E quindi i maliziosi dicono: la spiegabilitÃ  serve sÃ¬ per motivi alti e filosofici, ma serve anche perchÃ© se i modelli sono spiegabili Ã¨ piÃ¹ facile che siano adottati nell'Enterprise. E siccome quello Ã¨ il loro target, c'Ã¨ un mutuo interesse.

## Controversie Legali e Venture Capital

**Stefano Maestri**

> Mi si accende il discorso sulle denunce. Non so se avete visto la causa in corso tra xAI, Elon Musk e OpenAI. C'Ã¨ questa causa in corso perchÃ© lui Ã¨ uno dei founder e dice "Voi non potete diventare for profit perchÃ© io vi ho fatto un funding per una non profit".

**Paolo Antinori**

> Che mi sembra stranamente ragionevole peraltro come posizione, nonostante arrivi da Elon. Certo, raccontata semplicemente cosÃ¬, io non sarei neanche contro.

**Stefano Maestri**

> No, non sarei contro neanch'io di base, anche se in realtÃ  casca tutto il mondo dei venture capital americano perchÃ© crei un precedente. Se un'azienda fa un pivot e cambia il suo goal, allora il venture capital gli puÃ² chiedere indietro i soldi. Disastro, non c'Ã¨ una startup negli Stati Uniti che parta in un modo e finisca nello stesso modo. Ma perchÃ© Ã¨ giusto cosÃ¬, ti adatti al mercato.

**Stefano Maestri**

> Io ho sentito in un altro podcast una lettura che trovo piÃ¹ vicina all'Elon-pensiero. Lui li ha portati in tribunale e ha chiesto danni per 97 billion, 97 miliardi di dollari. La lettura perÃ² Ã¨ super interessante: dicono che in realtÃ  lui lo sa che non li prenderÃ , ma perchÃ© portarli in tribunale ora? PerchÃ© questi stanno preparando un IPO, e tu vai a fare un IPO con un potenziale debito di 97 billion? Ãˆ una manovra finanziaria, se un'azienda si presenta in borsa e dice "Mi quoto ma ho potenziali 97 miliardi di debito", forse il valore scende.

**Paolo Antinori**

> Ragionevole.

**Stefano Maestri**

> Tra l'altro, pare che Bending Spoons si quoti entro il secondo quarter con 20 billion di valutazione. Ma chiudiamo la parte finanziaria e veniamo all'intervista.

## Interviste e Percezioni nel Mondo Economico

**Stefano Maestri**

> L'avete sentita? Cosa ne pensate? Io sto zitto, ho tanti pensieri ma non ne dico neanche uno per ora.

**Paolo Antinori**

> CosÃ¬ come l'altra volta che ho sentito un'intervista di Hassabis, faccio fatica a ascoltare lui quando parla ma anche Amodei, perchÃ© o parlano troppo veloci o la densitÃ  dei concetti per parola Ã¨ piÃ¹ alta di quella che il mio cervello riesce ad assorbire. Mi ricorda la prima volta che ho guardato Dr. House o Rick e Morty, dove parlavano talmente in fretta di robe interessanti che dovevo fermarmi un momento.

**Alessio Soldano**

> Beh, ma scusa, intanto mettiamo un po' di contesto: l'intervista non era in un forum tecnico, era il World Economic Forum. Quindi il target erano politici, economisti, gente che ha in mano le redini del futuro del mondo. Infatti non hanno parlato di tecnicismi, sono stati piÃ¹ sulle previsioni dei prossimi 6, 12, 18 mesi, anche 5 anni.

**Paolo Antinori**

> Era un round due, la prima puntata l'avevano giÃ  fatta tempo dietro. Io ci ho letto un tentativo di far alzare le antenne ai politici sul fatto che l'arrivo dell'AGI potrebbe essere imminente ed Ã¨ un problema serio per chi non mastica di tecnicismi, perchÃ© il resto del mondo non Ã¨ preparato.

## Definizioni di AGI e SGI

**Stefano Maestri**

> Sempre per dare un po' di contesto, hanno parlato di AGI (Artificial General Intelligence) e di SGI (Super General Intelligence). Proviamo a darne una definizione classica. L'AGI Ã¨ un'intelligenza artificiale che Ã¨ brava almeno come il miglior essere umano in tutti i campi. Abbiamo giÃ  delle IA che in un campo specifico sono piÃ¹ brave della maggior parte degli esseri umani, come quelle che hanno vinto le Olimpiadi di matematica, ma se gli chiedi come si fa il verde non sanno dirti giallo e blu insieme. PerchÃ© sono molto specifiche. Invece l'AGI mette insieme il bravo programmatore, il bravo chef, il bravo pittore, tutti in un singolo oggetto.

**Stefano Maestri**

> La super intelligence Ã¨ quella che Ã¨ molto piÃ¹ intelligente di tutti i migliori uomini, capace di scoprire cose nuove.

**Paolo Antinori**

> Anche semplicemente nel confronto con l'umano con una capacitÃ  di memorizzazione infinita. Un test per un'AGI passerebbe per uno che passa l'esame dell'universitÃ , ma non ci si deve aspettare che sappia l'enciclopedia a memoria. Sono due cose diverse.

**Stefano Maestri**

> Beh, ma non Ã¨ solo sulla memoria, Ã¨ l'utilizzo di quella memoria per creare cose nuove. Essere in grado di fare piÃ¹ del migliore essere umano in ogni campo, meglio di qualunque Nobel in tutti i campi. Amodei in quell'intervista dice che Ã¨ come avere 1000 Nobel per ogni campo che lavorano insieme.

## Dibattiti sul Futuro dell'Intelligenza Artificiale

**Stefano Maestri**

> Loro non sono d'accordo sul fronte temporale. Amodei parla di addirittura quest'anno o l'anno prossimo. Hassabis sostiene 5 anni. E la moderatrice rinfaccia ad Amodei che questa cosa l'aveva giÃ  detta e aveva giÃ  cannato la previsione. LÃ¬ lui si arrampica un po' sugli specchi cercando di ridefinire l'AGI mettendoci "specializzata" alla fine. Praticamente tolgono la G da AGI ma la chiamano comunque AGI.

**Paolo Antinori**

> Stai barando!

**Stefano Maestri**

> Esatto. Invece Hassabis dice che per fare quella roba lÃ¬ serve la physical AI. PerchÃ© per lui la vera intelligenza generale Ã¨ quella che sa fare cose fuori dal computer, con i robot.

**Alessio Soldano**

> SÃ¬, perchÃ© Hassabis dice che Ã¨ facile finchÃ© sei in un ambito in cui puoi verificare i risultati. Quando passi a situazioni in cui devi fare l'esperimento fisico per capire se il comportamento Ã¨ buono o meno, lÃ¬ quel boost di produttivitÃ  dell'IA che scrive software per migliorare se stessa non c'Ã¨, almeno ad oggi.

**Stefano Maestri**

> In tutto questo Amodei dice: "Spero che lui abbia ragione perchÃ© ci dÃ  piÃ¹ tempo per mettere a posto le cose, perchÃ© il mondo non Ã¨ pronto all'AGI". Da cui la presentazione al World Economic Forum.

**Paolo Antinori**

> LÃ¬ c'Ã¨ stata l'osservazione della moderatrice: "Ma non possiamo metterci d'accordo per cui tu lo fai oggi ma te lo tieni per te per 5 anni e lo studi?". Che era una giusta obiezione.

## Riflessioni sulla Competizione Globale

**Stefano Maestri**

> Se fosse un'azienda sola forse sÃ¬, ma con la competizione degli altri paesi... in 5 anni la Cina ci arriva tanto quanto l'America. Non puoi fermare questa cosa. Tra l'altro noto che c'erano loro due, i due piÃ¹ scienziati, ma nÃ© Altman nÃ© Musk sono stati invitati a quella conversazione. Forse perchÃ© Amodei e Hassabis sono piÃ¹ pacati.

**Stefano Maestri**

> PerÃ² Ã¨ impressionante detto da due che vedono cose che noi non vediamo. Hassabis giÃ  nel 2017 parlava di Large Language Model in grado di conversare amabilmente, quando nessuno li chiamava cosÃ¬. Quindi la domanda Ã¨: cos'Ã¨ che hanno visto per fare un po' i Doomer? PerchÃ© continuavano a dire di essere positivi, ma quello che dicevano era da Doomer: il lavoro sparisce, guerre, peste, carestie, la ridistribuzione della ricchezza dovrÃ  seguire regole diverse.

**Stefano Maestri**

> Amodei scrive una volta all'anno un essay e quello uscito due giorni dopo l'intervista sono 97 minuti di lettura. Un libro. Ed Ã¨ quello con la visione piÃ¹ cupa. Dice che il lavoro sparirÃ , ma saremo bravi a fare altro, tipo le parole crociate.

## Paragoni con la Bomba Atomica e Riflessioni Finali

**Paolo Antinori**

> Amodei cita il film Contact: come ha fatto una civiltÃ  avanzata a sopravvivere a se stessa nella fase di adolescenza tecnologica? Che Ã¨ quella in cui suppone siamo noi ora: possiamo fare piÃ¹ cose di quante ne riusciamo a capire. Ãˆ sorprendente pensare che siamo sopravvissuti fino a questa etÃ  considerando le cazzate che abbiamo fatto.

**Stefano Maestri**

> E poi loro, molto americani, continuano a dire che bisogna proteggere questa tecnologia dalla concorrenza perchÃ© Ã¨ come la bomba atomica. Questo paragone fortissimo Ã¨ sempre un po' impressionante.

**Paolo Antinori**

> Mi colpiva come un uomo pacato come Amodei continuasse a dire che non possiamo assolutamente dare alla Cina i chip. Quasi come un venditore di pentole.

**Stefano Maestri**

> Che poi Ã¨ una ricetta che non funziona, essere protezionisti. C'Ã¨ un razionale perÃ²: tutto quello che facciamo oggi passa dall'hardware, che Ã¨ il collo di bottiglia. Per disegnare un processore, produrre la macchina che lo stampa, mandarla a Taiwan e stampare i chip passano 5 anni. Il software Ã¨ molto piÃ¹ veloce dell'hardware. Quindi il suo discorso Ã¨: siccome l'hardware Ã¨ piÃ¹ lento, se loro hanno qualche anno di ritardo, questo ci dÃ  tempo di adattare il mindset prima che arrivi l'AGI.

## Il Cambiamento dei Nomi e le Aspettative di Mercato

**Stefano Maestri**

> Nel frattempo stanno succedendo un sacco di cose. Menzionavo prima questo Open Claude, che ha cambiato nome tre volte in dieci giorni: Claude Bot, poi Moltbot, ora Open Claude.

**Paolo Antinori**

> Io so perchÃ© ha cambiato nome. PerchÃ© adesso fa figo scrivere su LinkedIn "ex Google", "ex Amazon". Devono aver chiesto al modello di scegliere il nome e lui ha suggerito di cambiare nome per fare scena.

**Alessio Soldano**

> E se poi fa confusione con il Claude di Anthropic, meglio ancora.

**Stefano Maestri**

> Hanno fatto un blog post per spiegare perchÃ© hanno cambiato nome tre volte. Se qualcuno Ã¨ curioso, c'Ã¨ il post.

## L'Utilizzo di Modelli e Agenti AI

**Stefano Maestri**

> Premessa: Ã¨ una roba da smanettoni. Cosa fa? Sostanzialmente quello che promette Claude Cowork: avere un agente che ha accesso a tutte le vostre informazioni, mail, calendario, file. Ãˆ un ciclo che itera sul modello ed Ã¨ capace di fare cose interfacciandosi con WhatsApp o Telegram.

**Stefano Maestri**

> Io l'ho fatto partire isolandolo un po' per sicurezza. Gli ho dato accesso in lettura alla mia mail, a un calendario e a delle directory con file markdown. L'esperienza Ã¨ impressionante anche se Ã¨ buggato. Immaginatelo sul lungo periodo quando una Big Tech ci metterÃ  le mani.

## Interazione e Automazione con le AI

**Stefano Maestri**

> Mi Ã¨ capitato di scrivergli da Telegram mentre ero in giro: "Dovrei aver ricevuto quattro email da questa newsletter. Prendi tutti i link, traduci in italiano, fammi una classifica e dammi le 10 notizie piÃ¹ rilevanti. Mettile in un file e mandami la sintesi qui". E lo fa. Lo fa anche bene. Oppure chiedergli degli appuntamenti. Ãˆ una finestra sul futuro di come si utilizzerÃ  il PC.

## Riflessioni sul Futuro della Programmazione

**Paolo Antinori**

> Aiutami a capire: il modello mentale che mi sono dato Ã¨ che sia un agente a cui Ã¨ stato insegnato come integrarsi con Telegram, web e mail. Ma sono building blocks che avevamo giÃ  o c'Ã¨ di piÃ¹?

**Stefano Maestri**

> Hai toccato il punto. Se vogliamo smitizzare, prendiamo Claude Code che stiamo usando tutti e tre. Ci ha colpito, ma il software in sÃ© non Ã¨ l'uovo di Colombo, i modelli lo sono. Infatti ci sono giÃ  mille cloni. Questo software integra bene tutta una serie di canali e fa vedere quello che si puÃ² fare. Poi puoi farlo anche da solo con piÃ¹ fatica.

**Paolo Antinori**

> C'Ã¨ una differenza sensibile con Manus?

**Stefano Maestri**

> L'accesso al computer e l'apertura verso mille fonti. C'Ã¨ tanto context engineering dietro. Amodei dice che il 90% del software sarÃ  scritto dall'IA entro la fine del 2025. Non Ã¨ andato lontano. Magari Ã¨ il 30%, ma Ã¨ tanto. Raccontava che in Anthropic molti ormai dettano e basta.

## Evoluzione del Codice e delle Interfacce Utente

**Stefano Maestri**

> C'Ã¨ il paradosso di Jevons: piÃ¹ una tecnologia diventa efficiente, piÃ¹ ne consumiamo. Non Ã¨ che il telefono ha tolto il lavoro al fotografo, ma quello che prima era la totalitÃ  ora Ã¨ il 10%. I programmatori scriveranno forse solo il 10% del codice, ma quel 10% sarÃ  enorme.

**Stefano Maestri**

> PerÃ² mi chiedo: non Ã¨ che stiamo diventando come i datilografi? Quando Ã¨ arrivato il computer hanno pensato che avrebbero solo scritto di piÃ¹, invece Ã¨ cambiato proprio il modo di lavorare. Forse il codice diventa una nicchia e il nostro lavoro diventa mettere insieme i pezzi con gli agenti.

**Alessio Soldano**

> SÃ¬, noi diciamo cosa vogliamo e l'IA lo realizza se il contesto Ã¨ ben definito.

**Paolo Antinori**

> Questo mi richiama alla battuta: "Adesso basta dire all'IA chiaramente cosa vuoi". Quindi i clienti diventeranno bravissimi a spiegarsi, mentre a noi hanno sempre detto cose sbagliate a metÃ .

## Il Ruolo degli Agenti AI nel Futuro della Tecnologia

**Stefano Maestri**

> Gli agenti portati all'estremo sono la fine del mouse, non la fine dei programmatori.

**Paolo Antinori**

> Ti seguo. Ãˆ come se Siri o Alexa funzionassero davvero. Gli dici le cose e loro le capiscono invece di far partire la canzone sbagliata.

**Stefano Maestri**

> Ieri Ã¨ uscita la nuova versione di Chrome potenziata dall'IA. Ãˆ la "personal intelligence" all'interno dell'ecosistema Google. Accesso a foto, mail, documenti. Ãˆ lo stesso concetto di Open Claude ma sul cloud invece che sul file system locale.

**Alessio Soldano**

> E sei vincolato a un unico vendor.

**Stefano Maestri**

> Forse sono io un boomer che pensa ancora alle cose sul PC, mentre per molti il punto di concentrazione Ã¨ Google Workspace.

**Paolo Antinori**

> Google ci aveva giÃ  provato con i Chromebook e non ci Ã¨ riuscita del tutto. Vedremo.

**Alessio Soldano**

> Io sono piÃ¹ possibilista. Se guardi quanto facciamo in cloud oggi rispetto a 10 anni fa, c'Ã¨ un abisso. Quando cambi computer non devi quasi piÃ¹ copiare nulla.

## La Trasformazione degli Strumenti di Lavoro

**Stefano Maestri**

> Rubrica Boomer vs Gen Z: mia figlia ha chiesto un tablet invece del computer perchÃ© "tanto Ã¨ tutto in cloud". Lo usa con la tastiera Bluetooth e fine. Per me Ã¨ impensabile, il tablet lo uso solo per leggere a letto. Alla fine mi porto sempre dietro il PC.

**Alessio Soldano**

> Dipende dalle aspettative. Se usi il device solo per mail e documenti, il tablet basta.

**Stefano Maestri**

> Ma tutti vanno in quella direzione: Anthropic con Cowork, OpenAI con l'editing dei LaTeX, Google con la personal intelligence. Mi chiedo: sta cambiando il modo di scrivere software o sta cambiando quello che chiamiamo software? Il nuovo software Ã¨ orchestrare gli agenti. Claude Code fa cose incredibili con quattro comandi bash.

**Paolo Antinori**

> Questa settimana ho scoperto che con SED si possono estrarre porzioni di file interamente. Non lo sapevo! Probabilmente lo sapeva mio zio che programmava sugli Unix negli anni '90. Ãˆ come in un magazzino: prima alzavi i pesi a mano, ora schiacci un pulsante. C'Ã¨ sempre l'utente che schiaccia, per ora.

**Stefano Maestri**

> Hai visto i magazzini Amazon? LÃ¬ non c'Ã¨ quasi nessuno.

**Paolo Antinori**

> Vero, ma il mio robot aspirapolvere va al buio perchÃ© ha i sensori infrarossi. Non ha bisogno che io accenda la luce. Ci sono tante cose che sono sempre state lÃ¬ e non ci pensiamo mai.

## Conclusioni e Teaser per il Futuro

**Stefano Maestri**

> Bene, siamo all'ora e dieci. Abbiamo lanciato il teaser della prossima puntata speciale sul nostro uso degli agenti.

**Paolo Antinori**

> Dovresti mettere un suono di gong alla fine, tipo l'entrata di Undertaker.

**Alessio Soldano**

> DUNG!

**Stefano Maestri**

> MercoledÃ¬ esce anche un'intervista che ho giÃ  montato.

**Paolo Antinori**

> PerchÃ© non facciamo i teaser delle interviste?

**Stefano Maestri**

> Non lo so, mi piace fare la domanda al buio all'ospite. Se a qualcuno non piace lo ignorerÃ². Ciao a tutti!

**Alessio Soldano**

> Ciao!

**Paolo Antinori**

> Ciao ciao!