---
title: "Lâ€™AI che cambia tutto: multi-modello, immagini e video evoluti, auto autonome e meccanici col pilota automatico #29"
categories:
  - Puntate
tags:

  - AI
  - Anthropic
  - Images
  - Video
  - Karpathy
layout: single
author_profile: true
---

{% include video id="iNbxngud1us" provider="youtube" %}

ðŸ‘‰ [Ascolta su Spotify](https://open.spotify.com/show/16dTKEEtKkIzhr1JJNMmSF?si=900902f2dca8442e)<br/>
ðŸ‘‰ [Guarda su YouTube](https://www.youtube.com/channel/UCYQgzIby7QHkXBonTWk-2Fg)<br/>
ðŸ‘‰ [Segui su LinkedIn](https://www.linkedin.com/company/risorseartificiali)<br/>


# Trascrizione: Risorse Artificiali - Puntata 29

## [00:00] Intro e Numerazione Puntate

**Stefano Maestri**
> Ciao a tutte e tutti e bentornati a Risorse Artificiali con voce nasale perchÃ© ho un raffreddore esagerato, ma siamo qui lo stesso per la puntata 29. Attenzione, 29 tutte in fila, non abbiamo saltato neanche una settimana, siamo bravissimi. Ma adesso che le contiamo, sappiamo anche che puntata stiamo registrando. Alessio, che Ã¨ l'ingegnere vero del gruppo, ad un certo punto ha detto "Ma perchÃ© non mettiamo i numeri alle puntate?".

**Alessio Soldano**
> Adesso che le contiamo, sappiamo anche che puntata stiamo.

**Stefano Maestri**
> E io ho detto, "Eh, boh, perchÃ© non non mi Ã¨ mai venuto in mente, mettiamoli". E allora le abbiamo numerate, sappiamo che siamo alla puntata 29. Eh, 29, quindi vuol dire piÃ¹ di 6 mesi.

## [02:34] Il nuovo Transcript Integrale

**Stefano Maestri**
> Eh, ma eh da adesso dalla puntata 27 abbiamo anche il transcript integrale, cosÃ¬ se per caso vi siete persi qualcosa. CioÃ¨ e dopo piÃ¹ di 6 mesi abbiamo deciso di diventare piÃ¹ bravi e piÃ¹ professionali e vi mostriamo una cosa di cui andiamo estremamente orgogliosi. Attenzione che sto per fare lo share dello screen. Eh, andiamo estremamente orgogliosi che Ã¨ questo che non Ã¨ No, scusate, che non Ã¨ questo, forse. No, non Ã¨ questo, eh. Ho sbagliato. Cosa succede? Ma non la taglia nemmeno tanto fa niente. Dove?.

**Paolo Antinori**
> PerchÃ© chi ci ascolta lo fa per pietÃ , non per interesse.

**Stefano Maestri**
> E sÃ¬, lo fa per pietÃ , non per interesse. No, ma non Ã¨ vero. Guarda che abbiamo avuto un incremento di ascolto importante nelle ultime te. Dovrei dire il numero di puntate, ma non lo so. Ma vabbÃ¨, negli ultimi due mesi 28, no?. Siamo orgogliosi di questa cosa che vabbÃ¨ il nostro sito fino qua ce l'avevamo giÃ , ma da adesso dalla puntata 27 abbiamo anche quti post che sono il transcript integrale, vedete, del di quello che diciamo. CosÃ¬ se per caso vi siete persi qualcosa, visto che tutti qui si lamentano che siamo troppo lunghi, siamo troppo prolissi e poi devono tornare indietro, ascoltare perchÃ© non si ricordano le cose, non vi preoccupate perchÃ© potete andare sul nostro sito e cercare la parola chiave, la parolaccia chiave tipicamente che io Paolo abbiamo detto e e trovare il punto facilmente.

**Stefano Maestri**
> Eh no, scherzi a parte, allora Ã¨ carino anche, l'abbiamo raccontato velocemente l'altra volta, Ã¨ carino anche dire come questa cosa la facciamo, perchÃ© Ã¨ un'applicazione pratica dell AI. Noi usiamo un software per registrare che si chiama Riverside che fa il transcript mettendo chi ha parlato, il minuto e il testo. Il problema di questi transcript Ã¨ che il testo non Ã¨ super affidabile in italiano. In inglese Ã¨ quasi perfetto, in italiano non Ã¨ molto affidabile. CioÃ¨, si capisce di cosa stai parlando, ma molte parole sono sbagliate, non Ã¨ pubblicabile cosÃ¬ com'Ã¨ e allora non l'abbiamo mai pubblicato, salvo che nel frattempo Ã¨ arrivato Gemini 3 e quindi quello che possiamo fare Ã¨ prendere il transcript generato invece da YouTube, che invece anche in italiano Ã¨ praticamente perfetto, parola per parola, ma che non ha il collegamento con i minuti e con chi ha detto che cosa e questo non lo rendeva pubblicabile.

**Stefano Maestri**
> Prendendo i due transcript e il video e dando l'impasto a Gemini 3, esce fuori un bellissimo file markdown che io posto su GitHub ed Ã¨ finita. Eh, quindi fa lui questo lavoro qua con un prompt neanche troppo complesso in cui gli dico, "Guarda, hai un transcripto, tienilo come riferimento per il minutaggio, questo Ã¨ un altro trans, tienilo come riferimento per le parole, hai anche il video, fai del tuo meglio" e lui fa un buon lavoro, secondo noi.

**Alessio Soldano**
> Fai la magia.

**Paolo Antinori**
> Crediamo faccia un buon lavoro perchÃ© non abbiamo realmente mai letto il transcrit.

**Alessio Soldano**
> No, beh, guarda, io ne ho letto uno, il primo.

**Stefano Maestri**
> lo dici tu perchÃ© l'ingegnere Alessio non siamo noi, te lo ricordo, Ã¨ lui che poi va a rileggere tutto. Io ero tranquillo quando lui mi ha detto che che andava bene, diciamo che era corretto al 99%.

**Alessio Soldano**
> Eh, l'unico l'unica criticitÃ , secondo me, Ã¨ che a volte se ci sovrapponiamo nel parlare magari qualcosa che dice uno finisce nel testo che ha detto l'altro.

**Stefano Maestri**
> SÃ¬, Ã¨ vero. Questo l'ho notato anch'io, in particolare nella scorsa puntata con Veronica che ringraziamo ancora di essere venuta, ma che bisogna spegnere per farla smettere di parlare e quindi delle volte beh, ma ci piace. Una volta c'era questa sovrapposizione.

## [07:17] Esperimento "LLM Council" di Karpathy

**Stefano Maestri**
> Eh ehm bene, quindi torniamo seri che non lo siamo mai, ma eh allora dico io una cosa, poi lascio parlare Paolo che c'Ã¨ una fila di cose che ci vuole raccontare e dico io una cosa su un esperimento di Carpati che, come ci ha fatto notare un altro ospite Alberto e forse no, credo Stefano ce l'avesse fatto notare la persona piÃ¹ citata di questo podcast, ma di di tutti mondo, vorrei dire. PerchÃ© cosa succede? Scarpati ha fatto questo esperimento in cui mette insieme quattro modelli State of the art, gli fa la stessa domanda, li fa valutare tra loro e sputa fuori eh una risposta che sia bilanciata come la miglior risposta possibile. ed Ã¨ interessante. L'ha chiamato LLM Council, eh, dÃ  un ruolo ad ognuno di loro e vabbÃ¨, prima danno la risposta, poi anonimizzando le risposte chiede a tutti di fare un ranking. Sulla base del ranking un ultimo modello mette insieme una risposta finale.

**Stefano Maestri**
> Allora, poche righe di codice, quattro cinque prompt scritti bene, perÃ² l'ha fatto Carpati e quindi ne parla il mondo. E io ho notato anche questa cosa in questo momento, diciamo che la sua fama precede qualunque cosa lui faccia. Detto questo, Ã¨ interessante da un punto di vista filosofico. Io l'ho preso, c'ho smanettato un po', l'ho provato, l'ho modificato, ho fatto una pull questa a lui per usare i modelli locali, perchÃ© volevo vedere se la sua tesi Ã¨ sono meglio quattro modelli State of the art che uno in buona sostanza, eh perchÃ© comunque tutti hanno delle criticitÃ  de se sono capaci di lavorare tra loro, eh otteniamo una risposta migliore.

**Stefano Maestri**
> Assolutamente vero, lo si vede chiaramente, sia in domande che prevedano un certo tipo di conoscenza, anche spicciola se volete, tipo io gli ho chiesto quanto tempo ci mette un ghepardo per attraversare il ponte piÃ¹ lungo del mondo, che vuol dire che deve sapere che velocitÃ  fa il ghepardo e qual Ã¨ il punto del mondo?. Quali punti esistono? In realtÃ  gli state of the art fanno un lavoro assolutamente piÃ¹ impressionante perchÃ© diciamo non casca la prendono come una domanda tranella in cui tranello in cui non vogliono cascare perchÃ© ho scoperto da loro che il ponte piÃ¹ lungo del mondo sta in Cina ed Ã¨ 164 km. Ovviamente non una singola navata, perÃ² eh Ã¨ 164 km e la risposta di tutti i modelli State of the Art Ã¨: "BenchÃ© il ghepardo possa andare a 110 all'ora, non potrÃ  mai fare 110 all'ora per 164 km perchÃ© muore, anzi deve camminare, anzi deve fermarsi a mangiare, a bere, fanno tutto una pippa" e mi dicono che ci mette giorni in buona sostanza ad attraversare sto ponte e giÃ  quello era abbastanza impressionante, ma anche su domande invece piÃ¹ di costruzione matematica, cose cosÃ¬, lÃ¬ si vede tanto la differenza del council rispetto al modello singolo.

**Stefano Maestri**
> Io ho voluto provare ad estendere questa tesi e chiedermi ok, ma questo effetto qua lo vediamo anche sugli small model. Sapete che io sono leggerissimamente critico ancora sugli small model e rimango critico, nel senso poi dipende quanto small, eh, nel senso io ho usato modelli veramente piccoli perchÃ© per farne girare quattro sulla mia macchina eh serviva roba veramente piccola e al di lÃ  che non sono neanche d'accordo sul fatto che quale sia il ponte piÃ¹ lungo del mondo e vabbÃ¨ questo trattasi di conoscenza, perÃ² PerÃ² tipo ce n'Ã¨ uno adesso, non non mi ricordo quale, forse Quen 2.5 che Ã¨ convinto che che i ghepardi non esistano. CioÃ¨ mi risponde "No, il ghepardo non Ã¨ male che non esiste, quindi assumo che tu intenda il serpente con le macchie da leopardo.".

**Stefano Maestri**
> No, intendo intendo il ghepardo.

**Alessio Soldano**
> Non il prompt l'hai fatto in inglese? No, non in italiano.

**Stefano Maestri**
> I prompt inglese. SÃ¬, sÃ¬. Prova. VabbÃ¨, non c'ho provato anche italiano. Sei modelli cines teatro ho provato anche in italiano e con quelli con quelli piccoli, no, in inglese. VabbÃ¨, comunque al di lÃ  di questo perÃ² l'effetto si vede, cioÃ¨ alla fine la risposta del council Ã¨ comunque meglio del di qualunque delle singole risposte, soprattutto sulle cose un pochino piÃ¹ di ragionamento, matematica, codice, cose cosÃ¬, anche sui modelli piccoli, quindi Ã¨ interessante.

**Alessio Soldano**
> Mi hai fatto venire un dubbio, a parte aggiungere la cosa, come giÃ  ti dicevo, l'elenco delle cose da provare, eh magari sulla mia macchina che forse forse un po' qualcosa un po' piÃ¹ grande della tua riesce a far andare. Eh, probabilmente passando ai modelli piccoli mh cambia molto anche proprio come scegli quei modelli, cioÃ¨ eh visto che la conoscenza sarÃ  necessariamente una frazione della conoscenza totale, uno potrebbe prendere volutamente tipo un modello cinese, un modello francese o un modello americano che magari sa essere trainati su dati completamente differenti e e vedere se si compensano e riescono a fare meglio, veramente meglio.

**Stefano Maestri**
> di quanto sÃ¬ l'estensione di questa cosa che in realtÃ  Ã¨ quella che io vorrei provare Ã¨ ma non so quando avrÃ² il tempo, ma ma Ã¨ nei todista, adesso ci sono le vacanze di Natale, magari qualcosa riesco a fare e provare a fare dei fine tuning sui modelli, cioÃ¨ prendere i quattro modelli, fargli magari un paio di fine tuning specifici specializzandone uno magari piÃ¹ nel ragionamento logico, uno piÃ¹ nel ragionamento matematico, uno piÃ¹ nel codice. e poi fargli una domanda di scrivere un codice che faccia sia il ragionamento logico che quello matematico, vedere se sono capaci a collaborare un po' meglio.

**Alessio Soldano**
> A questa Ã¨ un'idea. Diventa poi tipo un'applicazione d'agente alla fine.

**Stefano Maestri**
> Eh ni sÃ¬ e no. Nel senso che gli agenti di base eh dovrebbero ciclare fino ad ottenere un ad ottenere il gol. CioÃ¨ quella lÃ¬ Ã¨ la mia definizione da gente, qualcosa che con o senza tool, perchÃ© poi i tool sono possono essere un di cui, gli dai un gol specifico, ma eh ma lui continua a fare un ciclo su se stesso fino a quando non raggiunge il gol. Eh, questi no, questa Ã¨ proprio domanda secca, la sottopongo al consiglio.

**Alessio Soldano**
> Consiglio e tiriamole fare una.

**Stefano Maestri**
> Non Ã¨ molto distante da un agente, perÃ² neanche secondo Carpati Ã¨ Ã¨ strettamente un agente. Poi la stessa modellazione la si puÃ² fare in un sistema d'agenti, sono d'accordo, e forse lÃ¬ Ã¨ ancora piÃ¹ interessante. Quello potrebbe essere il passo dopo. potrei provare con uno dei degli dei sistemi ad agenti che voglio provare nel nel nelle vaze di Natale.

**Alessio Soldano**
> Magari prova qualcuno degli ascoltatori, ci fa sapere.

**Stefano Maestri**
> Magari prova qualcuno dagli ascoltatori, ci fa sapere e sarebbe interessante.

## [14:20] Open Router e Deployment Ibrido

**Stefano Maestri**
> Io aggiungo l'ultima cosa su quell'esperimento lÃ¬ di Carpati e poi anche sulla mia estensione che eh che ci sta, perchÃ© la mia estensione fa sia tutto locale che ibrido, quindi due modelli locali e due eh invece state of the art o quello che Ã¨. Come fa Carpati, come faccio io anche nella versione ibrida a chiamare piÃ¹ di un modello State of the Art. Lo nomino perchÃ© magari non tutti lo conoscono e se volete sperimentare Ã¨ molto comodo. Eh, usa Open Router. Open router che cos'Ã¨? Un router di modelli in cui voi eh pagate loro, pagate open router con un caricando un credito. Io ci ho messo $10 per l'ultima volta, per intenderci. E poi eh potete usando lo stesso end, lo stesso indirizzo e quindi lo stesso credito utilizzare eh vari modelli. Loro ne hanno una trentina disponibili, se ricordo bene. E ci sono tutti gli State of the Art principali open source de PS, non deepsek, eccetera.

**Stefano Maestri**
> Ãˆ interessante se volete fare un po' di test, magari state facendo il vostro sistema d'agenti e cosÃ¬ e volete vedere quale con quale modello performate meglio. Ricordo che quando parlo di performance in questo contesto non Ã¨ mai in termini di velocitÃ , ma in termini di bontÃ  del risultato. Ehm, cosÃ¬ interessante. Mettiamo il link in descrizione. non Ã¨ lo sponsor della puntata, purtroppo, ma qualora volessero essere sponsor della puntata ci contatteranno.

**Alessio Soldano**
> cittÃ  ama i risultati.

**Stefano Maestri**
> Eh, Paolo Ã¨ andato a spegnere Alexa. Paolo Paolo se n'Ã¨ andato su questa cosa perchÃ© ha paura del momento Mastrotta.

**Paolo Antinori**
> Ho chiuso Alexa fuori dalla stanza, scusate. Ehm, no, allora devo dire tante cose perchÃ© hai detto tante cose interessanti, ma quella piÃ¹ urgente, prima che me la dimentico, Ã¨ hai detto che hai fatto un deployment ibrido della tua flotta di modelli che perÃ² ha mandato il mio cervello in ha attivato il mio cervello. Tu hai definito ibrido, un mix di small model locali e foundational model remoti, quando laddove io forse avrei definito ibrido un'altra ulteriore via di mezzo, small model locali e small model remoti. Nel senso, ci sta che il tuo computer non ce la faccia a far girare troppi small model, ma non Ã¨ una condizione necessaria al fatto che debbano per forza girare tutti in locale questi small model, quindi no.

**Stefano Maestri**
> No, assolutamente sono d'accordo. SÃ¬, perÃ² la la riflessione Ã¨ quando qualcuno adesso dice un deployment ibrido, quale definisce?.

**Paolo Antinori**
> Quello mix small e large o mix locale remoto? Mix mix locale remoto. Io l'ho sempre sentito in questa accezione.

**Stefano Maestri**
> Poi nella fattispecie nell'esperimento che ho fatto io remoto ho usato Gemini 3, quindi piÃ¹ in alto di cosÃ¬ non potevo andare perÃ² perchÃ© no?.

**Paolo Antinori**
> Puoi usare Mistral, puoi usare loro.

**Stefano Maestri**
> C'hanno tra i piccoli che che mettono c'Ã¨ Lama, c'Ã¨ Quen, no, col piÃ¹ grande 14 forse di Quen hanno eh c'hanno sicuramente Quen, c'hanno Mistral, c'hanno qualche distillato di Deepsic, c'hanno Lama ancora 31 32 33 eh quattro no. ChissÃ  come mai non ce l'ha nessuno. Lama 4 non non ne parla piÃ¹ neanche meta.

**Paolo Antinori**
> Non fare tanti pass.

**Stefano Maestri**
> Ãˆ stato un successo Ã¨ stato un successo strepitoso a me, Lama 4. Eh, ricordiamo che Meta Ã¨ lo sponsor di questa puntata.

## [18:21] Ilya Sutskever e l'Impatto sul Business

**Paolo Antinori**
> Senti, le altre cose che volevo dire sono su Carpati. Innanzitutto Ã¨ il piÃ¹ citato perchÃ© non abbiamo ancora imparato qual Ã¨ il cognome di Ilia l'amico suo e quindi non riusciamo ad a chiamarlo per cognome.

**Stefano Maestri**
> Se volete posso citare a lunghissimo anche Il Sat Skivers.

**Paolo Antinori**
> Ecco quello lÃ¬. Esatto. Eh che molto l'armata delle tenebre. Eh, detto questo, ehm, di Carpati, eh volevo ulteriormente dimostrarmi fan boy, anche se mi non mi piace essere fan boy, ma eh mi riesce sempre a essere elegante nelle sue mosse. Allora, innanzitutto questo esperimento di Carpati, lui l'ha introdotto cosÃ¬ dicendo eh avevo in mente un'idea da un po' di tempo ed ero convinto che ci fosse giÃ  questa del dell'esperimento multi multiouncil con i Large Language Model, ma ho cercato un po' in giro e non c'era. mi sono rimasto stupito. Allora l'ho vi vaccodato, messo insieme, bon fatto via veloce e quindi ho detto "Ah, va che bravo". Quindi non ci sta cercando di vendere che lui Ã¨ piÃ¹ sveglio degli altri. Ãˆ solo che si Ã¨ accorto che c'era aveva un'intuizione, dava per scontato che ci fosse e invece non c'era. Cosa che a me personalmente ricorda molto il mondo dei pated, come sapete, che ogni tanto scopri l'acqua calda e dici "Oh, possibile che l'ho scoperta io?".

**Stefano Maestri**
> Eh, l'hai scoperta tu?.

**Paolo Antinori**
> Ehm, la seconda cosa Ã¨ ehm qua Ã¨ per te, Stefano, che hai detto che gli hai aperto una PR. In quello stesso annuncio Carpati ha detto "L'ho fatta sta roba, era un'intuizione che ho fatto come entrer sul water o qualcosa del genere, l'ho fatta e non la toccherÃ² mai piÃ¹". Quindi ti ha giÃ  frenzonato la tua PR, eh, cioÃ¨ te l'ha detto, ha detto "Non aspettare come la sua e le altre 200 che le hanno aperte, eh?".

**Stefano Maestri**
> SÃ¬, no, ce ne sono una quarantina aperte, ma non Ã¨ ma non era quello il punto per me, era giusto per non pubblicare. Siccome poi l'ho scritto su LinkedIn che ho fatto questo esperimento, ne sto parlando qua, era giusto per non pubblicare il forketto e munger dal suo progetto che non Ã¨ mio stile. Eh, anche su LinkedIn ho detto se volete provarli i locali si fa. C'Ã¨ lÃ¬ la pull scaricatevi da quello. Poi lui non la lui non la mergerÃ  mai e non non me ne non mi interessa nemmeno ecco che la meri. Poi se vuoi possiamo parlare anche della tristezza di alcune polllerai. Questo Ã¨ giusto per esserci in quel gente che fissa ipo di una roba che in realtÃ  poi vai a vedere non Ã¨ nemmeno sbagliato. Ãˆ solo scritto in American English e loro li fissano in British English. Fa niente, cioÃ¨ l'ha detto che non l'avrebbe piÃ¹ cagata. VabbÃ¨, comunque questo Ã¨ il bello e il brutto di di di essere sulla cresta dell'onda come Carpati. La fama, no?.

**Stefano Maestri**
> Volete che vi parli di ILA Sutskever? Io sono diventato un fan boing di ILA. Voglio lavorare per ILA. Non non potrÃ² mai, ma fa niente questo.

**Paolo Antinori**
> Ma allora ci stiamo bruciando tutto il tempo, ma io ti rispondo di sÃ¬ perchÃ© io ho visto la sua recente intervista e non non mi ci sono innamorato, insomma. L'ho trovato un po' pedante, l'ho trovato un po' troppo filosofico, sembrava di stare a messa, non mi Ã¨ piaciuto molto.

**Stefano Maestri**
> SÃ¬, Ã¨ un po' il suo modo di parlare che comunque Ã¨ cosÃ¬. SÃ¬, del del sembr un po' di stare a messa, sÃ¬, ma ripeto, Ã¨ il suo modo di parlare, cioÃ¨ anche nei talk lui Ã¨ cosÃ¬, eh, ma in realtÃ  a me dell'intervista, se devo proprio tirar fuori due punti perchÃ© sennÃ² ci bruciamo davvero tutto il tempo, eh due punti principali, eh Ã¨ uno che dice "Ma possibile che sti modelli State of the Eh, lo diciamo anche per gli ascoltatori. Se leggete sota vuol dire state of the art in questo mondo. Eh, e quindi i modelli di frontiera siano cosÃ¬ bravi a passare i benchmark sempre piÃ¹ eanti eccetera, ma l'impatto sul business dov'Ã¨? C'Ã¨ poco. CioÃ¨, ci sono tanti esperimenti, ci sono tante prof of concept, tutti che chiacchierano di agenti del futuro che sarÃ  solo AI. Ma la veritÃ  dove sta? PerchÃ© in realtÃ  non c'Ã¨ ancora nulla. Eh beh, lui dice una roba interessante su questo, dice, cioÃ¨ i modelli comunque sono trainati per ottenere un risultato, ma la complessitÃ  reale del mondo Ã¨ molto piÃ¹ alta di quella del linguaggio e insiste su un punto su cui insistono alla fine tutti, cioÃ¨ a partire da Demis Assabis in tutte le interviste lo dice, ma anche adesso Open Ai gli investimenti che ha fatto.

**Stefano Maestri**
> Tutti dicono hanno bisogno di un'esperienza reale, un'esperienza reale nel mondo reale allo stesso eh Jan Leun che sapete che sta lasciando meta per fondare una startup e questa startup sarÃ  esattamente su modelli eh che eh vogliono vogliono Real Mode. SÃ¬, sÃ¬. World evoluti, cioÃ¨ con l'esperienza sensoriale tattile. Ian Lecun Ã¨ andato molto oltre. Lui Ã¨ un Ã¨ un ricercatore di base, quindi eh ricordo che Jan Leun Convolutional Neural Network Ã¨ il padre ufficiale delle Convolutional Neural Network, ovvero quelle reti neurali che si usano per fare visione. E lui insiste, come dice anche Ilan nell'intervista, i modelli di linguaggio sono una parte piccola impressionante, ma una parte piccola di quello che costituisce l'intelligenza eh animale, umana, animale prima e umana poi, e quindi bisogna dargli di piÃ¹. Poi dopo ti dico la seconda cosa che mi ha colpito, ma dimmi di questo che hai con stai facendo dire ti sto scuotando il talk perchÃ© m la cosa che hai detto in particolare iniziale su eh va bene i modelli ma fino a se stessi lascia il tempo che trova, bisognerebbe trovare un'applicazione di business mi ha acceso un collegamento con una cosa che ho imparato giusto stamattina ascoltando un altro podcast in cui ehm non so se vi ricordate qualche tempo fa Antropic mi sembra che fosse aveva fatto l'esperimento di far gestire a eh a Cloud una distributore delle macchinette in cui qualcuno l'aveva tipo takeoverato chiedendogli di vendere dei prodotti tipo nucleari o qualcosa del genere ed era stato interessante, perÃ² era un episodio fino a se stesso.

## [24:16] Benchmark delle Vending Machine

**Paolo Antinori**
> Ho scoperto stamattina che qualcuno ha pensato che Ã¨ effettivamente una buona cartina tornasole della qualitÃ  di un modello, la gestione a lunga distanza di un business in forma di vending machine. Dicevano l'osservazione che a livello di dati economici le attivitÃ  piÃ¹ redditizie a vasso rischio sono le lavanderie automatiche e i distributori di macchinette. lo prendo come dato di fatto, non lo so, cioÃ¨ ci credo, perÃ² non ho verificato e quindi qualcuno ha detto "Ma forse dovremmo effettivamente lasciarglielo fare" e quindi hanno definito e standardizzato un benchmark, visto che si parlava di benchmark con Alberto Danese qualche tempo fa sul vending machine e quindi c'Ã¨ questo sito con la leaderboard dei modelli e come si comportano sul tempo e sulla distanza, quanti soldi fanno. Quindi qualcuno questa applicazione pratica dei modelli al business ha addirittura trovato una piccola maniera di esperimento controllato per verificare come si comporterebbe e si chiama vending machine vending bench questa questa cosa per chi fosse curioso.

## [26:06] Transformer, ScalabilitÃ  e Oracle

**Stefano Maestri**
> La seconda cosa invece che mi colpisce dall'intervista di Ilia ed Ã¨ quella che mi colpisce di piÃ¹, Ã¨ la chiarezza in cui spiega perchÃ© i Transformer hanno cosÃ¬ tanto successo nelle big tech e perchÃ© c'Ã¨ cosÃ¬ tanta spinta, perchÃ© danno risultati eccezionali. primo e su questo siamo tutti d'accordo. Lui ne Ã¨ uno dei padri dei Transformer. Ricordo che Ã¨ stato nella team di sviluppo dei Open AI per Chat GPT 3.5 5 e 4, ma eh dice e poi perchÃ© sono un eh elemento di ricerca estremamente innovativo, estremamente di risultato, ma facilissimo da capire, da vendere ai se Level, perchÃ© quello che gli dite Ã¨ tu metti piÃ¹ risorse, avrai un modello migliore, piÃ¹ soldi, modello migliore, facilissimo. ed Ã¨ come funziona il nostro business, cioÃ¨ return of investment facilmente calcolabile, of investment non necessariamente, ma ritorno di risultato facilmente calcolabile per la legge di scalabilitÃ .

**Stefano Maestri**
> E questa roba qui ai se Level eh della Silcon Valley piace da morire perchÃ© sanno che se io investo tot otterrÃ² questo. Poi ci possono essere degli errori eccetera, ma ormai sui Transformer dopo il 2017 sÃ¬, ottimizziamo un po' i meccanismi di attenzione per essere piÃ¹ efficienti, ma non per essere piÃ¹ efficaci, cioÃ¨ tutti gli ottimizzazioni sui meccanismi di attenzione degli ultimi 2 anni di psichi in testa sono per usare meno memoria, per essere piÃ¹ veloci alla fine Ã¨ per essere piÃ¹ veloci e per usare meno risorse, non per essere piÃ¹ efficaci per davvero, nel senso che la sparsa attention Ã¨ ancora efficace tanto quanto gli altri. Certo, consuma un botto, perÃ² e quindi eh dico non c'Ã¨ piÃ¹ ricerca, Ã¨ una ricerca conclusa, quindi io investo, ottengo, perÃ² secondo lui siamo non ancora al plateau dei e Gemini lo dimostra che non c'Ã¨ plateau ancora. perÃ² Ã¨ comincia a piegare la legge la legge di scalabilitÃ  sui Transformer e il Reinforcement Learning sta ritardando questa parte qua, ma comunque stanno rallentando e quindi da qui in poi serve ricerca. Secondo lui, secondo bene o male tutti, serve esperienza nel mondo reale, esperienza di tipo diverso da quella del linguaggio, perchÃ© l'uomo e gli animali non pensano solo col linguaggio.

**Stefano Maestri**
> Poi vabbÃ¨, io vi dico una cosa su cui anche non non sono stato particolarmente eh d'accordo ed Ã¨ che lui dice non si capisce perchÃ© la natura, perchÃ© poi parlano anche di evoluzione come equivalente del pretraining eccetera. VabbÃ¨, dovete ascoltarlo se siete interessati, ma eh lui ad un certo punto dice non c'Ã¨ un'evidenza chiara e Doaresce gli va dietro, non c'Ã¨ un'evidenza chiara del perchÃ© l'evoluzione ci ha portato ad essere eh degli animali sociali e non essere isolati. di questa cosa non c'Ã¨ un'evidenza chiara e si fa fatica a riprodurre sui modelli. Secondo me, oggettivamente, questa Ã¨ una cazzata perchÃ© Ã¨ evidente, perchÃ© siamo siamo degli animali sociali, perchÃ© in gruppo siamo meno attaccabili dai leoni, Ã¨ piÃ¹ facile coltivare eh le cose, cioÃ¨ se vado all'evoluzione, poi dopo dopo lui va avanti e specifica meglio la socialitÃ  a livello dei lavori eh knowledge knowledge work, quindi lavori di di cervello, perÃ² il perchÃ© l'uomo uomo si Ã¨ evoluto come animale sociale Ã¨ per gli altri motivi degli uomini primitivi eccetera eccetera. lo stesso motivo perchÃ© abbiamo il dito ponibile, cioÃ¨ il dito ponibile non ce l'abbiamo per schiacciare meglio lo spazio sulla tastiera, ce l'abbiamo per tutta una serie di altri motivi, poi viene comodo anche sulla tastiera, perÃ² eh, quindi questo Ã¨ velocissimo.

**Stefano Maestri**
> Va bene, tutto questo non era in scaletta, stupendi. Eh, quindi cominciamo il minut 28 cominciamo al minuto 28 a parlare di quello di quello che 28 minuti fa ho detto. Poi lascio la parola a Paolo che c'Ã¨ un sacco di cose da dirci.

**Paolo Antinori**
> Beh, le aveva sÃ¬ ho deciso di rinunciare per che sono piÃ¹ interessato a sentire quello che ci mostrerÃ  invece Alessio. Volevo solo commentare un'unica news breve, eh, che Ã¨ una news di economia e legata a Oracle e in particolare legata al grosso tema. Siamo in una bolla, non siamo in una bolla, chi sÃ¬, chi no. Eh, cerco anche io come altri di cercare di capire, cioÃ¨ al di lÃ  del fatto che probabilmente sÃ¬, lo siamo, eh Ã¨ interessante la conversazione in generale che dice "SÃ¬, Ã¨ una bolla, ma diversa dalle altre per questo per quest'altro motivo". Quindi chissÃ  come si comporta. Riassunto molto breve. Ehm, in realtÃ  la news vera e propria Ã¨ eh che ho letto un articolo del Financial Times in cui ho capito tre o quattro parole e le tre o quattro parole che sono riuscito a capire sono che ehm Oracle da quando a settembre ha annunciato questo investimento di 300 miliardi eh per i data center per Open AI, in realtÃ  ha perso una capitalizzazione di mercato di 60 miliardi eh sulle azioni e qualcuno diceva mh ok, cioÃ¨ ehm Ãˆ interessante questa questa cosa, ma Ã¨ una scommessa un pochettino grossa questa di Oracle e il mercato glielo sta ricordando, gli sta dicendo "Certo, forse riuscite a fare il botto con questa cosa, ma a quanto pare l'orizzonte temporale Ã¨ di almeno 5 anni e per almeno 5 anni loro sono pensati di andare in perdita su queste faccende.".

**Paolo Antinori**
> Qualcuno li faceva i conti in tasca dicendo "Ora non ha lo stesso modello di business degli hypercaler perchÃ© non vendono cloud. eh su scala cosÃ¬ vasta per avere un un free clash flow di cosÃ¬ continuo da poter permettersi di fare di di spendere i soldi in questa maniera. Mh gli auguriamo tutta la fortuna del caso perchÃ© Ã¨ una scommessa a tutti gli effetti. E parlava ho iniziato parlando di bolla. Adesso qualcuno dice mh forse questa mossa di Oracle non aveva le gambe e non lo so, non sono numeri troppo grossi. Io ci capisco fino a quel che ci capisco, perÃ² mi ha fatto prestare un pochettino piÃ¹ attenzione alla faccenda e un pochettino preoccupato s le perturbazioni che il successo il successo di questa iniziativa possono avere.

**Stefano Maestri**
> Eh, ho letto anch'io una roba su quella cosa lÃ¬. Il contraltare di questa roba Ã¨ che perÃ² Oracle di tutte le big tech Ã¨ quella che gira a fattore di moltiplicazione degli utili piÃ¹ bassi. Senza entrare nel troppo nel finanziario, ma per chi ci ascolta, bene o male la capitalizzazione di un'azienda in borsa la si confronta con tanti parametri. Uno dei parametri con cui la si confronta Ã¨ quante volte gli utili vale l'azienda. Quindi io guadagno 1000, valgo 30.000, sto girando 30 volte gli utili. 30 Ã¨ proprio il numero di Oracle. Eh, tanto per dare un'idea. Google gira a 56, eh Open AI Ã¨ stimata 158, eh, che v Ã¨ una follia. 158 Ã¨ una follia. GiÃ  56 e ma giÃ  30 Ã¨ tanto, se ne confronti con l'economia.

**Alessio Soldano**
> GiÃ  30 Ã¨ tanto confronti con le economie normali o magari non americane.

**Stefano Maestri**
> SÃ¬, no, 30 Ã¨ giÃ  tantissimo, perÃ² rispetto a Nvidia che fa 65, eh Google 56, eccetera eccetera, Ã¨ meno della metÃ . Eh, cioÃ¨ se perÃ² lo confronti a General Motors che gira sette volte gli utili, mi pare, cioÃ¨ siamo siamo in fen siamora, il giro sugli utili sembra quello quasi di una bolla, anche se la bolla, la DNET eran tutti sopra i 100 quando sono scoppiati. Eh, adesso vabbÃ¨, questo diventa un po' finanziario e non Ã¨ neanche il nostro la nostra specialitÃ . Ehm, perÃ² ho capito il tuo discorso, anche io sono preoccupato da un punto di vista finanziario. Ribadisco che dal punto di vista tecnologico perÃ² la vedo come le DNET, cioÃ¨ le DNET erano una bolla. Assolutamente sÃ¬. La tecnologia che era internet Ã¨ qui ancora live and kicking, senÃ² non saremmo qua a registrare il podcast.

**Paolo Antinori**
> Esatto. Vai Alessio. Dopo che abbiamo perso metÃ  degli ascoltatori grazie ai nostri rumblings, Ã¨ al tuo turno di riconquistare qualcosa.

## [35:19] Generazione Immagini: Flux 2 vs Z-Image

**Alessio Soldano**
> Assolutamente. Ma allora, eh io in realtÃ  sono un po' di giorni che avevo l'intenzione di farvi vedere alcune cose sulle ultime uscite, le ultime news in ambito a generazioni, immagini e video. Qualche settimana fa ormai Ã¨ uscito Flux 2 Dev. Allora, per chi non non si ricorda, non segue, Ã¨ il modello di M Black Forest.

**Stefano Maestri**
> Black Forest Lab. E no, Stefano, non Ã¨ questo. No, Flax 2. Ho capito che stai parlando. Quello era un tab privato che non dovevi condividere, Stefano.

**Alessio Soldano**
> Eh, Vanagi, no, no. Flux 2. Dev, Flux 2 lo sto cercando. Eh, tu vai avanti a parlare. Ma allora sostanzialmente perchÃ© Ã¨ interessante Flux 2? eh quando a aprile mi sembra eh eh del dell'anno scorso Ã¨ uscito Flux, il primo, eh Ã¨ stato un insomma un qualcosa di mh molto importante perchÃ© era un modello che permetteva di fare di creare in community sviluppi aggiuntivi, fare dei fun tuning, fare dei lora, fare tante belle cose e la gente sostanzialmente ha apprezzato molto Flux, ha avuto un grande successo e un un grande seguito.

**Alessio Soldano**
> il fatto che sei uscito il due, che migliora la qualitÃ  della generazione eccetera, Ã¨ sembrata un'ottima notizia e Ã¨ sembrato anche significativo la joint venture che c'Ã¨ stata tra Black Forest e Nvidia per far sÃ¬ che questo nuovo modello eh girasse sulle schede video, diciamo consumer, se cosÃ¬ le possiamo definire, RTX 5090, eh di Nvidia senza senza particolari problemi perchÃ© sostanzialmente il modello Ã¨ 32 billion e non ci stava di base sul sulla memoria del delle schede Nvidia e quindi ne hanno fatto una versione FP8 eccetera. i benchmark nella nella versione Pro, perchÃ© comunque come il vecchio Flux 1 e sono usciti vari, diciamo, gusti del del modello Ã¨ uscito Dev, Flex Pro Kline, eh che sono rispettivamente quello openwe weight, eh quello professionale, diciamo, che si usa soltanto attraverso Black Forest. Eh, i benchmark della versione Pro sono eh sono meglio di nano banana, del nano banana, perÃ² quello che c'era fino a qualche settimana fa, non il Pro, eh.

**Alessio Soldano**
> Quindi va bene, tutto bene, tutto bello. Interessante anche il fatto che per la parte di ehm vision language, per l'interpretazione del prompt e per l'interpretazione delle immagini che vengono fornite come parametro di input al modello, eh si utilizzi un modello Mistral 3 da 24 billion. Eh quindi migliorie anche sul su quell'aspetto, non proprio soltanto sulla generazione delle immagini. Quindi bellissimo. Ok, abbiamo il nuovo Flux 2. Io l'ho provato, sÃ¬, carino, ma non mi ha impressionato cosÃ¬ tanto, mettiamola cosÃ¬, salvo il fatto che qualche giorno dopo eh un una startup credo del gruppo di Alibaba se ne esce con un nuovo modello che si chiama Z Image, piccolissimo da 6 billion.

**Alessio Soldano**
> Eh, open weight, anche questo eh, velocissimo che genera immagini in decine poche decine di secondi su hardware assolutamente normale e che fa immagini migliori di quelle di Flux, di Flux 2. E il i sorgenti sono disponibili su GitHub, c'Ã¨ giÃ  il modello Shockin Face che si puÃ² scaricare, eh, e possiamo andare a vedere qualche esempio, nel senso che Internet Ã¨ letteralmente impazzita per questo per questo nuovo modello, perchÃ© ribadisco, lo si usa veramente facilmente con eh con hardware accessibile. E allora io ieri sera stavo guardando uno dei vari podcaster che fanno recensioni di di video, recensioni di modelli di generazione immagini e faceva un parallelo tra questo Z Image, tra Flux 2 di cui parlavamo un po' secondi fa e Quen Image che Ã¨ il l'altro modello open weight considerato tra i migliori al momento.

**Stefano Maestri**
> Nella scherm questi sono i tuoi esperimenti. Faccio vedere i tuoi esperimenti.

**Alessio Soldano**
> SÃ¬, sÃ¬. Beh, nella schermata che stai mostrando si vede dove si posiziona rispetto anche ai modelli State of the Art.

**Stefano Maestri**
> SÃ¬. No, e poi ho fatto vedere un po' di immagini generate che erano abbastanza impressionanti, ma vediamo i tuoi esperimenti che sono piÃ¹ significativi.

**Alessio Soldano**
> Secondo me SÃ¬, giusto per evitare di che qualcuno se la prenda male. Gli esperimenti non sono miei, eh sono di un un podcaster che poi magari mettiamo il link in descrizione e che faceva eh questo questo parallelo, questo confronto e guarda di questa immagine forse c'Ã¨ anche quella con le etichette. Comunque io vabbÃ¨, lo so quellao eh, aspetta, eh, cosÃ¬ vedete anche l'ora in verea cui stavo facendo questi screenshot. Eh, esatto. Eh, per dire Z image Flux in mezzo e Quen a destra. Eh, il prompt Ã¨ scritto sotto, eh, una una donna che fa la verticale, eh, con.

**Paolo Antinori**
> Aspetta, Alessio, ti interrompo. L'esercizio per chi arriva adesso Ã¨ tipo gioco d'enigmistica. Trova gli errori, eh, trova gli errori che piace molto, tra l'altro, a chi critica lei ha e dice "Ah, guarda, perchÃ© non genera bene le mani, non genera bene i piedi, non genera bene questo, quell'altro".

**Alessio Soldano**
> Ecco, questi promptore di questo di questo confronto, chiaramente sono tra quelli piÃ¹ critici e e che attualmente, se infatti se escludete le immagini di sinistra, eh ci fanno tenere delle immagini, diciamo, discutibili. Eh, i modelli State of the Art, Gemini 3 Pro, giÃ  ovviamente riescono a generare cose bellissime. Quelli openwe weight eh, diciamo cinesi tendenzialmente ancora non ce la facevano e fino all'altro giorno quando Ã¨ arrivato Z Image. Guardate, guardate, insomma, si commenta da sola parteede e a sinistra Ã¨ molto meglio rispetto alle altre. Abbiamo un'anatomia corretta.

**Paolo Antinori**
> E Alessio, scusami, non ti Ã¨ venuto il dubbio o non c'Ã¨ qualcuno che speculi che cosÃ¬ come imparavo da te, che questo Ã¨ un classico esempio eh di verifica, qualcuno stia barando e insegnando ai modelli a passare i test anzichÃ© a far cose corrette.

**Alessio Soldano**
> possibile possibile, eh, anche perchÃ© questo, ripetiamolo, stiamo parlando di un modello veramente piccolo, 6 billion, eh, perÃ² eh c'Ã¨ anche da dire che questi si posizionano, come dire, facciamo un modello per generazione super realistica, eccetera, principalmente per mh persone e per dopo lo vediamo eh mh grafiche Eh, pubblicitÃ , eh, advertising, comunque adesso ci arriviamo.

**Stefano Maestri**
> 6 billion 6 billion gira anche su una normale Nvidia, tipo la mia.

**Alessio Soldano**
> SÃ¬, sÃ¬, sÃ¬. Comodo anche. Meno di servono meno di 16 GB di RAM.

**Paolo Antinori**
> E fatemi commentare che questa ultima cosa che hai detto del dominio di applicazione che hanno scelto, quindi gli umani e le grafiche, si aggancia di nuovo all'osservazione di Ilia, cognome che dice Stefano, per cui eh bisogna concentrarsi magari un po' di piÃ¹ a fargli f qualcosa di utile a sti modelli, anzichÃ© a bruciare il buco dello zono.

**Alessio Soldano**
> SÃ¬, sÃ¬, sÃ¬. Ma guarda, adesso vediamo un altro paio di esempi. Ãˆ degno degno di nota. Vai. VabbÃ¨, siamo rimasti solo anatomia. Eh, questa Ã¨ volutamente un prompto, dei, di nuovo delle critiche che ci sono a ai modelli e che generano mani con sei dita, eh piedi che non non sono piedi eccetera. E quindi ha beh, quella quella di Quenny Mage non ha fatto dita in piÃ¹ eccetera, ma ha fatto le braccia un filino lunghe, secondo me, nel senso che sono piegate, arrivano all'altezza dei piedi, c'ha degli avambracci spaventosi questa qua. Eh, sÃ¬. O ha dei problemi alle gambe, eh? O ha delle gambe molto corte, sÃ¬, a seconda. Eh, quella in mezzo non Ã¨ male, perÃ² forse un po' plasticosa anche come eh.

**Paolo Antinori**
> Scusatemi, ritiro tutto quello che ho detto precedentemente su far fare cose utili ai modelli.

**Alessio Soldano**
> VabbÃ¨, questo Ã¨ un puro benchmark comunque, eh, perÃ² si nota la naturalezza del dell'immagine di sinistra. Qui invece andiamo su eh generazione di eh No, forse questa te l'ho data tagliata, Stefano, diimmagine, eh generazione di wildlife, mettiamola cosÃ¬. E l'immagine Ã¨ quella fatta da il prompto. Adesso me lo ricordo chiedeva un'immagine fatta con un obiettivo fishai di un animale di cui non ricordo il nome di questa bestia eh nella foresta e Bradipo play o un qualcosa del genere e quella di destra per dire Ã¨ bella di per sÃ© come immagino.

**Paolo Antinori**
> Guarda, si vede l'immagine di destra in alto di Flux.

**Alessio Soldano**
> Ãˆ bella, perÃ² se la vedi piÃ¹ da vicino, come la guardavamo prima, Ã¨ chiaramente artificiale, eh, con quei colori lÃ¬, con insomma e m SÃ¬, bella, va bene per forse una copertina, perÃ² non ti viene da pensare, ok, Ã¨ un'immagine davvero che io ho fatto con la mia camera digitale, ho scattato e mi Ã¨ uscita quella quella di sinistra.

**Stefano Maestri**
> Ah! Eh! Diamine. SÃ¬, anche il pelo sembrano i capelli biondi che mi ero fatto io con la prima versione di.

**Alessio Soldano**
> Eh, sembra un peluche se vuoi. E quella di sinistra Ã¨ tanta roba. Quella sotto eh Ã¨ carina, ma soffre del fatto che, siccome gli ho detto fishai, lui mi ha fatto la la cosa rotonda, come se eh vabbÃ¨, oltre al fatto che di nuovo la qualitÃ  del pelo, mettiamola cosÃ¬, non Ã¨ eh particolarmente degna. Vai next. Vediamo cosa cosa c'era nel Next.

**Stefano Maestri**
> SÃ¬, perÃ² anche quella sotto effettivamente sembra piÃ¹ un cartone animato che un'immagine fottorealistica.

**Alessio Soldano**
> Ecco, qui andiamo. Quello quando dicevamo prima hanno scelto un ambito Ã¨ un ambito al fattorealismo. Allora, eh questa in questo prompt Ã¨ la parte finale del prompt. Il regular angle amator low quality photo. Forse ne parlavamo anche un po' di tempo fa quando dicevo che mi piace mi piaceva. ehm mh crea come modello eh flux crea perchÃ© era capace di fare delle immagini che sembrano vere perchÃ© hanno degli arte delle delle piccole imprecisioni, delle piccole eh sbavature grano nel nel nell'immagine che le fanno sembrare reali fatte da un da una macchina fotografica che non Ã¨ perfetta, eccetera. Ecco, ovviamente nel promptere queste cose. Eh, questi sono i risultati con i tre modelli comparati.

**Stefano Maestri**
> Eh io la prima roba che noto Ã¨ che gli hai chiesto un selfie e in quella di qua in image si vede il telefono che Esatto.

**Alessio Soldano**
> Ad esempio. Eh e questa cosa qua quando si diceva applicazione pratica pensa ai milione di influencer o presunti tali sui vari Instagram eccetera. Con questo vanno vanno nozze, cioÃ¨ abbiamo mioni di influencer digitali inesistenti e che.

**Paolo Antinori**
> un altro ambito d'applicazione potrebbe essere le foto degli UFO anche.

**Alessio Soldano**
> SÃ¬, sÃ¬. La l'immagine dopo Ã¨ un se vuoi, una specie di m benchmark che Ã¨ stato usato quando Ã¨ uscito Gemini. eh si faceva vedere com' era bravo a generare il testo nel nei cartoloni pubblicitari eccetera. Allora, qui secondo me tutte e tre le immagini sono bellissime, eh, i biscottini sembrano sembrano veri e insomma secondo me li compreresti da mangiare. Eh, perÃ² se vedi la differenza, ad esempio, guarda Flux in mezzo, il testo non Ã¨ venuto benissimo. Eh, dove c'Ã¨ scritto Sunday December 15th m a sinistra, a sinistra, insomma, molto meglio il testo. si potrebbe commentare sul fatto che ha fatto la la biscottiera trasparente, che si sa se Ã¨ di vetro, perÃ² eh siamo comunque a livelli che si raggiungevano fino a poco tempo fa, no?. Che neanche con i modelli State of the Art con i PI.

**Paolo Antinori**
> Mi avete dato una visione del futuro di uno store online come magari Amazon, no, ma un AliExpress in cui tutte le immagini saranno generate e non avrai idea di cosa starai comprando e renderÃ  molto divertente l'idea dello shopping online.

**Alessio Soldano**
> Assolutamente. Eh, questo invece Ã¨ interessante per vari motivi. Allora, di nuovo immagine, questi, scusami, sono gli Appstein Files, giusto?.

**Paolo Antinori**
> quelli che ci stai mostrando adesso. Eh, questi, scusa, scusa, non volevo distrarti, perÃ² ho subito pensato a quello.

**Alessio Soldano**
> Di nuovo amator low quality motion blur. Eh, perchÃ© perchÃ© siamo bravi a far generare un'immagine tutta bella, [Â __Â ] impaginata bene da copertina, perÃ² vediamo se riusciamo a generare un'immagine che potreste aver fatto con fotocamera compatta piuttosto che col cellulare di tre generazioni fa e in discoteca e col poca luce eccetera, no?. Eh, quindi da un lato c'Ã¨ quella particolaritÃ  lÃ¬ del prompt, dall'altro il fatto che in questo prompt si chiedono tre persone specifiche, eh, Anatway, Jackie Chan e Messi, eh, che Ã¨ particolare perchÃ© eh richiede al modello di sapere chi sono, quindi un modello da 6 billion non Ã¨ detto che abbia tutta questa conoscenza per eh generare questa roba. che in realtÃ  fa meglio della della concorrenza perchÃ© adesso andiamo a vedere da vicino. Questa Ã¨ Z Image e ho scoperto, tra l'altro contando questo podcaster che lo raccontava che Jackie Chan Ã¨ particolarmente ostico da far generare i modelli e non chiedetemi perchÃ© eh perÃ² vabbÃ¨ direi che c tutti tutte e tre ci sono.

**Paolo Antinori**
> Ã¨ troppo veloce, non si riesce ad avere dei buoni scatti.

**Alessio Soldano**
> Probabilmente la base di training Ã¨ un po' compromessa. Eh, guarda quello dopo Ã¨ questo Ã¨ imbarazzante. Ecco, Messi Ã¨ imbarazzante, nel senso che il calciatore di serie C Messia e Esatto e Jackie Sun sembra quello che faceva Shunsu nel primo Mortal Kombat. Ecco, e questo Ã¨ solo un po' quello di invidia qua.

**Stefano Maestri**
> Quello Chan, secondo me, modello con eh super grande, appena uscito, state of the art per l'open weight di Black Forest.

**Alessio Soldano**
> Ecco qua, questo Ã¨ il risultato. E quello sotto invece Ã¨ il cinese. Qu VabbÃ¨, eh, anche cicciano imbarazzante.

**Stefano Maestri**
> Messi puÃ² richiamare, ma non Ã¨ lui.

**Alessio Soldano**
> SÃ¬. E poi non Ã¨ un'immagine scattata cosÃ¬ live, Ã¨ un sembra quasi un fotomontaggio.

**Stefano Maestri**
> SÃ¬, esatto, vero. Eh, no, questo Ã¨ imbarazzante. Questo non ha capito di chi parlava parlando di Messi, semplicemente, secondo me, eh Ã¨ che non Ã¨ andato a prendere l'informazione.

**Alessio Soldano**
> SÃ¬, nonostante i 34 billion del Mistral messo davanti. Ah, beh, ha messo avanti i Mistral.

**Paolo Antinori**
> Ma eh mi date eh Alessio, ho un compito per te per queste vaanze. Fai l'esperimento di Carpati sui modelli visuali e fagli vedere se si mettendosi d'accordo ottengono un risultato migliore. Eh, chissÃ .

**Alessio Soldano**
> Eh, Ã¨ interessante, perÃ². SÃ¬, sÃ¬, perÃ² ci perchÃ© tra l'altro poi m vabbÃ¨ ci devo pensare perchÃ© c'Ã¨ anche tutto il discorso del dell'interpretazione dell'immagine finale, cioÃ¨ magari un un'immagine non viene capita oltre cioÃ¨ cioÃ¨ la generazione ma anche poi l'interpretazione dell'immagine.

**Paolo Antinori**
> Peraltro, scusami se ti aiuta, volevo darti anche un sample da utilizzare per fare una comparazione. Ok. Aiuto!.

**Stefano Maestri**
> Eh no, perÃ² mi hai dato un gancio prima di farti continuare sui modelli. Lo dico velocissimo, guarda. Prima di farti continuare invece sui video, che c'Ã¨ c'Ã¨ anche roba video, mi sa. SÃ¬. Eh, che hanno messo un Mistral davanti. Allora, Ã¨ uscito il nuovo Mistral Mistral 3, eh, con grandi annunci State of the Artelli Open, eccetera eccetera. Guardate qui, hanno messo tutte le comparazioni facendo vedere che sui benchmark sono leggermente meglio di DeepSek 3.1 eccetera. Peccato che il giorno prima sia uscito Deepsek 3.2 che fa meglio di cosÃ¬ e eh cioÃ¨ io quando ho visto l'annuncio che non hanno nemmeno cambiato e nel frattempo era uscito il modello piÃ¹ avanzato, ho detto boh, cioÃ¨ forse c'Ã¨ un lavoro umano di marketing qui da fare o forse Ã¨ una scelta perchÃ© non potevano dire siamo usciti un giorno dopo e facciamo un pochino meno bene, ma siamo sempre bravi. perÃ² fatto sta notizie sono usciti sia Mistral 3 che Deepsek 3.2. Tutti e due open weight, open source anche nel codice, non nel nei meccanismi di training ovviamente e tutte e due interessanti. Scusa, chiusa parentesi.

**Alessio Soldano**
> No, no, interessante assolutamente. Vedi, almeno quelli di di Flux sono riusciti a uscire qualche giorno prima la concorrenza.

## [54:53] Generazione Video: Runway e Kling

**Alessio Soldano**
> E citavi i video perchÃ© in realtÃ  ci sono anche eh delle news sull lato video, in particolar modo Ã¨ uscito Runaway Gen 4.5. arriva la diapositiva. Yes. Che Ã¨ un modello di generazione video. Allora, noi ne abbiamo parlato la prima volta in modo abbastanza m esteso di Runaway, quando Ã¨ uscito Runaway Alef, che era, almeno a memoria mia, il primo modello che consentiva di fare l'editing dei video con un prompt, cioÃ¨ tu gli dicevi "Ah, questo video cambia questo aspetto", piuttosto che quest'altro aspetto lo faceva. Eh, questo continua a fare questa cosa e perÃ² in realtÃ  questo Gen 4.5 si posiziona come un'evoluzione di Gen 4. Eh, evoluzione di Gen 4. Per cosa?. Per migliorare anche qui, Paolo, come prima, principalmente fotorealismo e fisica dei soggetti. Eh, Ã¨ proprio nella nel loro statement di diciamo cioÃ¨ l'obiettivo Ã¨ controllare le prossime lezioni. Praticamente l'obiettivo Ã¨ fare qualcosa che che sembri davvero un video vero, cioÃ¨ eh non Ã¨ tanto per fare le che ne so generare un cartone animato piuttosto che un eh un qualcosa di m diciamo eh boh, non saprei bene come dire. Il l'obiettivo di nuovo Ã¨ fare qualcosa che sembri reale al 100% e che coinvolga persone di nuovo.

**Paolo Antinori**
> M scusami, mi Ã¨ partito mi Ã¨ partito un pensiero che non c'entra assolutamente niente, ma ho pensato che i cimiteri del futuro assomiglieranno piÃ¹ a un film di Harry Potter che a quelli che siamo abituati noi, probabilmente.

**Alessio Soldano**
> Eh, il rimanendo sempre su Gen 4.5, mh, l'altro aspetto su cui si diciamo si vantano Ã¨ l'aderenza al prompt che sembra essere il migliore addirittura di VO 3.1 o di Sora 2. E anche qui Ã¨ importante perchÃ© magari il video che generi potrÃ  non essere perfetto, perÃ² nel momento in cui fa mostra tutto e solo quello che gli hai chiesto, chiaramente Ã¨ molto piÃ¹ utilizzabile. Eh, si torna al discorso di prima. Loro ricordami Ale una cosa, eh loro hanno anche un world model, quell di Runway?. Eh, mi sembra di sÃ¬, non mi ricordo, devo andare a guardare.

**Stefano Maestri**
> No, perchÃ© era per riguardo alla battuta prima di Paolo, il controllare le prossime elezioni, tra l'altro pillola rossa, pillola blu. Ehm, al di lÃ  del controllo delle masse, che Ã¨ una possibile applicazione, eh ma citavamo la politica americana, no, e il paragone con il piano della bomba atomica sul piano AI, quello Ã¨, diciamo, se qualcosa va un po' storto, il controll un po' tanto storto, eh, meno meno storto Ã¨ potrebbero essere la base dei nuovi videogame, molto ancora piÃ¹ realistici di oggi.

**Alessio Soldano**
> Oggi sÃ¬, c'Ã¨ convergenza tra i due mondi, l'abbiamo detto, sia in un verso che nell'altro, cioÃ¨ anche m fare il videogioco serve anche come base di dati di esperienza per i modelli di generazione.

**Stefano Maestri**
> Eh sÃ¬, poi se se ci sarÃ  meno lavoro saremo tutti piÃ¹ videogiocatori per intrattenerci e genereremo piÃ¹ dati per trainare i robot. Esatto. Fa un po' Matrix questa se vuoi, visto che abbiamo appena visto pillola rossa, pillola blu, non siamo attaccati come batterie, ma ci avviciniamo.

**Paolo Antinori**
> A me mi a me hai fatto venire in mente un po' Ready Player 2.

**Stefano Maestri**
> Ah, sÃ¬, sÃ¬, anche certo.

**Alessio Soldano**
> E anche qui c'Ã¨ il momento cinese, eh, perchÃ© poco dopo l'uscita di Runaway 4.5 5 o in parallelo, non ricordo le date precise, comunque stiamo parlando dagli ultimi 5-10 giorni. Eh, Cling Ã¨ uscito in due nuove versioni. Stiamo parlando di una startup cinese, si chiama Qu, eh, una roba del genere, non mi ricordo piÃ¹ se Ã¨ nel gruppo Alibaba o o quale altro, diciamo, eh in quale altra orbita de dei grandi delle big tech cinesi giri. Eh, comunque giÃ  avevano fatto in passato due modelli video decisamente interessanti come diciamo rapporto qualitÃ  del generato e eh pesantezza e quindi se vuoi i costi nel generare nell'ottenere risultati che erano Cling 16 e 21. Oggi escono eh Cling O1 e Cling 2.6 che hanno due, diciamo, specializzazioni differenti. Eh Cling O1 Ã¨ un multimodale, ma multimodale spinto, nel senso che nel fare il prompt eh testo eh immagini o video anche contemporaneamente. CioÃ¨, fino ad ora noi avevamo che eh tu potevi dire, "Va bene, genera un video a partire da questo da questa immagine che usi come immagine di partenza oppure da queste due immagini che usi come immagine di partenza e di arrivo, eh, oppure solo col testo, oppure beccati questo video, eh, editalo cambiando questi aspetti per dire, quindi video piÃ¹ eh, prompt. Adesso gli si puÃ² dare tutto tutto assieme, immagini, testo e dire, guarda, usa l'immagine per partire, poi a un certo punto il video deve essere tipo questo e eh insomma multimodale puro. E se vuoi Ã¨ un Ã¨ come se fosse un un nano banana pro eh in versione video. e decisamente decisamente una buona una buona evoluzione.

**Alessio Soldano**
> Eh, invece il 2.6 Ã¨, diciamo, la miglioria del 2.1 uno che oltre ad aggiungere di nuovo piÃ¹ fedeltÃ  sul sull'anatomia, sul fotorealismo, eccetera, eh mette per la prima volta l'audio nativo. Allora, per generare video con l'audio, fino ad ora, a parte i modelli tipo di State of the Art, ehm, Vio, Sora, eccetera, quello che si faceva era generare il il video e l'audio con un un modello a parte e poi venivano sostanzialmente messi assieme. Kling 2.6 ha l'audio nativo. Intanto quello che stai facendo vedere, Stefano, Ã¨ un altro prompt tricky, diciamo. Eh, qui praticamente si chiede di fare un video di una ginnasta che fa il volteggio, credo si chiami, la trave. Eh, sÃ¬. Oddio, non so se questo movimento del volteggio o qualcos'altro, comunque un qualche tipo di eh operazione alla trave. di nuovo c'Ã¨ il parallelo tra eh ehm questo modello e quello che esisteva al momento sul mercato dei modelli, diciamo, eh open. E ed Ã¨ interessante come l'anatomia sia corretta, come il il movimento sia naturale, eh non ci sono strani traslazioni sulla trave o eh cose strane e credo che puÃ² interromperÃ² la condivisione. dopo c'erano altri altri confronti, eh no, dicevo dell'audio nativo Ã¨ interessante perchÃ© perchÃ© appunto si puÃ² generare gli effetti gli effetti audio e il il parlato direttamente con questo modello tutto assieme. Eh, si potrebbe ut, quindi tu gli puoi dare il il parlato da testo o parlato da audio?. Parlato da testo, o tutti e due? Con questo credo che tu glielo debba dare come testo, eh, perchÃ© non ha la multimodalitÃ  spinta del dello 1. Eh, ok. Mentre in 1 gli puoi dare anche dell'audio da mettere come sfondo, eh, come sottofondo. SÃ¬, io ho capito cosÃ¬. Non l'ho provato, ma ho capito cosÃ¬. In realtÃ  il sia il 26 che l'1 si possono provare gratuitamente, eh, almeno questo Ã¨ quello che dicono sull'applicazione web che ha appena SÃ¬, quella che avevo aperto prima di O1 permetteva di generare video. Io lo volevo provare ieri sera, ma i server sovraccarichi e non si poteva. Eh sÃ¬, c'Ã¨ quel problema lÃ¬, perchÃ© il mondo vuole provarli e eh no, vabbÃ¨, il commento generale di tutto questo escursus su generazione audio e video Ã¨ eh i cinesi non stanno fermi proprio per nulla.

**Stefano Maestri**
> SÃ¬, sÃ¬, perÃ² e il commento invece Ã¨ leggermente diverso. No, i cinesi non stan fermi per nulla. VabbÃ¨, potremmo parlare di Deepsic 3.2 che Ã¨ un ulteriore passo avanti notevole, cioÃ¨ si posiziona molto vicino Gemini 3, su certe cose addirittura leggermente meglio, su cose meno. Poi bisogna sempre vedere l'utilizzo reale eccetera eccetera eccetera, perÃ² sicuramente eh fa vedere anche, scusate, parentesi su Gemini 3.2 e su Deepsek 3.2, du perÃ² fa vedere che fanno un pochino piÃ¹ fatica e si devono adattare un po' di piÃ¹ ai chip che hanno, perchÃ© a differenza di tutti gli altri modelli che crescono su tutto, come Ã¨ cresciuto su tutto Deepsic 3.2, due, ma anche sulla dimensione della finestra di contesto, quindi memoria disponibile per ogni chip di fatto, eh tipo Gemini ha spinto tantissimo su questo perchÃ© Ã¨ un milione di mil si dice che in realtÃ  non rilasciato ce l'abbiano pronto a cinque eccetera eccetera.

**Stefano Maestri**
> Eh, loro sono fermi e un po' al palo, 128k, se ricordo bene, e su quello sono un po' fermi e questo condiziona molto poi quello che Ã¨ l'utilizzo reale, soprattutto in coding, quindi l'esperienza di coding che si puÃ² avere un po' inferiore sta anche nei modelli cinesi nei 64k8k di contesto, cioÃ¨ quello che ne ha di meno al momento Ã¨ Cloud, che su certe versioni c'ha anche lui un milione. Ma su altre Ã¨ fermo a 200.

**Alessio Soldano**
> Ma gli state of the art occidentali sono tutti piÃ¹ grandi i contesti rispetto ai cinesi, no?.

**Stefano Maestri**
> Invece il commento che avevo piÃ¹ generale Ã¨ tanta evoluzione che vediamo, perÃ² che sia testo, che sia audio e abbiamo una notizia anche su quello, poi prima di chiudere sull'audio, eh, che sia video, che sia immagini, Ã¨ sempre generazione. Non so se siete d'accordo con me, si vede poco al momento di multimodalitÃ  spinta in input. soprattutto nei modelli open, mentre invece eh no, ma c'Ã¨ qualcosa adesso, appunto, eh questa questo coso di O1 eh scusami, non ho capito l'osservazione, Stefano, dicevi generale Stefano dice siamo piÃ¹ indietro sul il lato modelli open weight, siamo piÃ¹ indietro sulla multimodalitÃ  eh in ingresso, se vuoi, nel soprattutto quella in tempo reale, cioÃ¨ tornavo al discorso di Jan Leun, Non l'ho detto, scusate, cioÃ¨ era solo nella mia testa. Jan Le Kun che se ne va e dice: "Non Ã¨ questa la strada. La strada Ã¨ che i modelli devono capire il mondo intorno a loro. CioÃ¨, ci servono dei modelli che capiscono il mondo intorno a loro oltre che il linguaggio. Eh, e sui modelli open eh mi sento di dire che c'Ã¨ poco nulla. Eh, invece come parziale a risposta a quella roba qui c'Ã¨ questo video che io ho visto in settimana che invece ritengo abbastanza impressionante. Aspettate che dietro l'audio. Ah no, lasciamoglielo l'audio che poi lo facciamo sentire. Zumaci un po'.

**[Video Playback]**
> wrench for the drain plug and an oil filter wrench. Yeah, I got the casual 5W40 recommended and the correct oil filter and I have the correct tool for the oil filter housing. Great. You've got everything we need. To get started, let's get the car lifed and access the oil drain plug. Okay. And where is the oil filter? The oil filter is located on the front of the engine right below the intake manifold. It's always a good idea to remove the oil cap before you drain the oil. Ok, great. I'll do that. Okay, up we go. Okay, I got the car up in air. Where is the oil drain plug? That's the plastic panel you'll need to remove. The drain plug is located underneath that panel. There's the panel off and looks like that's the drain plug. What size is that? It looks like a 17 mm drain plug. I'm going to pull it out now. Make sure you have the drain pan in place to catch the oil. Ok.

**Stefano Maestri**
> vabbÃ¨, non voglio farvelo vedere tutto, perÃ² questo Ã¨ un video fatto da un utente che stava facendo una cosa con una macchina, cioÃ¨ non Ã¨ la demo fatta da Google in durante la loro presentazione. Questa Ã¨ un utente che ha preso l'ultimo Gemini sul telefono e si Ã¨ fatto aiutare a cambiare, cioÃ¨ poi lui Ã¨ un meccanico, evidentemente, vista la strumentazione che ha, e sapeva cosa stava facendo, perÃ² un po' come le macchine a guida autonoma, cioÃ¨ se questa Ã¨ la direzione, torniamo al discorso che abbiamo giÃ  fatto tante volte, sia io che Paolo, cioÃ¨ mi pare che ci crediamo, gli occhiali sono prossimamente a faccia.

## [1:10:04] Tesla Full Self Driving in Italia

**Alessio Soldano**
> Beh, senti, hai detto guida autonoma. Vai, chiudiamo, chiudiamo con quella.

**Stefano Maestri**
> A me hai tirato il gancio a Full Self driving di Tesla in Italia da qualche giorno.

**Paolo Antinori**
> SÃ¬, anche in italiano che si capisce. Parlane che io te lo faccio vedere.

**Alessio Soldano**
> Mah, strade strette. Eh, il discorso Ã¨ che chiaramente, beh, qui intanto vediamo un altro podcaster sicuramente piÃ¹ famoso di noi che fa questo video. Guarda mamma, senza mani. Allora, Tesla faceva provare a clienti non il l'ultima versione della guida autonoma che Ã¨ arrivata in Italia, che c'Ã¨ giÃ  in diversi altri stati da un po' e questi questi due podcaster sono andati a fare il la prova e si vede la macchina che appunto che guida da sola. Questa cosa Ã¨ fatta in Italia, dalle parti di Milano, sud di Milano, se se ho visto bene, eh, e la macchina guida da sola. Loro fanno tutti i commenti a come com'Ã¨ andata, come non Ã¨ andata. E adesso adesso un attimo qui credo che giri a sinistra, entri una stradina stretta.

**Stefano Maestri**
> Eh, aspetta che passino le macchine. SÃ¬, poi gira tanta roba. senza neanche particolare esitazione, direi.

**Alessio Soldano**
> Andiamo dove c'Ã¨ la strada stretta che qua ecco, strada stretta non si passa e non si passa assieme. E qui Ã¨ impressionante perchÃ© la macchina deve decidere quando aspettare o quando andare. Eh magari andare avanti pianino pianino. Qui Ã¨, tra parentesi, con le ruote oltre la la riga bianca, quindi non Ã¨ che dici "Ah, usa quella come riferimento, sa dove puÃ² andare, dove non puÃ² andare". CioÃ¨, si deve mettere un po' sull'erba per far passare gli altri. Si ferma, guarda, corregge leggermente, va un pezzettino ancora. CioÃ¨ questa roba qua Ã¨ da paura, onestamente. SÃ¬. Poi adesso qua a un certo punto arriva un camioncino, una macchina qui che continua a farvi passare, ma adesso poco piÃ¹ avanti arriva a un punto dove c'Ã¨ l'altro che si ferma e lei lo capisce la macchina e va dritta, guarda questo ha capito che si Ã¨ fermato ferato e senza esitazione passa lei.

**Stefano Maestri**
> CioÃ¨, questo Ã¨ veramente tantissima roba, considerando che fa tutto con le telecamere, eh, qua su Tesla non ci sono le o altro. qui permet metter sull'angolo. La cosa che vi faceva l'impressione che l'unica appunto che sono riusciti a fare questi al sistema Ã¨ che non evita le buche.

**Alessio Soldano**
> Eh sÃ¬, cioÃ¨ ci rimane solo quello come guidatori di evitare le buche, perchÃ© no?. C'Ã¨ anche la parte in cui suoni clxon quelli davanti e gli fai le corna. Ecco, sÃ¬, sÃ¬, quello Ã¨ importante. Eh, quello Ã¨ importante.

**Stefano Maestri**
> Ah, no, ecco, poi quando Ã¨ arrivato ha parcheggiato in un parcheggio predisabili, perÃ² ma fail. SÃ¬, sÃ¬, sÃ¬.

**Alessio Soldano**
> Quello Ã¨ il big fail dal video. Alla fine parcheggia nel parcheggio disabili. Ãˆ vero, perÃ² parcheggia da solo. Attenzione perchÃ© eh anche questo mica e gli hanno detto, "Guarda, tanto in Italia lo fanno tutti, fallo anche tu". CosÃ¬ gli hanno detto il modello. SÃ¬, probabilmente sÃ¬.

**Stefano Maestri**
> No, perÃ² questa cosa vogliamo dirla noi a Tesla Italia. Noi volevamo fare la stessa cosa e non c'era piÃ¹ posto, ma potete contattarci e riservarci un posto speciale per venire a fare il video e mostrarlo nel nostro podcast, sappiamo.

**Paolo Antinori**
> Oppure potete installare l'aggiornamento sulla macchina di Alessio che giÃ  ce l'ha e facciamo tutto per i fatti nostri.

**Alessio Soldano**
> Ãˆ gratis possibilmente. Ah, gratis. SÃ¬, sÃ¬. E bene. E non so neanche se la mia macchina ha l'hardware giusto, tra l'altro. Devo devo capire. VabbÃ¨, cambia la scheda video della macchina, dai. Nel mondo d'oggi cosÃ¬ funziona, no? Eh, sÃ¬, sÃ¬.

## [1:14:02] IPO Anthropic e Chiusura

**Stefano Maestri**
> Allora, siamo giÃ  allora e 11, quindi dobbiamo 12, eh, quindi dobbiamo chiudere perchÃ© altrimenti Paolo ci sgrida, perchÃ© voi non sapete Paolo ci sgrida tantissimo quando siamo offline, eh, solo perchÃ© gli solo perchÃ© gli facciamo fare le televendite, quindi sarebbe il momento in cui lui dovrebbe dirvi di registrarvi al canale, mettere le stelline, eccetera, ma lo faccio io perchÃ© tanto lui non lo fa. E no, perÃ² chiudiamo su un'ultimissima cosa per chi Ã¨ arrivato fino in fondo ad ascoltarci e poi magari ci torniamo nelle prossime settimane, ma che si lega alla tua prima notizia Paolo dei bolla non bolla che a me ha colpito. Ci sono tante chiacchiere, tante, troppe, quasi certezza ormai, che Antropic voglia andare a fare ipo, cioÃ¨ quotarsi in borsa, eh, entro l'anno prossimo si parla di Q del Q2 2026, cioÃ¨ entro giugno 2026, che boh, mixed feeling, perchÃ© puÃ² voler dire eh ci crediamo tantissimo, ma puÃ² anche voler dire pigliamo il bottino, scappiamo prima prima che scoppi tutto.

**Paolo Antinori**
> Sc ai hai ai posteri l'hardware sentenza o ai nostri ascoltatori nei commenti l'hardua sentenza o se non andremo piÃ¹ onine perchÃ© la bolla Ã¨ scoppiata e il molo sta cadendo e no beh, ma noi andiamo online lo stesso.

**Stefano Maestri**
> La bolla Ã¨ la bolla Ã¨ scoppiata, ma internet finchÃ© internet continua a funzionare noi veniamo qua a parlare di bolle scoppiate, non c'Ã¨ problema. Anche perchÃ© ribadisco, io sono convinto che la tecnologia comunque resti. La tecnologia Ã¨ qua per restare, poi la finanza Ã¨ un altro discorso.

**Paolo Antinori**
> Guarda, io quando prima Alessio stava facendo vedere la carrellata di demo fatti con i modelli video, ho proprio pensato cazzo, per tutte queste puttanate c'Ã¨ bisogno di storage cloud da qualche parte, cioÃ¨ quell'industria non cadrÃ , gli genereremo solo piÃ¹ pattumiera da da realizzare, quindi forse, ma bisogneremmo investire su storage e cloud.

**Stefano Maestri**
> Eh, alla fine sÃ¬, come alla fine Facebook e Compagnia Bella e e tutti i social sono diventati revenue per chi ha fatto storage cloud.

**Alessio Soldano**
> Beh, io leggo in giro che il mercato della produzione delle memorie Ã¨ in crisi perchÃ© ce ne serve talmente tanto, fa fatica starci dietro.

**Stefano Maestri**
> Eh, sÃ¬. Bene, grazie e alla prossima. Ciao. Ciao.