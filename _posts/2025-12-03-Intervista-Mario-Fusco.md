---
title: "Intervista a Mario Fusco: sviluppo software nellâ€™era dellâ€™Intelligenza Artificiale"
categories:
  - Interviste
tags:

  - AI
  - Java
  - Agenti
layout: single
author_profile: true
---


{% include video id="annKzlWVKmM" provider="youtube" %}

ðŸ‘‰ [Ascolta su Spotify](https://open.spotify.com/show/16dTKEEtKkIzhr1JJNMmSF?si=900902f2dca8442e)<br/>
ðŸ‘‰ [Guarda su YouTube](https://www.youtube.com/channel/UCYQgzIby7QHkXBonTWk-2Fg)<br/>
ðŸ‘‰ [Segui su LinkedIn](https://www.linkedin.com/company/risorseartificiali)<br/>

## Into.... (00:00)

## [01:32] INTRODUZIONE E PASSIONE PER LA TECNOLOGIA

**Stefano Maestri**
> Ciao a tutti e tutte, bentornati al nostro appuntamento con le interviste che non chiamiamo interviste artificiali, anche se "Risorse Artificiali" Ã¨ il podcast, perchÃ© ci piace sottolineare che sono interviste super umane. Come al solito, anche se avete letto chi Ã¨ nel titolo, avete visto la foto e probabilmente l'avete giÃ  riconosciuto, io non vi dico subito il nome dell'ospite. Ma prima gli faccio la prima domanda che Ã¨ sempre quella che a me piace di piÃ¹ ed Ã¨: "Qual Ã¨ o qual era il tuo gioco o giocattolo preferito quando eri bambino o adesso?".

**Mario Fusco**
> Allora, se rispondo a questa domanda sembro monotematico, nel senso che sviluppo software da quando ero veramente bambino e probabilmente il mio primo giocattolo preferito Ã¨ stato proprio il mio primo computer. Mi rendo conto che rispondere in questo modo sembra un po' da persona, diciamo, fissata su una sola cosa, perÃ²... ti do il contesto esatto. Il contesto Ã¨ che in realtÃ  il motivo per cui mi sono appassionato a questo campo e faccio questo lavoro Ã¨ che mio papÃ  aveva un negozio di informatica nel nostro paese d'origine a Mondragone nei primissimi anni '80. GiÃ  quello era un po' un outlier per l'epoca. Il mio primo computer nel 1980, avevo 6 anni, Ã¨ stato lo Spectrum ZX80. Non so se qualcuno l'ha mai visto...

**Stefano Maestri**
> Io sÃ¬, perchÃ© avevo la tua etÃ  piÃ¹ o meno.

**Mario Fusco**
> Era un affarino grande cosÃ¬, bianco e nero coi tasti blu e su ogni tasto, oltre alla lettera, c'era anche una keyword del Basic. Quindi praticamente con un tasto funzione piÃ¹ la lettera lui ti scriveva la keyword del linguaggio Basic, quindi insomma appunto era fatto per iniziare a programmare in Basic. All'epoca non aveva nessun supporto di memoria, quindi lo accendevi, scrivevi un po' di codice, lo facevi girare, quando lo spegnevi non c'era piÃ¹ niente, ricominciavi da capo. PerÃ², appunto, sto parlando del 1980.

---

## [04:09] CHI Ãˆ MARIO

**Stefano Maestri**
> Allora va bene, ci ha giÃ  dato anche un altro indizio: Mondragone, l'etÃ  e via. Anche se non l'avete letto nel titolo, avete capito che con noi oggi c'Ã¨ Mario Fusco. Qua di solito io mi fermo e dico introduciti da solo durante le interviste, ma prima di farlo e siccome so che Mario Ã¨ modesto, dico io due parole. Mario, possiamo definirlo facile facile, uno degli sviluppatori piÃ¹ famosi del mondo. Lui non si sarebbe definito cosÃ¬, ma lo definisco cosÃ¬ io: uno speaker seriale, non Ã¨ un frequent speaker, Ã¨ uno speaker seriale, nel senso che dovete stare attenti che non venga a farvi un talk a casa vostra. Ma da sempre si occupa di sistemi enterprise, abbiamo lavorato insieme per tanti anni e stiamo ancora lavorando insieme. E quindi qui sÃ¬, dai, facci tu un'introduzione: da dove arriva tutta questa tua passione per il mondo Enterprise ed in particolare Java?
>
> PerchÃ© un'altra cosa che non ho detto, Mario Ã¨ Java Champion, ha scritto libri su Java, ha fatto numerosi talk, come dicevo prima, ma soprattutto ha contribuito a tantissimi progetti open source che sono diventati di uso comune. Partendo da altri, probabilmente piÃ¹ piccoli che io non ricordo, ma forse il piÃ¹ grande che ricordo per primo Ã¨ Drools, quindi un sistema di regole. Se vogliamo l'intelligenza artificiale prima dell'intelligenza artificiale generativa, quella che...

**Mario Fusco**
> ...quella che viene chiamata Good Old Fashioned Artificial Intelligence.

**Stefano Maestri**
> Esatto. E insomma, e qui arriva invece oggi uno dei principali contributor di LangChain4j e di Quarkus ed in particolare di tutto lo sviluppo ad agenti AI all'interno di LangChain4j. Quindi ti lascio introdurre, ma tienimi a mente questa domanda: Com'Ã¨ che sei partito da un sistema di regole e sei arrivato ad agenti AI? Com'Ã¨ che ci sei arrivato?

**Mario Fusco**
> Sono entrato in Red Hat quasi 15 anni fa e quando sono entrato in realtÃ  sapevo relativamente poco di rule system. Ne avevo implementato uno giocattolo in Scala, ma piÃ¹ che altro per sperimentare col DSL di Scala che non perchÃ© ero bene a conoscenza degli algoritmi interni di un Rule Engine. Ma insomma partendo da lÃ¬ poi mi sono unito al team che sviluppava Drools all'epoca e ho continuato a contribuire a quel progetto fino a diventare il project lead.
>
> Mi sono appassionato a quella tecnologia, agli algoritmi interni che sono alcuni belli complessi, insomma, per cercare di fare le cose in modo piÃ¹ ottimizzato possibile. PerchÃ© lÃ¬, appunto, la sfida Ã¨ cercare di applicare in maniera efficiente migliaia di regole su migliaia di oggetti con delle join anche abbastanza complicate, regole anche temporali eccetera e farlo in maniera efficiente. Quella Ã¨ la sfida, diciamo, algoritmica piÃ¹ impegnativa e divertente.
>
> E quindi sÃ¬, ho lavorato la maggior parte degli anni che ho speso in Red Hat, li ho spesi lavorando su questa tecnologia. Ultimamente ho iniziato un po' a guardarmi in giro e come diceva Stefano mi sono anche iniziato ad appassionare alla nuova AI, perchÃ© quella basata sui motori di regole di cui parlavo prima viene appunto chiamata in letteratura Good Old Fashioned Artificial Intelligence (o GOFAI, se volete cercare l'acronimo).
>
> PerÃ² appunto ho cercato anche poi molto di recente, diciamo nell'ultimo anno, di guardarmi un po' in giro e ovviamente in giro Ã¨ impossibile non sbattere contro la nuova intelligenza artificiale, quella generativa, e quindi ho iniziato a collaborare al progetto LangChain4j, come diceva Stefano. Ho scritto il modulo nuovo di agenti che Ã¨ la cosa su cui sto ancora lavorando in questi giorni.
>
> Quindi diciamo sono passato dalla vecchia intelligenza artificiale alla nuova. Credo che le due cose non siano... che non sia completamente vero che la nuova sostituisce e rende inutile la vecchia, ma credo che in realtÃ  siano due tecnologie complementari per tanti motivi. E quindi uno dei miei sforzi che sto cercando di fare in questi ultimi mesi, in quest'ultimo periodo, Ã¨ dimostrare questa complementarietÃ  e cercare di fare funzionare insieme queste due tecnologie.

---

## [10:11] IL TALK DROOLS VS GENAI

**Stefano Maestri**
> Infatti tu l'anno scorso, correggimi se sbaglio, mi pare fosse l'anno scorso, hai anche fatto un talk, o piÃ¹ di uno, su questa cosa qua, sulla complementarietÃ .

**Mario Fusco**
> SÃ¬, il talk era partito semplicemente da una notizia che avevo letto online da qualche parte. Non so se vi ricordate, ma insomma quello che era successo l'anno scorso Ã¨ che Air Canada aveva avuto un problema con uno dei suoi chatbot, nel senso che questo chatbot chattando con un utente aveva avuto un'allucinazione suggerendo all'utente che avesse il diritto ad un rimborso che in realtÃ  apparentemente non aveva. Il problema Ã¨ che il chatbot ha detto che questo rimborso era dovuto e l'utente ha preso gli screenshot della sua conversazione col chatbot, Ã¨ andato in tribunale, ha chiesto il rimborso e la Corte ha imposto ad Air Canada di dare quel rimborso, anche se appunto non era probabilmente dovuto.
>
> Ovviamente il giorno dopo quel chatbot era offline. E il problema Ã¨ che appunto aveva allucinato su una regola di business di Air Canada e loro si erano un po' troppo fidati.
>
> Sto anche parlando di forse un anno e mezzo fa, credo che nel frattempo le cose siano cambiate un po', le tecnologie attorno siano cambiate un po', perÃ² appunto il mio punto all'epoca che credo sia valido ancora adesso Ã¨ che se hai le tue regole di business codificate, di sicuro le regole per decidere quando un utente ha diritto a un rimborso sono regole di business che Air Canada e qualsiasi altro vettore ha ben codificate, anche perchÃ© deve adeguarsi probabilmente alle leggi nazionali ed internazionali. Non Ã¨ niente che si possono troppo inventare nemmeno loro.
>
> E appunto se queste regole sono ben codificate, sono chiare e trasparenti, non c'Ã¨ nessun motivo per cui debba affidarmi a un'intelligenza artificiale generativa per interpretarle a modo suo e generare risposte che potrebbero essere non corrette.
>
> Ma la mia idea era che in quel caso voglio usare l'intelligenza generativa per avere una conversazione molto umana, user friendly con gli utenti, ma allo stesso tempo voglio che quando c'Ã¨ da applicare delle regole di business che sono chiare e inequivocabili, a quel punto voglio farlo con un software totalmente predicibile come un motore di regole in questo caso, che Ã¨ un ottimo fit per interpretare quelle regole. Ed era questo l'esempietto da cui sono partito.

**Stefano Maestri**
> Che se vuoi ha proprio tutto un filone di pensiero che sta prendendo forma e gambe, se mi consenti, nell'ultimo periodo, da MCP (o Model Context Protocol) se lo vogliamo dire all'inglese in poi, in cui qualcuno, oserei anche tanti, cominciano a dire che in fondo, una delle grandi forze della generativa Ã¨ proprio la capacitÃ  di fare una user interface conversazionale come nuova modalitÃ  di user interface. Poi quando devi fare le cose vere gli attacchi sotto dei tool e quindi un rule engine puÃ² essere un tool alla fine, puoi esporlo come MCP immagino...

**Mario Fusco**
> Assolutamente sÃ¬. Infatti nell'esempietto che avevo fatto all'epoca â€” all'epoca MCP non esisteva nemmeno â€” Drools girava come un tool. Non girava su un server remoto MCP, girava in locale ma per il resto girava esattamente come un tool. Quindi era l'intelligenza artificiale che a un certo punto capiva che non doveva calcolarsi il rimborso da sola, inventarselo, ma utilizzare il motore di regole per calcolarlo. Questo motore di regole era wrappato in un tool e l'intelligenza artificiale chiamava il tool per calcolare il rimborso. Era esattamente la stessa cosa con la possibilitÃ  in piÃ¹ adesso che questo tool potrebbe essere installato remotamente e servito via MCP.

**Stefano Maestri**
> Certo, sÃ¬, sÃ¬, perÃ² il senso Ã¨ quello, cioÃ¨ dare dei tool che facciano cose deterministiche su un'interfaccia utente che puÃ² anche essere indeterministica.

---

## [16:00] I LINGUAGGI DI PROGRAMMAZIONE DINAMICI UN VECCHIO NEMICO

**Stefano Maestri**
> Allora, su questa cosa qui, uscendo un attimino da quello che stiamo dicendo, mi stimoli una mezza provocazione che voglio farti e vedere come ti... Tu scrivi, anzi "pinni" nel tuo profilo X: *"Programming languages don't differ much in what they make possible, but in the kind of mistakes that they make possible"*. Per gli utenti che non masticano l'inglese, che fanno fatica con la mia pronuncia italiana: I linguaggi di programmazione non sono molto diversi per quello che possono fare, ma per gli errori che rendono possibili.
>
> Allora la provocazione che ti faccio Ã¨: la possiamo estendere quella cosa qui anche all'AI? Fa quello che potremmo fare con un linguaggio di programmazione? Fa di piÃ¹, fa di meno, rende possibili piÃ¹ o meno errori?

**Mario Fusco**
> Allora, giusto per essere chiari, il contesto di quella frase che Ã¨ un bel po' vecchia â€” e quando l'ho scritta non c'era ancora la Generative AI come la conosciamo adesso â€” era su un'altra mia vecchia fissazione. Nel senso che a me non piacciono i linguaggi di programmazione dinamici, perchÃ© appunto consentono di fare errori che normalmente non sarebbero nemmeno possibili con un linguaggio staticamente tipizzato. Quindi il contesto di quella frase Ã¨ quello lÃ¬, era un modo per promuovere l'utilizzo di linguaggi staticamente tipizzati.
>
> Per tornare alla tua domanda: sÃ¬, lo scenario ovviamente Ã¨ totalmente cambiato. E forse guarda, adesso che ci sto pensando pure qua il fatto di avere un linguaggio staticamente tipizzato magari aiuta pure quando vogliamo fare il cosiddetto "Vibe Coding". Nel senso che questi strumenti iniziano a funzionare parecchio bene, perÃ² Ã¨ inevitabile che errori ne facciano. Certi errori che fanno: se stai generando Java, te ne accorgi subito, semplicemente perchÃ© Java non compilerebbe proprio. Se stai generando un linguaggio dinamico, probabilmente te ne accorgi solo al runtime che Ã¨ stato commesso un errore. Quindi, nel contesto del Vibe Coding spero che avere linguaggi con un sistema di tipi piÃ¹ forte possa essere piÃ¹ di aiuto.
>
> Poi c'Ã¨ tutto il filone di discussione sul Vibe Coding che io ho iniziato ad usare e funziona, certe volte, sorprendentemente bene. Veramente resto sorpreso, quasi salto dalla sedia dal codice che vedo generare ultimamente. CiÃ² nonostante, errori ne fa ovviamente. Dopo che il codice Ã¨ stato generato, un paio di martellate qualche volta bisogna dargliele. E, appunto, magari se si usa un linguaggio statico forse Ã¨ piÃ¹ facile.

---

## [19:37] AI ASSISTED CODING

**Stefano Maestri**
> Infatti io spezzo una lancia e torno su un tema che tocchiamo spesso â€” io personalmente tocco spesso in podcast e poi anche in newsletter â€” a me non piace tantissimo il termine "Vibe Coding" applicato alle... passa a me il termine... alle cose serie. CioÃ¨ io preferisco chiamarlo "AI Assisted Coding", perchÃ© il Vibe Coding nella mia testa Ã¨: gli do l'istruzione e speriamo che vada tutto bene o poco piÃ¹. Mentre invece quando fai del software di livello enterprise e quant'altro, insomma, devi essere guidato. Questa generazione di codici, un po' quello che dicevi tu, delle martellate.
>
> PerÃ², visto che tocchi il Vibe Coding, ti faccio una domanda che in qualche forma faccio un po' a tutti quelli che masticano di programmazione. E tu sei piÃ¹ che "masticare". Ma allora, io penso spesso che all'inizio c'erano le schede perforate per programmare...

**Mario Fusco**
> C'era ancora qualcuno a casa di schede Hollerit, sono le schede Hollerit della tesi di laurea di mio padre...

**Stefano Maestri**
> Ok, ok. E che manco avevi la tastiera quasi, no? CioÃ¨ erano delle tastiere speciali per fare i buchi e cosÃ¬. Poi siamo passati all'Assembler dove dovevi sapere qual era il registro dove mettere le cose nella memoria eccetera. Da lÃ¬ i primi linguaggi di astrazione piÃ¹ alta, Fortran, Pascal eccetera...

**Mario Fusco**
> SÃ¬, sÃ¬, esatto.

**Stefano Maestri**
> Poi il linguaggio di programmazione ad oggetti e poi se vuoi i functional programming che sono comunque un'astrazione ancora maggiore. E allora la domanda sorge spontanea: Ã¨ il linguaggio naturale il prossimo livello di astrazione? Stiamo sempre piÃ¹ andando in quella direzione lÃ¬ in cui descriviamo il problema e dobbiamo sapere quello che facciamo e leggere quello che genera. Ma boh! CioÃ¨, la vedi questa progressione anche tu o sono io che mi faccio le fantasie?

**Mario Fusco**
> Allora, la vedo ma c'Ã¨ un grosso ponte tra tutte le cose che hai detto prima e l'ultima che hai detto che deve essere in qualche modo attraversato. Nel senso che tutte le cose che hai menzionato, dalle schede Hollerit fino ai linguaggi di programmazione di altissimo livello funzionale eccetera, sono linguaggi formali non ambigui. Questo Ã¨ il fatto. Mentre il linguaggio naturale non Ã¨ un linguaggio formale, non Ã¨ un linguaggio di programmazione per il semplice fatto che i linguaggi di programmazione sono non naturali e quindi intrinsecamente non ambigui, devono essere non ambigui.
>
> Di ambiguitÃ  nei linguaggi naturali ce ne sono fin troppe. Pensa all'uso dei pronomi per esempio: disambiguare un pronome non Ã¨ banale. Errori se ne possono fare, incomprensioni ce ne possono essere. Ecco, questo in un linguaggio di programmazione a qualsiasi livello sia, dalle schede Hollerit fino all'Haskell, non Ã¨ possibile. Quindi la differenza grossa che vedo Ã¨ questa.
>
> E l'altra cosa, collegata a questo, c'Ã¨ una vignetta carina dei disegnatori francesi â€” non so se l'avete mai vista â€” dove c'Ã¨ il CTO probabilmente che dice a uno dei programmatori: "In futuro non ci sarÃ  piÃ¹ bisogno del tuo lavoro, scriverÃ² al computer in maniera assolutamente dettagliata e specifica quello che voglio ottenere e lui me lo farÃ  ottenere". E il programmatore gli dice: "Lo sai come si chiama scrivere tutto in maniera dettagliata, precisa e non ambigua? Programmare".
>
> E quindi sÃ¬, ce lo vedo che il linguaggio naturale sarÃ  il prossimo linguaggio di riprogrammazione. C'era un post su X proprio ieri mi sa, di uno dei principali creatori dei modelli di Anthropic, che diceva che nel futuro â€” lui diceva tra 6 mesi, forse Ã¨ un po' ottimista â€” perÃ² in futuro non controlleremo piÃ¹ il codice generato, cosÃ¬ come adesso quando compiliamo Java non andiamo a controllare il bytecode generato.
>
> Mi sembra che ci puÃ² essere un fondo di veritÃ , perÃ² appunto da prendere un po' con le pinze. A parte la timeline molto aggressiva che non voglio nemmeno discutere, perchÃ© poi fare previsioni su queste robe ho imparato che non Ã¨ il caso di farlo perchÃ© Ã¨ facile sbagliare di ordini di grandezza, sia in positivo che negativi.
>
> A parte questo ci vedo l'analogia: nessuno che compila Java va a leggersi poi il bytecode che Ã¨ generato, si fida che il bytecode Ã¨ stato generato giusto. Ci vedo l'analogia. Io credo che in futuro, anche se questi strumenti funzioneranno sempre meglio â€” e giÃ  ripeto, adesso funzionano in modo sorprendentemente buono â€” ma un'occhiata a quello che generano gliela do e penso di dargliela anche in futuro. Questo Ã¨ il discorso. Ma proprio per il motivo che ti dicevo: la traduzione da Java a bytecode Ã¨ assolutamente deterministica. Certo ci puÃ² essere un bug nel compilatore, prima o poi qualcuno lo troverÃ  e qualcun altro lo fisserÃ , perÃ² Ã¨ totalmente deterministica. La stessa cosa non si puÃ² dire con il Vibe Coding.

**Stefano Maestri**
> No, esatto, questo Ã¨ il punto, l'indeterminismo che va gestito.

---

## [27:00] Ãˆ PIÃ™ IMPORTANTE SAPER LEGGERE CHE SCRIVERE IL CODICE

**Stefano Maestri**
> PerÃ² su questa roba qui che hai appena detto, mi viene un'altra di domanda provocazione. Ma quindi stai dicendo, tra le righe, che sempre di piÃ¹ diventa importante saper leggere, valutare e correggere il codice piÃ¹ ancora che scriverlo da zero?

**Mario Fusco**
> Allora, questo io penso che sia stato sempre cosÃ¬. Adesso ovviamente c'Ã¨ un...

**Stefano Maestri**
> Interessante. Questo che sia sempre stato cosÃ¬ spiegamelo perchÃ© mi piace.

**Mario Fusco**
> Per chi fa il programmatore lo sa: io il 5% del mio tempo lo passo a scrivere codice e l'altro 95% a leggerlo. Non solo il mio, ma quello degli altri. Soprattutto se si lavora in un progetto open source e cosÃ¬. Quando si fa la review di una pull request devi leggere il codice del committer che sta suggerendo la modifica, capire quello che quel codice vuole fare, capire se ci sono margini di miglioramento, cercare di suggerirli in maniera quanto piÃ¹ non ambigua possibile e non Ã¨ sempre facile.
>
> Quindi io anche da prima di leggere il codice generato dalle AI, credo che una grossissima fetta del mio tempo lavorativo sia speso molto di piÃ¹ leggendo codice mio e degli altri che non scrivendone di nuovo. Ãˆ chiaro che l'introduzione del Vibe Coding non fa altro che aumentare questa percentuale. Tutto qua.

**Stefano Maestri**
> PerchÃ© il committer...

**Mario Fusco**
> Esatto, solo per quello. Il committer non Ã¨ un essere umano o Ã¨ parzialmente un essere umano e parzialmente una macchina ad aver generato quel codice. Dal punto di vista mio che devo leggerlo e capirlo probabilmente non cambia nemmeno cosÃ¬ tanto, anche perchÃ© dicevo prima che certe volte il codice che genera l'AI mi fa saltare sulla sedia.
>
> Scusami se divago un attimo, ma quello che mi sorprende di piÃ¹ Ã¨ che quello che mi capita, per esempio, Ã¨ che scrivo la signature di un metodo e se ho dato un nome al metodo ragionevole e i nomi degli argomenti sono ragionevoli, quello che mi fa l'AI Ã¨ generarmi completamente il body di quel metodo. Io lo guardo, quasi sempre corretto, me lo tiro dentro. Non l'ho scritto io, non avrei saputo scriverlo ma di sicuro ho risparmiato tempo facendolo scrivere dall'AI.
>
> Quello che volevo dire Ã¨ che la cosa che ho notato e che mi ha sorpreso di piÃ¹ ultimamente Ã¨ che non solo l'AI genera quel metodo, ma lo stile in cui Ã¨ scritto quel metodo Ã¨ molto vicino al mio stile di programmazione. Scrivere software mi rendo conto che per chi non lo fa di mestiere non Ã¨ facile da capire, ma c'Ã¨ uno stile di scrivere software che Ã¨ molto personale.

**Stefano Maestri**
> Ogni scrittore ha la sua penna alla fine...

**Mario Fusco**
> Esatto. Se io leggo una storia di Stephen King solo dallo stile so che l'ha scritta Stephen King. E la stessa cosa succede per il software. E quello che fa l'AI che mi sorprende Ã¨ non solo scrivere il body di quel metodo, ma scriverlo in maniera molto simile a come l'avrei scritto io, col mio stesso stile di programmazione, perchÃ© lui sta nel contesto di tutto il resto del codice che ho scritto e aggiunge il suo pezzo utilizzando lo stesso stile.
>
> Quindi perchÃ© sto dicendo questo? PerchÃ© quando poi mi capita di leggere il codice degli altri, se Ã¨ stato generato in questo modo, a quel punto Ã¨ quasi veramente indistinguibile capire qual Ã¨ la parte che ha scritto l'essere umano e qual Ã¨ la parte che ha scritto l'intelligenza artificiale. Non ha manco senso porsi la domanda a quel punto lÃ¬. Devo fare la review, leggo il codice e nemmeno mi accorgo se quel codice Ã¨ stato scritto da una macchina o da un essere umano. Faccio la review e basta.

**Stefano Maestri**
> Una cosa che io ho visto succedere â€” stiamo facendo con il mio team â€” Ã¨ che quando arrivano pull request esterne fatte da altri e sono chiaramente fatte con l'AI come tutte, essendo che partono con il contesto dal nostro progetto, Ã¨ paradossale ma sono piÃ¹ simili a come l'avremmo scritto noi di come l'avrebbe fatto un contributor qualunque. Quindi Ã¨ anche quasi piÃ¹ facile fare la review perchÃ© ti ci trovi di piÃ¹, cioÃ¨ seguono il tuo di stile. Se tu sei il main contributor del progetto, bene o male quello che genererÃ  assomiglierÃ  piÃ¹ a quello che scrivi tu che a quello che scrive Tizio Caio.

**Mario Fusco**
> Ãˆ vero, Ã¨ vero, sÃ¬. Non ci avevo pensato in questi termini, perÃ² Ã¨ vero.

**Stefano Maestri**
> E quindi quando hai i contributori esterni sporadici si allineano di piÃ¹, il che non Ã¨ male per chi deve mantenere il progetto alla fine. Sarei curioso ma Ã¨ una cosa che a te capita poco o mai probabilmente, perchÃ© tu giustamente hai detto lavori su un progetto, si prende il tuo stile eccetera. Sarei curioso di chiederti invece su un progetto Greenfield, quindi che parte da zero, scritto con l'AI, un giudizio sullo stile dell'AI. PerÃ² probabilmente non ti Ã¨ mai capitato in questi ultimi mesi.

**Mario Fusco**
> Allora, onestamente no. Nel senso che ancora non ho fatto quel passo in piÃ¹ di farmi startuppare il progetto dall'AI o farmelo scrivere da zero dall'AI.

**Stefano Maestri**
> Sai, progetto che parte da zero, non conosce ancora il tuo stile. Ero curioso, siccome so che Mario scrive molto bene, permettimi, hai uno stile marcato nello scrivere il codice. Come dicevi prima Stephen King, cioÃ¨, di nuovo, chi non Ã¨ nel nostro mondo fa fatica a capire questa cosa, sembriamo matti a fare questo discorso, probabilmente la maggior parte. PerÃ² se io leggo un pezzo di codice che ha scritto Mario, vi giuro che sono in grado di dire l'ha scritto Mario piuttosto che l'ha scritto un altro nostro collega. Mi incuriosiva un tuo giudizio su stili diversi ma chiaramente non hai avuto occasioni.

**Mario Fusco**
> No, la veritÃ  Ã¨ sÃ¬, ma piÃ¹ che altro il modo con cui uso questo strumento Ã¨ ancora quello che ti dicevo: lo uso come aiuto interno nell'IDE. Mentre scrivo codice mi dÃ  un pezzettino di autocompletamento, ma non sono mai andato allo step successivo di dire "anche all'interno di un progetto non greenfield devo implementare questa feature, implementamela tu e poi dopo la metto a posto io se serve". Insomma su questo passo devo ammettere che ancora non l'ho fatto. Cerco sempre di dare io la forma iniziale alla cosa che sto facendo e poi mi faccio aiutare, ma piÃ¹ che altro per risparmiare tempo, per generare i dettagli implementativi. La forma cerco sempre di tenerla io. Potrei provare a fare questo passo successivo, ancora non l'ho fatto quindi non ho tanto feedback da darti su questo.

---

## [35:30] AI NELL'ENTERPRISE... MEGLIO JAVA

**Stefano Maestri**
> No, torniamo invece ad un altro tema che hai toccato prima e che ci porta a... secondo me significativa. Hai parlato prima di linguaggi dinamici versus linguaggi statici, quindi Java, eccetera, e cito una cosa che c'era nelle tue slide di uno degli ultimi talk tuoi che ho sentito in cui chiedevi: *"Do you really want to do transaction, security, scalability in Python?"*. CioÃ¨ volete fare le cose complicate, enterprise, veramente in Python? Il non detto di questa frase, ma che c'Ã¨ poi in tutte le slide, Ã¨ una... quello che io ho chiamato una difesa pragmatica di Java anche nel mondo dell'AI. Carta bianca per spiegarci perchÃ©, come, dove.

**Mario Fusco**
> SÃ¬, allora pure qui magari vale la pena di dare un po' piÃ¹ di contesto. Il mio punto Ã¨ che questi nuovi sistemi che usano le AI generative hanno poco senso, a meno che non sto facendo chatbot di ChatGPT o di qualche altro provider simile. Ma se lo voglio inserire in un contesto piÃ¹ ampio di un'applicazione Enterprise â€” che appunto come dicevi prima magari usa qualche tool MCP per leggere e scrivere dal database o per fare altre operazioni o per mandare email â€” se voglio integrare questi sistemi con un software Enterprise, ancora adesso e per un motivo valido io credo che la stragrande maggioranza di questi tipi di software girano in un modo o nell'altro sulla Java Virtual Machine. Magari adesso non sono scritti tutti in Java. Kotlin vedo che sta prendendo sempre piÃ¹ piede (prima c'era Scala che adesso mi sembra che sia un po' piÃ¹ messo da parte ultimamente, ma magari mi sbaglio). PerÃ² insomma la stragrande maggioranza di questi software usati dalle aziende sono scritti in Java o in linguaggi che girano sulla Java Virtual Machine.
>
> E il mio punto era che voglio integrare questa nuova tecnologia con tutta la code base che ho giÃ  e per farlo perchÃ© non farlo ancora in Java, insomma? Ãˆ la cosa piÃ¹ semplice.
>
> L'altra cosa che mi rendo conto potrebbe essere piÃ¹ discutibile, perÃ²... essendo *strongly opinionated* come al solito su tante cose, inquadriamo pure questo: ho l'impressione che certe nuove tecnologie in questo campo arrivano piÃ¹ dal campo dei Data Scientist e quindi piÃ¹ dal campo del tipico programmatore Python, piuttosto che dal campo Enterprise e quindi dal campo del tipico programmatore Java. Mi rendo conto che giÃ  dicendo questo sto facendo una grossa generalizzazione. Ho l'impressione che alcune di quelle cose risentono del fatto che arrivano dal mondo dei data scientist.
>
> Lo stesso MCP di cui parlavi prima, che Ã¨ stato pensato da quel mondo lÃ¬: perÃ² quando Ã¨ iniziato, quando Ã¨ stato pensato non c'era â€” correggimi se sbaglio â€” dentro nessun concetto di authorization per chiamare un certo tool, di sicurezza. PerchÃ©? PerchÃ© tutti quei concetti vivono, sono scontati nel mondo enterprise. Io non inizierei mai a scrivere un nuovo pezzo di software che gira su un server remoto ed Ã¨ supposto di essere chiamato da altri servizi esterni senza pensare: "Ok, questo affare gira su un server remoto, come faccio ad autenticare gli utenti? A capire che livelli di autorizzazione hanno? Come faccio a implementare la sicurezza, la transazionalitÃ  se serve?".
>
> Sono le prime domande che un ingegnere che lavora nel mondo dell'enterprise si fa. Una persona che lavora piÃ¹ sulla generazione dei modelli, sulla parte matematica, sulla parte algoritmica e basta, queste domande all'inizio non se le fa. E il risultato mi pare evidente insomma: e adesso stiamo combattendo per far rientrare dalla finestra queste cose che servono pure su un server MCP. Ce le stiamo costruendo sopra, attorno, ma MCP non Ã¨ stato pensato con quelle esigenze di appunto... perchÃ© secondo me viene da un mondo dove il mindset delle persone che ci lavorano dentro Ã¨ un po' diverso.

**Stefano Maestri**
> SÃ¬, sÃ¬, proprio un problema di mindset che tu tra l'altro condensavi bene, se ricordo bene, in quel talk che citavo. Poi tutti questi talk, lo dico per chi ci ascolta: mettiamo tutti i link in descrizione, potete andare ad ascoltarveli perchÃ© sono tutti disponibili su YouTube. Quelli di cui stiamo parlando sono quelli piÃ¹ recenti che Mario ha fatto al Devoxx, grande conferenza Java in Belgio. E magari se vi va di andare ad ascoltarli, almeno avete tutto il contesto, perchÃ© chiaramente qui distiliamo qualche concetto, ma magari ci perdiamo dei pezzi di contesto, anche se Mario Ã¨ bravo a riportarceli.
>
> PerÃ² tornando a quello che dicevi, il mindset... che un conto Ã¨ fare l'esperimento, il proof of concept eccetera, e un conto poi Ã¨ farci girare il sistema di Air Canada che non deve dare indietro soldi a caso o peggio, o cose anche piÃ¹ mission critical di un sistema che dÃ  indietro un biglietto.

---

## [41:13] L'INFERENZA DEI MODELLI IN JAVA

**Stefano Maestri**
> Allora, perÃ² su questa cosa qui, perchÃ© allora in questo mondo sono visti vari esperimenti â€” anche tu in passato ne hai fatti credo â€” di vari punti dove integrare diciamo gli LLM o comunque le AI. E adesso sei molto concentrato â€” e poi ci arriviamo, ne parliamo piÃ¹ diffusamente â€” su quello che Ã¨ diciamo la parte agentica, quindi il mettere un po' insieme i due mondi se mi consenti.
>
> PerÃ² in passato hai sperimentato anche fare inferenza di modelli dentro a Java, giusto? Rispetto agli esperimenti che hai fatto, vedi ancora che ci sia uno spazio per questa cosa qui? Come sono andati gli esperimenti? Son curioso perchÃ© poi non ne abbiamo mai piÃ¹ parlato neanche noi.

**Mario Fusco**
> Hai ragione. Allora, il passo successivo che ho provato a fare un po' di tempo fa Ã¨ che il software che utilizzo e che sviluppo tipicamente si connette a dei server esterni dove girano i modelli che io utilizzo. Questi server esterni possono essere di terze parti (esempio OpenAI GPT, Anthropic, Gemini ecc.) o l'altra cosa molto tipica che succede, o che almeno io ho provato a fare diverse volte, Ã¨ che mi piace avere dei modelli anche ovviamente piÃ¹ piccoli di quelli che nominavo, ma che mi girano in locale.
>
> Tipicamente questi modelli, un modo molto comodo per farli servire in locale Ã¨ usando Ollama, ma pure lÃ¬ quando girano in locale girano su questo server Ollama e quello che fai con Ollama Ã¨ comunque interfacciarti via HTTP. Stai comunque facendo una chiamata HTTP, la stai facendo sulla tua macchina locale non andando su un server remoto, ma stai comunque andando via HTTP.
>
> L'idea era invece quella di avere tutto nello stesso processo, nella stessa Java Virtual Machine, incluso l'inferenza dei modelli. Quindi c'ho il mio server Quarkus che parte e dentro c'Ã¨ un pezzo che non fa affidamento su nessun altro servizio esterno, ma anche l'inferenza del modello gira all'interno di quel processo.
>
> I primi esperimenti che ho fatto su questa idea usano e usavano una libreria molto carina, molto fatta bene che si chiama Jlama. Jlama appunto Ã¨ basata sulla nuova Vector API per utilizzare appunto la capacitÃ  dei processori nuovi di fare calcoli vettoriali. PerÃ² il limite di quella tecnologia Ã¨ che ancora non riesce a fare uso invece delle GPU e quindi, come puoi capire, ci sono limiti nella dimensione dei modelli che puoi usare. Se inizi a usare modelli relativamente grossi, non potendo utilizzare una GPU, diventa esasperantemente lento, insomma diventa non piÃ¹ utilizzabile.
>
> Un'altra possibilitÃ , un'altra tecnologia invece molto interessante sulla stessa idea, ma che stavolta riesce anche ad utilizzare le GPU, Ã¨ TornadoVM, su quella sto sperimentando in questi giorni. Con TornadoVM riesci ad ottenere lo stesso risultato che dicevo prima, ovvero avere l'inference che gira direttamente sulla Virtual Machine, e TornadoVM â€” che Ã¨ una tecnologia che viene sviluppata principalmente all'UniversitÃ  di Manchester â€” riesce anche a fare uso della GPU.
>
> I motivi per fare questa cosa qua, cioÃ¨ perchÃ© dovrei far girare l'inferenza in locale sulla Java Virtual Machine invece che fare affidamento su un servizio esterno? Ce ne sono un po', secondo me, tutti abbastanza discutibili. Eppure qua questo Ã¨ un moving target, quindi le cose che dico probabilmente erano piÃ¹ vere 6 mesi fa o un anno fa rispetto ad adesso e probabilmente non so se saranno vere ancora in futuro.
>
> Ma insomma Ã¨ piÃ¹ facile di sicuro in fase prototipale, in fase di testing pure, avere tutto incluso nello stesso processo. Tiro su una sola cosa, gira quella, gira tutto lÃ¬ dentro e quindi Ã¨ molto piÃ¹ facile se non altro in campo prototipale, di sviluppo e di testing.
>
> Altre cose potrebbero riguardare probabilmente la sicurezza, nel senso che invece di girare su un servizio esterno l'inferenza mi gira in locale e quindi ho tutto sullo stesso processo, non sto andando su un servizio esterno e non sto mandando cose in giro, anche informazioni in giro che potrebbero essere sensibili per il business e quindi questo Ã¨ un altro possibile vantaggio.
>
> Poi, ripeto, questi strumenti devono essere pure, diciamo, efficienti dal punto di vista computazionale e adesso ancora in Java non Ã¨ cosÃ¬ banale arrivare a quel punto lÃ¬.

**Stefano Maestri**
> Ok.

**Mario Fusco**
> E quindi la situazione Ã¨ questa, Ã¨ una possibilitÃ  molto interessante. Ci vedo delle... dei vantaggi. Per adesso ancora diciamo che certi vantaggi superano i possibili vantaggi, ecco.

---

## [49:52] LANGCHAIN4J E GLI AGENTI IN JAVA

**Stefano Maestri**
> Prima di muoverci sul prossimo argomento che come dicevo sono gli agenti e che sono molto interessanti, ma forse di nuovo qua potrebbe esserci un problema di mindset perchÃ© manutenere ed efficientare l'inferenza di un modello ha bisogno di un mindset completamente diverso da quello dal programmatore, piÃ¹ da amministratore di sistema. Quindi per la produzione potrebbe essere complicato, perÃ² capisco tutti gli altri esempi che hai fatto di test, prototipizzazione eccetera.
>
> Ma parliamo di agenti che Ã¨ il tuo focus principale. Di agenti in Java, agenti scritti all'interno della libreria che si chiama LangChain4j, da non confondere con LangChain e basta, nel senso che "4j" perchÃ© Ã¨ per Java, ma ci sono anche differenze filosofiche rispetto a LangChain. Non Ã¨ un porting di LangChain su Java, questo ci tengo a sottolinearlo.
>
> E poi c'Ã¨ tutto il lavoro che hai fatto sugli agenti che mi interessa molto perchÃ©, guarda, io parto solo con un'altra tua citazione di una cosa che dici da qualche parte, forse in un articolo...

**Mario Fusco**
> SÃ¬, un articolo che ho scritto un paio di settimane fa.

**Stefano Maestri**
> ...che dici che *one size doesn't fit all*, cioÃ¨ non c'Ã¨ una taglia che va bene per tutto per gli agenti e parlavi di pattern eccetera. Raccontaci un po' sta cosa, dai.

**Mario Fusco**
> SÃ¬. Allora, prima faccio, se mi consenti, una piccola premessa su LangChain4j come nome, perchÃ© ho notato pure partecipando a qualche conferenza in giro che c'Ã¨ un po' di misunderstanding e devo ammettere che col senno di poi credo che la scelta del nome sia stata un po' sfortunata. Nel senso che quando Ã¨ partito il progetto appunto c'era LangChain in Python e l'idea Ã¨: "Ok questa cosa si puÃ² fare in Python, perchÃ© non farla pure in Java?". Faccio LangChain4j, ovvero il LangChain for J che Ã¨ scritto in Java che gira sulla Java Virtual Machine, e l'idea del nome ovviamente Ã¨ partita da lÃ¬.
>
> Poi perÃ² quello che Ã¨ successo Ã¨ che Ã¨ stata solo l'idea, Ã¨ stato solo il punto di partenza, ma poi le due tecnologie hanno preso strade completamente diverse. Uno dettate ovviamente dal linguaggio utilizzato, certe cose che si possono fare in Python in Java non si possono fare e viceversa, i costrutti idiomatici di un linguaggio sono totalmente differenti dall'altro, quindi per forza di cose le due tecnologie hanno preso strade diverse. Ma poi hanno preso strade diverse anche dal punto di vista proprio di disponibilitÃ  di features, consentimi anche dal punto di vista forse filosofico o di idea generale di come vengono sviluppate.
>
> Quindi appunto c'Ã¨ rimasto attaccato questo nome LangChain4j. PerÃ² chi lo usa deve essere cosciente che Ã¨ una cosa totalmente scorrelata da LangChain in Python e per quello che posso vedere ultimamente Ã¨ molto piÃ¹ ricco di feature LangChain4j che non la libreria Python. Quindi veramente le due cose sono indipendenti.
>
> Fatta questa doverosa premessa, come dicevi, ho iniziato a guardare un po' questo mondo degli agenti. Per me il trigger, uno dei trigger delle motivazioni principali che mi hanno spinto a lavorarci su, Ã¨ anche collegata al fatto che dicevo prima che spesso mi piace usare dei modelli relativamente piccoli per cui posso far girare l'inferenza in locale dentro alla stessa Java Virtual Machine, ma piÃ¹ solitamente usando Ollama ultimamente a dire la veritÃ .
>
> Ma insomma di usare modelli in locale, e quindi usandoli in locale devono essere necessariamente non enormi come quelli che usate quando vi connettete a servizi remoti. E quindi avendo questi modelli piÃ¹ piccoli, perÃ² chiaramente le capacitÃ  di generalizzazione di questi modelli piÃ¹ piccoli sono un po' piÃ¹ limitate e quindi quello che piÃ¹ tipicamente succede Ã¨ che abbiamo dei modelli piccoli, magari specializzati su a fare una certa cosa, a soddisfare un certo bisogno.
>
> E perÃ² a quel punto, invece di usare un modello solo enorme, generico, ne uso un certo numero di modelli piÃ¹ piccolini e poi perÃ² ho il problema di farli cooperare, di metterli insieme, di farli lavorare come se fossero un unico grosso modello con vantaggio che sono molto piÃ¹ piccoli e quindi possono girare sulla mia macchina. Non spendo soldi per pagare le API di chat GPT o comunque insomma sono molto piÃ¹ economici in generale, insomma, che Ã¨ un altro vantaggio.
>
> Quindi l'idea Ã¨ che invece di avere un modello enorme unico, ne ho *n* piÃ¹ piccolini e poi ho il problema di farli cooperare. L'idea degli agenti Ã¨ nata da questa situazione. In realtÃ , poi guardandoci bene mi sono reso conto che le cose funzionano meglio sia usando modelli grossi che modelli piccoli, nel senso che ragionare ad agenti, ragionare a task ti costringe comunque a suddividere il problema in sottoparti. E facendo questa suddivisione, suddividendo il problema in parti piÃ¹ piccoli, aiuti l'LLM, aiuti l'AI generativa a svolgere queste parti piÃ¹ piccole in maniera piÃ¹ corretta a prescindere se stai usando un modello grosso o un modello piccolo.
>
> Quindi questo Ã¨ un altro vantaggio di passare a questa architettura d'agenti. Come dicevo, passare a questo modello d'agente perÃ² pone dei problemi che ho cercato di e sto cercando di codificare e risolvere in questo nuovo modulo di LangChain4j che si chiama LangChain4j Agentic. L'idea, appunto, Ã¨ che questi agenti dovendo cooperare per l'esecuzione di un macrotask, devono in qualche modo parlarsi fra di loro, condividere lo stato, condividere il contesto che in certi casi Ã¨ ancora piÃ¹ complicato ma anche importante. E quindi se date uno sguardo a questa libreria di cui vi sto parlando, su cui sto lavorando, vedrete che ci sono dei costrutti che vanno in questa direzione.

---

## [58:25] AGENTI E FUNCTIONAL PROGRAMMING: UN PARALLELO

**Stefano Maestri**
> Quindi mi interessa molto questa cosa che hai detto. Mi metto un attimo nei panni o nelle scarpe, per dirlo all'inglese, del tuo utilizzatore, cioÃ¨ quello che arriva, si prende Langchain4j agenti che comincia a sviluppare. Hai sottolineato bene che Ã¨ un cambio di nuovo di mindset, di modo di lavorare.
>
> Vista anche la tua esperienze precedenti, LambdaJ e poi tutta la parte functional programming eccetera, ci vedi dei paralleli nel pensare ad agenti e nel pensare per funzioni o sono fuori strada?

**Mario Fusco**
> No, ci sono sicuramente dei paralleli, insomma. Il parallelo interessante Ã¨ quello che a cui accennavo prima, insomma, la programmazione funzionale e questo paradigmi ad agenti sono guidati dalla stessa idea di base che poi per dirla chiaramente Ã¨ il *Divide et Impera*, insomma. Invece di descrivere un task enorme, la prima cosa che faccio Ã¨ lo suddivido in sottotask piÃ¹ piccoli e poi dopo cerco di risolvere questi problemi piÃ¹ piccoli e piÃ¹ maneggiabili in maniera uno per uno, insomma, e poi di mettere le cose insieme.
>
> Questo Ã¨ quello che si fa in programmazione funzionale. Quando si dice che una funzione deve avere un solo compito, deve essere lunga idealmente due tre righe di codice, non di piÃ¹ e quindi e poi quello che ti dÃ  la programmazione funzionale sono le primitive per comporre le funzioni, quindi per fare il MAP, il flat map e tutte quelle parolacce di programmazione funzionale. Quello che vogliamo dare con questo modulo ad agenti Ã¨ esattamente lo stesso, avere la consentimi componibilitÃ  di questi agenti di modo da farli da da avere dei degli agenti molto specializzati per fare certe cose e poi la possibilitÃ  di metterli insieme. Il parallelo quindi su questo ce lo vedo di sicuro.
>
> Quello su cui poi queste cose divergono invece Ã¨ quello che raccontavo prima che Ã¨ la parte di non determinismo, quello parzialmente resta e c'Ã¨ poco da fare lÃ¬. Per esempio, il cambio di mindset che Ã¨ richiesto in questo caso ed Ã¨ una cosa su cui mi scontro giorno per giorno Ã¨: come faccio a testare una cosa che non Ã¨ deterministica? E ed Ã¨ quello forse il cambio di paradigma piÃ¹ grosso che personalmente ho visto, ma che vedo anche in altri, quando si passa verso questi software basati sulle AI generativa, il testing Ã¨ un problema grosso.
>
> Giusto per raccontarne una, mentre lavoravo al mio modulo ad agenti ho mandato una pull request. Questa pull request rompeva un test che perÃ² era in un'area totalmente indipendente. Era evidente che il test che si rompeva era totalmente scorrelato dal lavoro che avevo fatto e questo test in realtÃ  quello che faceva era mandare a un LLM l'immagine di un gatto e nell'asserzione del test c'era scritto che la domanda all'LLM era "cosa vedi in questa immagine?" e l'asserzione era che la risposta doveva contenere la parola *Cat*. Il test falliva perchÃ© a un certo punto l'LLM si Ã¨ messe a rispondere: "I see an animal with a feline appearance" che ovviamente la parola *cat* non ce l'ha e quindi il test falliva per quello. E lÃ¬ il problema Ã¨ quello lÃ¬ insomma che bisogna cambiare il mindset: dire questo LLM deve rispondere con una frase che contiene la parola gatto, altrimenti il test Ã¨ fallito e purtroppo non Ã¨ piÃ¹...

**Stefano Maestri**
> Eh no, certo. CioÃ¨ proprio perchÃ© si ha a che fare con un sistema statistico e quindi anche i test devono essere di tipo statistico alla fine o se preferisci, nel tuo esempio, siccome hai a che fare con un sistema da linguaggio naturale, i test devono guardare il linguaggio naturale, quindi vabbÃ¨ gli embedding eccetera eccetera.

---

## [01:03:31] LA COMMUNITY E IL SERIAL SPEAKER

**Stefano Maestri**
> Allora, devo dire che ci dicono spesso, cioÃ¨ no, spesso qualche commento che riceviamo nelle puntate normali Ã¨: "bello, interessante, a volte siete troppo nerd". Diciamo che oggi ci abbiamo dato su questa cosa qua e ci siamo.

**Mario Fusco**
> Ma io ne sono felicissimo, io sono il paladino del nerdismo di questo podcast, quindi va bene.

**Stefano Maestri**
> Diciamo che l'argomento ci guida in quella direzione lÃ¬. Ma io adesso provo a portarci fuori un secondo e nel portarti fuori ti chiedo la parte della community. Allora, nel senso che adesso lasciamoci un attimo alle spalle tutto quello che Ã¨ AI... Dicevo all'inizio che tu sei uno speaker seriale, come mi piace definirti, ma non solo quello, ovviamente. Paladino dell'Open Source, lavorato in Red Hat per anni, ma comunque assolutamente convinto allora e ora della bontÃ  e credo tu non abbia cambiato idea ieri, almeno della bontÃ  del paradigma open source.
>
> E intanto, perÃ², mentre chiacchieramo, io voglio far vedere ai nostri ascoltatori che magari non hanno avuto modo prima e Mario, come appare oggi, non Ã¨... Ã¨ un po' meno personaggio. Ma Mario io l'ho conosciuto cosÃ¬, esattamente come nella foto tutta a destra dello schermo che sto condividendo...
>
> E tanto che sei dentro le community, racconto anche che il cambio da lÃ¬ a qui alla versione Ã¨ successo su un palco di una conferenza, quella che nominavamo prima Devoxx l'anno scorso. Quindi la domanda, raccontaci del taglio di capelli che Ã¨ sempre divertente, ma al di lÃ  di quello la domanda vera mia Ã¨: cosa vuol dire per te la community e quanto ti dÃ  il passami il termine "restituire" tutto quello che comunque dalla community prendiamo? PerchÃ© io sono molto convinto di questa cosa: noi siamo dentro queste community open source e prendiamo tanto dalle community e credo che le conferenze, i blog, i podcast siano un modo per restituire, ma questo Ã¨ la mia personale opinione. Non so se tu la vedi diversamente la community in generale.

**Mario Fusco**
> PiÃ¹ che restituire, userei la parola condividere che Ã¨ appunto un dare avere bidirezionale. Ecco, condividere conoscenza, questa Ã¨ la Ã¨ il punto di forza delle community.
>
> VabbÃ¨, il taglio di capelli Ã¨ successo in un ambito community, ma semplicemente perchÃ© Ã¨ nata la cosa come uno scherzo e poi l'abbiamo portata avanti, io e il mio amico Stephan che organizza la Devoxx Belgium.

**Stefano Maestri**
> No, perÃ² diciamo almeno questa cosa perchÃ© Ã¨ stato divertente. Io purtroppo non c'ero quell'anno, ma mi Ã¨ stato raccontato da colleghi...

**Mario Fusco**
> SÃ¬, c'Ã¨ il video su YouTube pure di quello.

**Stefano Maestri**
> Quello che mi hanno raccontato che Ã¨ stato fatto durante il Keynote, quindi uno dei talk piÃ¹ importanti di ogni conferenza e il bello Ã¨ che tutti guardavano Mario invece di che Keynote...

**Mario Fusco**
> SÃ¬, c'era il Keynote di Brian Goetz che parlava delle nuove feature di Java che peraltro molto bello e importante, Brian Goetz ovviamente chiunque Ã¨ nel mondo Java non puÃ² non conoscerlo, ma nel frattempo mi stavo tagliando i capelli. E lui, insomma, era un po' non so se era disturbato, insomma, era divertito pure lui, distratto anche un po'. E poi dopo subito dopo la Keynote invece su quel palco lÃ¬ c'Ã¨ stato il talk successivo era di Gavin King che Ã¨ un altro nostro amico, il creatore di Hibernate e c'erano ste masse di capelli che ancora rotolavano sul palco mentre lui parlava e quello pure era strano da vedere.
>
> Invece parlavamo della community: come diceva Stefano, a me piace parlare in pubblico, uno appunto per la parte puramente sociale della cosa e ma il vantaggio principale che ci vedo Ã¨ appunto la condivisione, come dicevo. Io, come Stefano, come tanti dei nostri colleghi, lavoriamo da casa, lavoriamo da remoto e quindi stando nella tua stanzetta davanti al PC, certe volte facciamo le cose nella nostra torre d'avorio e abbiamo poco confronto con poi chi i software che scriviamo dovrÃ  utilizzarli. Invece il confronto Ã¨ fondamentale perchÃ© altrimenti perdo 6 mesi a fare una cosa di cui non importa poco agli altri e non Ã¨ troppo produttivo, troppo bello. La parte bella di scrivere software Ã¨ poi vedere che questo software, questo lavoro che hai fatto viene utilizzato da altri, no? E per essere utilizzato da altri deve essere apprezzato e per arrivare lÃ¬ devi capire gli altri di cosa hanno bisogno e per capirlo ci devi parlare, non c'Ã¨ niente da fare.
>
> Quindi la parte di community, la parte delle conferenze Ã¨ importante per quello. Vado alle conferenze, presento i lavori, le cose su cui di volta in volta lavoro e poi mi confronto con le persone e la parte piÃ¹ importante per me non Ã¨ il talk in sÃ©, ma quello che succede immediatamente dopo, ovvero chiacchierare con chi il talk c'era, che va bene, ti fanno i complimenti, ti danno la pacca sulla spalla e quello fa sempre piacere, ma poi ti danno anche del feedback, ti dicono qual Ã¨ la cosa di cui hanno bisogno e che al momento non c'Ã¨, che ti manca e semplicemente non c'Ã¨ non perchÃ© era difficile da implementare, molto spesso mi capita, ma semplicemente perchÃ© non avevo pensato che potesse essere una cosa utile. Tutto qua.

**Stefano Maestri**
> E se non te lo dicono... i feedback sono fondamentali.

**Mario Fusco**
> Quindi la community Ã¨ importante per quello. Io ho iniziato a parlare in pubblico nel piccolino del Java User Group di Milano che abbiamo messo su oramai 24 anni fa. E lÃ¬ ho capito che l'importanza di parlare in pubblico... non nascondo che mi piace, insomma, che mi piace condividere quello che faccio, mi piace stare sotto i riflettori, stare on stage, perÃ² poi la cosa importante Ã¨ quella che dicevo prima e quello che succede subito dopo il talk sono le domande, i confronti, i feedback che si ricevono eccetera eccetera.
>
> Eppure, ecco, l'altra cosa anche importante Ã¨ che quando tu usi il mio software programmi contro la mia API, tu vedi il risultato finale, stai usando quel software cosÃ¬ come Ã¨ in quel momento. PerÃ² durante i miei talk quello che cerco di raccontare Ã¨ non solo come le cose funzionano, ma come ho fatto ad... tanti dei miei talk sono piÃ¹ sul viaggio che non sulla destinazione finale. Come ho fatto ad arrivare lÃ¬? PerchÃ© quella cosa Ã¨ scritta in quel modo lÃ¬? PerchÃ© quella feature Ã¨ implementata? PerchÃ© quel metodo c'Ã¨ quei tre argomenti e non altri due?
>
> Dare una spiegazione delle motivazioni che mi hanno spinto a fare le cose in un certo modo e questo e diciamo fa capire davvero alle persone il tipo di lavoro che hai fatto, come funzionano le cose e perchÃ© funzionano in quel modo lÃ¬, che Ã¨ un altro feedback, Ã¨ un altro momento di condivisione importante.

**Stefano Maestri**
> Guarda, perÃ² hai citato il JUG Milano, che 24 anni di community locale Ã¨ assolutamente interessante. Io ne approfitto per, diciamo, spezzare una lancia anche per quelli che ci ascoltano e che magari non hanno la tua o la mia â€” perchÃ© anch'io non mi nascondo voglia di stare sotto riflettori â€” ma partecipare, venire ad ascoltare Mario al JUG Milano piuttosto che da un'altra parte nelle community locali senza scomodare la grande conferenza... la community locale Ã¨ lÃ¬ per tutti. E anche solo partecipare, ascoltare Mario che vi racconta perchÃ© ha messo quella variabile nel metodo e poi di condividere con lui e con le altre persone che sono lÃ¬ Ã¨ qualcosa che dÃ  molto sicuramente e fa crescere molto.
>
> Io adesso sto pensando a chi magari ha un po' meno esperienza di noi. Vorrei dire piÃ¹ giovane di noi, ma non lo dico perchÃ© poi sembriamo vecchi, perÃ² diciamo chi ha un po' meno esperienza di noi, magari il confronto puÃ² essere quel momento di crescita, anche se per noi Ã¨ il momento del feedback oggi piÃ¹ che altro, ma Ã¨ sempre di crescita anche per noi, assolutamente in un altro senso, ma anche per lo Junior di turno puÃ² essere un momento di crescita, quindi davvero partecipate alle community locali e non.

---

## [01:15:45] CONTRIBUIRE AI PROGETTI OPEN SOURCE

**Stefano Maestri**
> Ma qua altra domanda per te, quella lÃ¬ Ã¨ la community di persona e invece la community quella su GitHub. CioÃ¨ se facessi la domanda che mi Ã¨ stata fatta da uno Junior a me e io non sapevo rispondere: "Ma come faccio a passare da 10 a 100 contributor?" Tu ce l'hai una risposta a quella domanda qua? Come faccio?

**Mario Fusco**
> Nel senso che tu hai il tuo progetto e vorresti invitare altre persone a fare... vorresti che fosse un po' piÃ¹ virale?

**Stefano Maestri**
> SÃ¬.

**Mario Fusco**
> Ãˆ una domanda difficile, a me l'hanno fatta e io giuro non Ã¨ una domanda bella bella complicata. La domanda che mi sono sentito fare piÃ¹ spesso Ã¨: "Come faccio io a contribuire? Nessuno mi conosce. Come faccio io a contribuire a un progetto che esiste giÃ  o come faccio a far crescere una community?". Devo ammettere che andiamo sul livello di complessitÃ  ancora maggiore della cosa.

**Stefano Maestri**
> Partiamo da come si contribuisce. Su come si cresce una community possiamo farci un episodio da solo. Ma se c'Ã¨ qualcuno che dice "VabbÃ¨, tutto bello, LangChain4j mi interessa, mi interessa Java piuttosto che voglio contribuire ad un altro community che non c'entra niente". Ce li abbiamo un consiglio da dare a costui?

**Mario Fusco**
> Allora, prima di tutto, se stai se vuoi contribuire a un progetto Ã¨ probabilmente perchÃ© quel progetto ti interessa o lo stai usando. Se lo stai usando potresti aver trovato delle cose che non vanno, che semplicemente, ok, hai trovato caso piÃ¹ classico, hai trovato un bug. Il primo modo per contribuire al progetto Ã¨ segnalare il bug.
>
> PerÃ² consentimi di aprire un'altra parentesi qua: segnalare il bug in maniera ragionevole. Ecco, questa Ã¨ una cosa che ci tengo a dire da contributor di progetti open source. Quando segnalate un bug, mettetevi, come dicevi tu, nelle scarpe, nei vestiti di quel di chi quel bug poi qualcosa deve farci, insomma, deve capire qual dov'Ã¨ il problema e fissarlo. Se mi dai un bug report dove mi dici "Ho chiamato questo metodo e non funziona" o semplicemente mi incolli uno stack trace cosÃ¬ e giÃ  quello Ã¨ tanto che me lo stai dando e non mi dai alcuna informazione su come riprodurre il problema lato mio, non Ã¨ una cosa actionable. Non so che farci. Mettiti nei miei panni. Ricevi una segnalazione del genere, come ci lavoro su.
>
> Quindi la prima cosa sÃ¬, se avete trovato un bug segnalatelo, riportatelo giusto in maniera actionable. Il passo successivo Ã¨: "Ok, ho trovato un bug, non solo lo segnalo, ma cerco di capire dentro che sto che sta succedendo e cerco di fissarlo, di mandare non solo il bug report, ma anche una fix di quel bug".
>
> Ma senza anche arrivare al bug, parliamo di un altro tallone d'achille dei progetti open source che Ã¨ probabilmente la documentazione. Quello che capita certe volte e che capita pure a me che sto usando un progetto che conosco relativamente poco, devo capire come si fa una cosa e faccio fatica a trovare documentazione ragionevole. Riesco a capire mio malgrado come usare quella cosa. Ecco, un altro modo per contribuire Ã¨ contribuire mandando la documentazione, scrivendo un tutorial, scrivendo un articolo che spiega come funziona una certa cosa.
>
> Quindi contribuire veramente a un ampio spettro di possibilitÃ , appunto, ripeto, con la documentazione, con i bug report, con i fix, con le feature request. "Vorrei fare questa cosa, ma ho guardato la documentazione, ho guardato le API, non si puÃ² fare, perÃ² ne ho bisogno". E ripeto, magari come dicevo prima, quella cosa lÃ¬ non c'Ã¨, ma non perchÃ© era irragionevole o complicatissima da implementare, ma semplicemente perchÃ© chi mantiene quella libreria non ci ha pensato tutto qua. Non ci ha pensato. E quindi pure lÃ¬ passo uno, mando alla feature request, cerco di spiegare pure lÃ¬ con un esempio actionable, con quanto piÃ¹ contesto Ã¨ possibile quel bisogno insoddisfatto e anche lÃ¬ il passo successivo puÃ² essere: "Ok, sta cosa manca, magari non solo chiedo di implementarla, ma provo a farlo io e mando Pull Request".

**Stefano Maestri**
> Faccio una battuta su questa cosa che hai detto e poi do un suggerimento a chi volesse anche contribuire. La battuta Ã¨ che anche i programmatori umani hanno bisogno del contesto, non soltanto le AI. Ha appena detto Mario, dateci il contesto. CioÃ¨ il contesto Ã¨ una parola mutuata dall'umanitÃ . Davvero dateci qualche paletto e qualche contesto a cui attaccarci per risolvere i problemi.
>
> Il consiglio che do Ã¨ chi vuole contribuire, una domanda che io mi sento fare spesso Ã¨: "Ok, prendo Langchain4j, non so quante migliaia o milioni di righe di codice sono, da dove comincio? Non esiste un main da dove partire, eccetera". A volte uno degli scogli Ã¨ guardare sto progetto eccetera. Consiglio mio che ci sono cominciano a esserci gli strumenti anche gratuiti. Se non lo conoscete guardatevi Deep Wiki di Cognition che Ã¨ un tool AI, gli date il repository GitHub e lui vi fa un report con il disegno delle classi, come navigare, quali sono i punti di ingresso, eccetera. e abbassa un po' lo scoglio dal "da dove comincio". Io lo trovo molto utile sui progetti nuovi, se volete provare.

**Mario Fusco**
> Questo lo prendo pure io come suggerimento, non lo conoscevo nemmeno io.

**Stefano Maestri**
> Ah, no, loro ce l'hanno dentro a Windsurf, fatto ancora meglio, il tool concorrente di Cursor, perÃ² c'Ã¨ questa risorsa free che tu vai e te lo fai da web e comunque ti dÃ  un bel po' di punti di ingresso e sai dove mettere le mani, secondo me sui progetti grossi Ã¨ interessante.

---

## [01:22:48] BIAS E BEHAVIORAL SOFTWARE ENGINEERING

**Stefano Maestri**
> Per chiudere ti porto su un altro argomento ancora che perÃ² mi interessa molto, anche perchÃ© abbiamo detto si stati molto verticali, molto nerd, perchÃ© Ã¨ la nostra passione, ma io voglio che passi anche il Mario che vede oltre la riga di codice perchÃ© c'Ã¨ ed Ã¨ ben presente anche nelle conferenze.
>
> Ci sono due o tre talk, ma io voglio partire o citare quantomeno l'ultimo che credo si intitolasse *Behavioral Software Engineering*, qualcosa del genere, che hai fatto di nuovo al Devoxx e spoiler farai da qualche altra parte, ma non diciamo dove, a meno che lo voglia dire tu. Ed era interessante perchÃ© affronta quelli che sono i bias che in italiano possiamo tradurre come preconcetti, delle persone applicate a quello che succede ad un ingegnere.
>
> Citavi tutta la letteratura piÃ¹ famosa nel campo, *Thinking, Fast and Slow*, per citare il piÃ¹ famoso di tutti, "Pensieri lenti e veloci" in italiano. Se non l'avete letto leggetelo questo che Ã¨ bellissimo. E perÃ² ti lascio carta bianca, raccontaci tu perchÃ© ci sei arrivato lÃ¬, se c'Ã¨ un perchÃ© e che cosa ti va di raccontare se devi tirare fuori due o tre cose chiave in 10 minuti.

**Mario Fusco**
> SÃ¬. Allora, non sono arrivato lÃ¬ partendo dalla programmazione, nel senso che sono arrivato lÃ¬ partendo dall'economia che Ã¨ un'altra cosa che non c'entra niente con la programmazione, ma che mi interessa ugualmente. E a parte i processi economici e l'economia in sÃ©, mi interessa di capire come ragionano le persone nell'ambito economico o in generale come le persone prendono decisioni. Poi le decisioni che piÃ¹ la maggior parte delle decisioni piÃ¹ importanti che prendiamo nella nostra vita hanno comunque una componente monetaria, economica e quindi le cose sono ovviamente correlate. Quindi Ã¨ piÃ¹ una scienza la cosiddetta economia comportamentale parte pure lÃ¬ dall'economia, ma Ã¨ piÃ¹ una scienza che studia come prendiamo le decisioni e quali sono, come dicevi tu, i bias che ci fanno certe volte prendere queste decisioni in maniera non completamente ottimale.
>
> E sono partito da lÃ¬ e poi mi sono ricongiunto alla programmazione, nel senso che mi sono reso conto ed Ã¨ questo il succo del talk che citava Stefano pure quello su YouTube se vi va di dargli uno sguardo. Mi sono reso conto che questi bias decisionali ovviamente non colpiscono solo in campo economico... dei preconcetti, appunto, su cui il nostro cervello lavora h24 in qualsiasi ambito e siamo fatti cosÃ¬ perchÃ© c'Ã¨ un motivo, perchÃ© c'era un vantaggio evoluzionistico a prendere decisioni in un certo modo. Adesso ovviamente il contesto in cui viviamo Ã¨ totalmente diverso da quello di 10.000 anni fa quando quell'evoluzione Ã¨ avvenuta, perÃ² il modo di pensare in quei termini Ã¨ rimasto e questo, come dicevo, influisce tutte su tutte le nostre decisioni, sul nostro processo decisionale e ovviamente parte delle decisioni che prendiamo sono le decisioni che prendiamo in ambito lavorativo, in ambito di sviluppo software se facciamo questo lavoro.
>
> Quindi il mio sforzo in quel talk Ã¨ di fare un parallelo tra come un bias, un certo bias e ne cito alcuni nel talk, influenza e puÃ² danneggiare le nostre scelte economiche, come quello stesso bias influenzare e danneggiare le nostre scelte lavorative in campo di sviluppo software.
>
> E campo pure lÃ¬... Certe volte, soprattutto per chi non fa questo mestiere, si sottovaluta la parte sociale ancora una volta dello sviluppo software. Si pensa che sviluppare software vuol dire stare davanti al computer da solo, in perfetto isolamento a vomitare codice e invece non Ã¨ quasi mai cosÃ¬. Si interagisce con le persone. Eppure lÃ  l'interazione con le persone deve essere mediata un po' da degli atteggiamenti che superano questi bias che inevitabilmente abbiamo e insomma il talk Ã¨ un po' tutto lÃ¬, quindi parlo dei bias piÃ¹ comuni.

**Stefano Maestri**
> Tira fuori il tuo bias, quello che ti sei sentito piÃ¹ addosso nello scrivere e che effetto ha fatto sul tuo modo di fare codice, se ce l'hai.

**Mario Fusco**
> Quello che probabilmente influenza di piÃ¹ il modo di fare codice ce ne sono un po'. Uno probabilmente Ã¨ il *Temporal Discounting*, e con temporal discounting intendo il fatto che diamo piÃ¹ importanza alle cose, anche alle gratificazioni piÃ¹ e ai guadagni piÃ¹ immediati e i guadagni piÃ¹ magari piÃ¹ grandi, ma piÃ¹ distanti nel tempo, sono scontati in maniera iperboliche e quindi sembrano meno importanti dell'immediato.
>
> E questo Ã¨ il motivo per cui inevitabilmente, perchÃ© succede da quando esiste il software, un motivo ci sarÃ , a un certo punto quel pezzo di software diventa talmente incasinato che Ã¨ difficile metterci le mani dentro perchÃ© per effetto del temporal discounting perchÃ© cerchiamo di risolvere un problema nel modo piÃ¹ veloce possibile. Questo ci dÃ  un reward immediato, ma non tiene conto del fatto che sto probabilmente se sto lavorando in quel modo, sto introducendo del debito tecnico e cosÃ¬ facendo sto facendo un danno al me stesso del futuro, a chi in futuro dovrÃ  mettere le mani lÃ  dentro, perchÃ© questo futuro, appunto, viene scontato, viene considerato in maniera meno importante del presente.
>
> Questo ci spinge a risolvere problemi col classico *name hack* che si dice nel nostro gergo da nerd. Vuol dire ho risolto il problema, ma probabilmente non si doveva risolvere cosÃ¬, ma ho semplicemente scelto il modo piÃ¹ veloce per risolvere. Questo Ã¨ una grossa influenza su come sviluppiamo software e probabilmente una delle grosse differenze tra una persona che sta iniziando da poco lavoro e una persona che ha piÃ¹ esperienza nel farlo, insomma.
>
> Chi ha piÃ¹ esperienza â€” e questo mi capita, chi ha piÃ¹ esperienza e ci metto una vita a fare le cose â€” vedo i ragazzetti che hanno 20 anni meno di me, che ci mettono la metÃ  del mio tempo a fare le stesse cose. Questo deriva dal fatto perchÃ© io cerco di pensare non solo alla feature nell'immediato come la voglio fare, ma anche come quelle cose poi potrebbero evolvere nel futuro, come rendere quel software piÃ¹ modulare, piÃ¹ manutenibile, piÃ¹ leggibile, piÃ¹ a prova di tempo. Ecco, e per fare questo occorre piÃ¹ tempo e perÃ² Ã¨ tempo ben speso.

---

## [01:32:15] CONSIGLI PER GLI JUNIOR

**Stefano Maestri**
> Allora, io di solito chiudo facendo un commento del perchÃ© in tutte le interviste come era come quello che sei oggi Ã¨ legato al tuo gioco giocattolo preferito, ma lÃ¬ Ã¨ fin troppo facile. CioÃ¨, mi hai detto lo Spectrum Ã¨ lÃ¬ da vedere che Ã¨ legato a tutto il tuo modo di essere e quindi questa qui la salto, cioÃ¨ l'ho detta, ma Ã¨ stata veramente facile, no? Poi l'altro modo Ã¨ che io che comincio a diventare anziano provo a chiudere sempre pensando ai giovani, sarÃ  che i figli crescono e comincio a pensare al futuro loro.
>
> E quindi chiedo sempre all'ospite come fa oggi un ragazzo che si avvicina e vuole diventare Mario Fusco.

**Mario Fusco**
> Eh no, vabbÃ¨, Mario Fusco, insomma... che vuole fare il nostro lavoro, dai.

**Stefano Maestri**
> Che vuole fare il nostro lavoro, vabbÃ¨, vuole diventare Stefano Maestri, se preferisce, adesso l'ho detto cosÃ¬, ma vuole diventare un programmatore. Vuole diventare un programmatore, eh, e magari appunto un piÃ¹ il piÃ¹ professionale possibile nel mondo enterprise, eccetera, perchÃ© il mondo Ã¨ cambiato. Noi ci mettevamo con lo ZX e cominciavamo a scrivere il codice. Oggi abbiam detto prima, Ã¨ piÃ¹ importante leggerlo che scriverlo. E quindi come si fa? Come fa uno junior a diventare senior oggi? PerchÃ© Ã¨ difficile, no? Io lo sento difficile.

**Mario Fusco**
> Mi fai una domanda veramente complicata perchÃ© Ã¨ difficile per me immedesimarmici, nel senso che quando ho iniziato io a programmare il contesto era ovviamente completamente diverso e ho seguito un percorso che adesso non posso piÃ¹ consigliare il percorso che ho fatto io, semplicemente perchÃ© quel percorso non esiste piÃ¹, insomma.
>
> Il percorso era giusto per capirsi, eh all'epoca chi ha la nostra etÃ , se lo ricorda, ci compravamo le riviste col codice scritto su sulle pagine e copiavamo quel codice dalla rivista allo schermo alla tastiera e magari saltavamo una virgola e non funzionava niente. E poi imparando, scrivendo quel codice, copiandolo dalla rivista, capivamo cosa faceva e io ho imparato da lÃ¬, insomma.
>
> E ovviamente non Ã¨ una cosa che posso piÃ¹ che posso piÃ¹ suggerire ed Ã¨ anche nÃ© posso piÃ¹ suggerire iniziate a scrivere codice cosÃ¬ senza alcun aiuto esterno perchÃ© non Ã¨ piÃ¹ vero, insomma, c'Ã¨ l'AI che si intromette e vuole scriverlo al posto tuo e questo lo vedo onestamente un problema per chi inizia questo lavoro. Credo che essere un junior in questo periodo storico, credo che approcciarsi a questo lavoro in questo periodo storico sia tutto sommato piÃ¹ difficile di quanto l'abbiamo fatto noi.

**Stefano Maestri**
> SÃ¬, Ã¨ molto diverso.

**Mario Fusco**
> PerchÃ© quando l'abbiamo fatto noi eri costretto ad imparare, ad imparare nel modo piÃ¹ duro possibile, sbattendoci la testa quanto piÃ¹ forte Ã¨ possibile. Adesso ci sono queste scorciatoie offerte dalla dall'AI generativa che da una parte sembra che ti mettono in grado di fare le cose in maniera piÃ¹ veloce, perÃ² dall'altro ti mettono in grado di farlo pure senza capire al 100% quello che stai facendo e quello non va bene.
>
> Quindi torniamo al discorso di prima. Ok, me lo faccio generare il codice, ma poi perÃ² almeno leggilo, leggilo, capisci come funziona, riga per riga, fermati, debugga, aggiungi commenti dentro quando scopri come funziona. Non accettare passivamente quello che ti genera l'AI, perchÃ© certe volte potrebbe non funzionare e quando non funziona devi sapere dove mettere le mani, insomma.

**Stefano Maestri**
> Guarda, provo a mettertela giÃ¹ cosÃ¬, dimmi come la vedi tu. Ãˆ una cosa che ho sentito, non cito da chi perchÃ© non sono certissimo di da chi l'ho sentita e l'ho un po' anche rielaborata, ma in fondo, quando eravamo primitivi, uomini primitivi, eccetera, la forma fisica era una necessitÃ  perchÃ© dovevi cacciare, cosÃ¬ come quando facevi il contadino che dovevi usare la zappa. Sempre di piÃ¹, negli ultimi anni si va in palestra per scelta, per piacere, perchÃ© ci si vuole tenere in forma.
>
> E io ai forse ai giovani di oggi che vogliono avvicinarsi ad un lavoro di cervello, qualunque esso sia, dico che l'imparare deve essere una scelta e non prendere le scorciatoie. Magari prendere le scorciatoie per fare perchÃ© io non mi metto piÃ¹ a zappare per terra o andare a cacciare il mammut, ma vado in palestra perchÃ© mi voglio tenere in forma, perchÃ© voglio essere in grado di portar su dalle scale senza fare fatica la spesa quando avrÃ² 70 anni. Forse Ã¨ questo cambio di mindset, di nuovo, l'abbiamo nominato tante volte oggi, che bisogna provare a fare. CosÃ¬ lo lasciamo con un messaggio di speranza almeno, perchÃ© sennÃ² tu mi hai detto Ã¨ difficilissimo, non fatelo, basta.

**Mario Fusco**
> No, no, no. Ãˆ che questi strumenti software sono diventati l'equivalente immateriale del trattore invece della Zappa. Adesso non si usa piÃ¹, si usa il trattore, quindi col trattore fai meno fatica, non eserciti piÃ¹ i muscoli e se non vai in palestra a 70 anni le scale non le fai piÃ¹, come dicevi.

**Stefano Maestri**
> E perÃ² se non sai neanche cosa stai piantando, non sai quello che Ã¨ la pianta, anche col trattore fai i disastri. Quindi l'invito Ã¨ imparate comunque con che cosa avete a che fare e poi usate tutti gli strumenti che vi facilitano la vita. Sempre il cervello acceso.

**Mario Fusco**
> Bravo, bravo. Ãˆ la prima cosa che non Ã¨ facilissima delle volte, ma Ã¨ la prima cosa da fare, accendere il cervello al mattino.

**Stefano Maestri**
> Pensiero critico, esatto. Che si sente tanto nominare, ma Ã¨ assolutamente quello che ci vuole.

**Mario Fusco**
> In maniera critica, ecco, questo volevo dire.

---

## [01:38:45] CONCLUSIONI

**Stefano Maestri**
> Io ti ringrazio. Io mi sono divertito in intervista. Spero ti sia divertito anche tu. Spero si sian divertiti tutti quanti e ancora grazie. In descrizione mettiamo tutte le le cose piÃ¹ o meno che abbiamo nominato, link, Mario, talk e non articoli. Andate a darci un'occhiata che sono sicuramente piÃ¹ completi di quanto siamo riusciti a dire in un'ora e mezza. E ovviamente io la marchetta la devo fare. Iscrivetevi al canale, mettete le stelline, le campanelline, eccetera eccetera eccetera. Ciao, grazie ancora. Grazie a tutti. Ciao.

**Mario Fusco**
> Grazie a te. Grazie a tutti, ciao.