---
title: "AI nel 2025: sorprese e delusioni tra Vibe Coding, DeepSeek, Gemini e open source #32"
categories:
  - Puntate
tags:

  - AI
layout: single
author_profile: true
---

{% include video id="7dDbpdnhWRM" provider="youtube" %}

ðŸ‘‰ [Ascolta su Spotify](https://open.spotify.com/show/16dTKEEtKkIzhr1JJNMmSF?si=900902f2dca8442e)<br/>
ðŸ‘‰ [Guarda su YouTube](https://www.youtube.com/channel/UCYQgzIby7QHkXBonTWk-2Fg)<br/>
ðŸ‘‰ [Segui su LinkedIn](https://www.linkedin.com/company/risorseartificiali)<br/>


## Intro e auguri di Buon Anno

**Stefano Maestri**

> Ciao a tutte e tutti e bentornati a Risorse Artificiali. Auguri in ritardo per chi festeggia il Natale, perchÃ© quando voi sentirete questa puntata sarÃ  giÃ  passato. Nella puntata scorsa, riascoltandola, mi sono accorto che ci siamo dimenticati di fare gli auguri. PerÃ² fa niente, vi facciamo giÃ  gli auguri di buon anno. Ci portiamo avanti.

**Alessio Soldano**

> Ciao! E cosÃ¬ ci portiamo avanti.

**Stefano Maestri**

> Siccome abbiamo fatto quest'ultima puntata in cui avevamo ospite Alex di Backlog MD, che Ã¨ stata per noi molto interessante ma anche estremamente nerd, abbiamo deciso di alleggerire un pochino. Anche se siamo nel periodo natalizio, facciamo una puntata magari un po' piÃ¹ corta e un po' diversa dalle solite, in cui ci chiediamo e vi chiediamo â€” chiediamo anche a voi se volete partecipare con i commenti â€” di fare una retrospettiva di quest'anno. Spoiler: nella prossima proveremo invece a guardare avanti, essendo la prima dell'anno. E quindi parto io con la domanda delle domande: cos'Ã¨ la cosa che vi ha stupito di piÃ¹ nel 2025, su cui non avreste messo un centesimo a dicembre 2024 e invece Ã¨ successo di tutto? Io ce l'ho la risposta, ma voglio la vostra prima.

## La sorpresa del 2025: Vibe Coding e ProduttivitÃ 

**Alessio Soldano**

> Parto io. Allora, intanto un minimo di storia personale: nonostante Stefano mi martellasse in senso buono da tempo sul fatto che l'intelligenza artificiale fosse bellissima, io fino alla fine dell'anno scorso sostanzialmente non me n'ero occupato piÃ¹ di tanto. Poi c'Ã¨ stato per me un turning point quando a gennaio sono andato a una delle conferenze qui vicino, al Voxxed Ticino. Nella Keynote, Stefan â€” uno degli organizzatori â€” faceva vedere come aveva costruito un'applicazione quasi completamente utilizzando l'intelligenza artificiale. Nonostante non fosse una novitÃ  assoluta, vederla lÃ¬ Ã¨ stato scioccante. Quando alcune settimane dopo si Ã¨ iniziato a parlare di "vibe coding", per me quella Ã¨ stata la cosa che proprio non mi aspettavo: riuscire a vedere software scritto dall'IA che sostanzialmente funzionava.

**Stefano Maestri**

> Quindi il vibe coding, l'AI assisted coding per te. Paolo?

**Paolo Antinori**

> Ãˆ una buona domanda. Ci stavo pensando e mi vengono in mente due avvenimenti principali che mi hanno fatto capire che valeva la pena prestare attenzione. Il primo Ã¨ stato quando ho provato la modalitÃ  podcast di NotebookLM: mi ha fatto un "wow effect", tipo magia. Sentire quei due che parlano in modo naturale mi ha scioccato. Tant'Ã¨ che ho annoiato i miei amici dicendo di provarlo assolutamente, magari sul documento piÃ¹ noioso del mondo, come specifiche tecniche o standard; ti apre la mente. La seconda cosa Ã¨ stata Deep Search di Google. Ho lanciato una query e ho visto che il browser faceva una ricerca per un quarto d'ora. Ho pensato: "Questa Ã¨ la stessa cosa che in passato avrei fatto in un weekend, passando il tempo davanti allo schermo ad aprire venti tab, leggerli, capire quali tenere e fare un'analisi". Queste due cose mi hanno fatto capire che la produttivitÃ  e il valore lato consumer erano reali. Non era solo per developer o ingegneri, ma per tutti.

**Stefano Maestri**

> Rispondo anche io. Ho due cose. Una, Alessio lo sa perchÃ© ne avevamo parlato a dicembre scorso, ma a settembre 2024 non avrei messo un centesimo sul livello di coding che abbiamo raggiunto oggi. Dicevo: "SÃ¬, sarÃ  interessante per i lavori ripetitivi, per i chatbot evoluti", ma pensavo che per il coding fosse presto. Invece i risultati di oggi sono veramente impressionanti. L'altra cosa su cui non mi aspettavo questa evoluzione sono i video e i world model. Sulle immagini me lo aspettavo, ma sui video i passi avanti sono stati incredibili. Penso a Veo o Sora, che permettono di mischiare immagini e video con una qualitÃ  difficile da distinguere dalla realtÃ . L'ho fatto vedere alla mia compagna sul telefono e mi ha detto che sembravano attori reali in una pubblicitÃ  qualunque.

## Le delusioni: Alexa e il pivoting di Meta

**Stefano Maestri**

> Vi faccio la domanda opposta: cos'Ã¨ la cosa su cui pensavate grandi cose e invece avete avuto una delusione?

**Alessio Soldano**

> Io non proprio, perchÃ© essendo l'anno in cui ho iniziato a occuparmi di queste cose non avevo aspettative elevate. Parlando di mini-delusioni, quando Ã¨ uscito Flux 2 ci si aspettava chissÃ  che cosa, invece nulla di che. Ma aspettative tradite all'inizio dell'anno, onestamente nessuna.

**Paolo Antinori**

> Io mi sarei aspettato che alcune tecnologie si spostassero piÃ¹ velocemente dentro altre. Mi viene in mente Alexa: sto ancora aspettando che mi capisca al primo colpo. So che c'Ã¨ il rollout di Alexa Plus negli Stati Uniti, ma mi sembra che potevano fare molto di piÃ¹ giÃ  tempo fa. Amazon ha sempre fatto scelte strane con le API e ha controllato l'ambiente piÃ¹ del necessario. Ora come ora mi sembrano un po' indietro e rischiano di aver perso un'occasione nella gara con Google.

**Stefano Maestri**

> Mi dai un gancio. Per me la delusione dell'anno non Ã¨ Apple â€” su cui non avevo aspettative a breve termine perchÃ© loro sono bravi a integrare nel lungo periodo â€” ma Meta. Mi aspettavo molto da loro per come si erano posizionati con Llama 3. Pensavo potessero fare un pivoting sul mercato piÃ¹ velocemente di Google, perchÃ© temevo che Google fosse troppo bloccata nelle sue logiche di business legate al motore di ricerca. Meta ha soldi infiniti dalla pubblicitÃ  social, ha investito tantissimo e ha fatto la scelta dell'open source, ma alla fine la spinta si Ã¨ abbastanza sgonfiata. Al momento, l'evoluzione dei loro modelli Ã¨ stata la mia delusione del 2025.

## Gli outsider: Thinking Machine Lab e No-Code

**Stefano Maestri**

> Avete un outsider? Qualcuno o qualcosa di fuori contesto che vi ha stupito?

**Stefano Maestri**

> Parto io cosÃ¬ vi lascio tempo di pensare. Per me Ã¨ Thinking Machine Lab, la startup di Mira Murati. Mi aspettavo una proposta concorrenziale diretta agli altri, invece sono stati intelligenti a non farlo. Si sono orientati verso API per il fine-tuning e ricerche sulla comparazione dei modelli, ritagliandosi una nicchia che diventerÃ  interessante man mano che i modelli maturano.

**Alessio Soldano**

> Io non mi aspettavo il ritorno alla CLI (Command Line Interface) per l'assisted coding. Abituati alle interfacce grafiche, tornare alla riga di comando sembrava strano, e invece pare abbia avuto molto successo.

**Stefano Maestri**

> Ãˆ vero, Ã¨ uno dei trend piÃ¹ importanti. Io lo apprezzo moltissimo perchÃ© uso ancora VI per editare i file.

**Paolo Antinori**

> La mia sorpresa Ã¨ stata l'affermarsi di proposte come Lovable. Non mi aspettavo fossero in grado di fornire un'esperienza end-to-end soddisfacente. La mia esperienza passata con il no-code era sempre stata subottimale: appena provavi a cambiare una virgola fuori dal framework, non ne valeva piÃ¹ la pena. Non ho ancora usato Lovable personalmente, ma ho molti amici, anche senza esperienza di sviluppo, che sono riusciti a ottenere risultati significativi.

## Strumenti quotidiani: La sfida tra Gemini, ChatGPT e Claude

**Stefano Maestri**

> Qual Ã¨ la cosa che usate di piÃ¹ oggi?

**Alessio Soldano**

> La mia risposta non aggiunge nulla: uso ChatGPT. Questo dimostra come il primo che arriva si guadagna una fetta di mercato. Quello che faccio con ChatGPT potrei farlo con Gemini, ma per abitudine e per l'abbonamento economico continuo lÃ¬. Ho centinaia di chat salvate. Se devo generare immagini perÃ² uso Gemini, perchÃ© le fa molto meglio.

**Paolo Antinori**

> Io uso tantissimo Claude Code per il codice. Mi sto impigrendo e gli faccio fare anche refactoring banali di search and replace o git commit. Lato vita quotidiana, uso Gemini sul telefono. Ãˆ comodissimo. Invece di aprire YouTube o Pinterest quando ho un momento morto, apro Gemini per chiedere curiositÃ  che mi passano per la testa, come se fosse un nuovo Wikipedia. Qualche giorno fa gli ho chiesto cosa sono i missili balistici; mi ha dato una spiegazione chiara e veloce. Sta rimpiazzando il motore di ricerca perchÃ© mi fido di questa "scorciatoia" per arrivare all'informazione senza dover navigare tra mille fonti.

**Stefano Maestri**

> Ma secondo te toglie tempo anche ai social?

**Paolo Antinori**

> Dipende. Io sono nella fascia di utenza di mezza etÃ  e ho smesso di usare quasi tutto tranne LinkedIn per lavoro. Non ho Instagram o TikTok, quindi a me non ha rubato spazio ai social perchÃ© giÃ  non li usavo.

**Stefano Maestri**

> Io invece uso molto Gemini nella vita di tutti i giorni, sia per le domande che per le immagini e la scrittura. Per il coding uso Claude, ma una nicchia che si sta spostando verso Gemini Ã¨ il vocale. Fino a due settimane fa la modalitÃ  vocale di ChatGPT era superiore, ma la nuova modalitÃ  Live di Gemini, dove puoi usare anche la telecamera, Ã¨ diventata molto meglio. Mi sto spostando lÃ¬, confermando i numeri di cui si preoccupa Altman in questi giorni.

**Paolo Antinori**

> C'Ã¨ anche un altro fattore: mi sta abbastanza antipatico Altman, quindi tendenzialmente evito le sue cose se c'Ã¨ un'alternativa valida. Se Gemini e ChatGPT sono uguali, scelgo Gemini. Grok non l'ho mai usato per lo stesso motivo legato a Musk.

**Stefano Maestri**

> Io Grok l'ho provato solo dentro X perchÃ© Ã¨ comodo per la sentiment analysis in tempo reale sulle notizie, avendo accesso diretto ai dati della piattaforma, ma per il resto concordo.

## Cosa abbiamo smesso di usare: Olama e gli IDE AI

**Stefano Maestri**

> Cosa state usando di meno rispetto a inizio anno?

**Stefano Maestri**

> Parto io: uso meno Claude come chatbot. Continuo a usarlo per il codice, ma per scrivere ormai vado su Gemini. Un'altra cosa che uso poco sono gli IDE AI come Cursor. Dopo essere passato alla CLI, preferisco usare VS Code normale in partnership con Claude Code quando lui deve fare "l'agente". Cursor lo sto usando pochissimo negli ultimi mesi.

**Paolo Antinori**

> Io non apro piÃ¹ Klein. Ãˆ stata la prima cosa che ho usato sotto tuo suggerimento, ma consuma un numero di token spaventoso. Cursor l'ho installato perchÃ© me lo forniva il lavoro, ma non l'ho mai usato letteralmente per mancanza di tempo. E come dicevo, non apro quasi mai ChatGPT da quando Gemini fa le stesse cose.

**Alessio Soldano**

> Io citerei Klein e poi in generale i modelli in locale con Olama. A inizio anno se ne parlava tanto per l'open source, ma poi si Ã¨ capito che l'esperienza era subottimale rispetto ai modelli di frontiera via API. Ho smesso di usare Olama. Recentemente, avendo un computer nuovo, sono tornato ai modelli locali ma uso LM Studio, che sotto usa Llama.cpp ma gestisce i modelli in modo piÃ¹ comodo.

## Impatto Business: MCP e DeepSeek

**Stefano Maestri**

> Venendo al lato business o enterprise, qual Ã¨ la cosa che ha avuto piÃ¹ impatto?

**Stefano Maestri**

> Per me Ã¨ MCP (Model Context Protocol). Ha avuto un impatto significativo perchÃ© ha permesso di aprire i modelli a nuovi dati. Anche se Ã¨ piaciuto piÃ¹ agli sviluppatori che agli utenti finali, ha cambiato le cose. Poi c'Ã¨ l'investimento di Meta nell'acquisizione di aziende per il tagging dei metadati, che Ã¨ stato molto importante anche se invisibile.

**Paolo Antinori**

> Per me l'impatto maggiore Ã¨ stato DeepSeek. A fine gennaio hanno rilasciato tutto in modo open, con tanto di paper. Hanno accelerato l'intera industria: non c'era piÃ¹ motivo per non fare almeno quello che facevano loro. Hanno fatto fare un "level up" a tutti. PerÃ² l'highlight dell'anno resta il super rilascio di Google dell'estate con Gemini 2.5; c'era un'infinitÃ  di roba e ci Ã¨ voluto tempo per capire quanto fosse valida.

**Alessio Soldano**

> Concordo. I modelli cinesi open weight hanno aiutato molto la community. Le novitÃ  che abbiamo visto a fine anno, come lo Z-Image, sono state possibili grazie a ciÃ² che era stato rilasciato precedentemente.

## Innovazione visiva: Nano Banana, Veo e Sora

**Stefano Maestri**

> E l'innovazione vera? Quella che ha cambiato le regole?

**Stefano Maestri**

> Per me la "Latent Attention" di DeepSeek Ã¨ stata l'uovo di Colombo. Ha influenzato persino il design delle TPU di Google. Pur essendo un refinement, a livello di innovazione Ã¨ quello che ha fatto di piÃ¹. Citerei anche il lavoro di Anthropic sull'explainability dei modelli.

**Alessio Soldano**

> Per le immagini, il momento "wow" Ã¨ stato l'uscita di Nano Banana (Gemini Flash). PiÃ¹ del Pro, perchÃ© con il Pro c'erano aspettative alte, mentre il Flash ha sorpreso tutti per velocitÃ  e qualitÃ . Sui video dico Veo, piÃ¹ di Sora. Sora ha avuto successo sui social, ma poi hanno limitato l'accesso per i costi. La gente usa ancora poco i video perchÃ© costano troppo, quindi l'impatto reale Ã¨ stato inferiore rispetto alle immagini, dove tutti si facevano le foto in stile Studio Ghibli o le action figure.

**Paolo Antinori**

> Io ho iniziato a usare gli MCP server per GitHub e Jira per gestire il backlog delle attivitÃ . Prima pensavo fossero solo delle "gimmick", invece poter scrivere all'ingegno della lampada "vai laggiÃ¹ e trovami queste informazioni" ha rivoluzionato il mio modo di lavorare. Mi sono reso conto che il collo di bottiglia Ã¨ solo la mia creativitÃ . Le idee migliori verranno collaborando con i colleghi: "perchÃ© non proviamo questa ricetta?".

**Stefano Maestri**

> Mi piace questa metafora della ricetta. Un LLM di buon livello Ã¨ un po' come un Bimby che mette insieme gli ingredienti. Non devi piÃ¹ essere per forza lo chef o il super programmatore, basta saper padroneggiare gli strumenti.

**Paolo Antinori**

> Esatto. Mia figlia di 9 anni potrebbe darmi idee bislacche che portano a risultati migliori dei miei, perchÃ© ora il costo per provare Ã¨ zero. Questo cambia anche il modo di approcciare il problema dei junior developer.

## Retrospettiva del Podcast: 32 puntate di Risorse Artificiali

**Stefano Maestri**

> Chiudiamo con l'ultima domanda: cosa vi Ã¨ piaciuto di queste 32 puntate?

**Stefano Maestri**

> Io sono affezionato al "momento Mastrotta", quando Paolo ricorda a tutti di mettere stelline e campanelline. Fatelo, se siete arrivati fin qui!

**Paolo Antinori**

> Il mio momento preferito Ã¨ stato quando abbiamo parcheggiato la scaletta per chiederci: "Ma voi per cosa la usate l'IA?". Ãˆ venuto fuori che la usavamo tutti per capire perchÃ© ci faceva male la spalla o ci prudeva il sedere. Ãˆ stata una cosa molto spontanea che mi ha fatto ridere tantissimo. Dovrebbe essere la puntata 15 o 16.

**Alessio Soldano**

> A me piace perchÃ© mi costringe a stare al passo con le news. Ãˆ un modo per distillare conoscenza da voi due e vedere le reazioni strane di Paolo, tipo quando ha mostrato i piedi nell'episodio su Z-Image.

**Stefano Maestri**

> Concordo. Mi piace il "fuori contesto" che solo un podcast puÃ² dare rispetto a un blog o una newsletter. Mi Ã¨ piaciuto avere punti di vista diversi e gli ospiti che abbiamo iniziato a invitare. Ãˆ piÃ¹ facile fare due chiacchiere con persone che ne sanno piÃ¹ di noi in questo formato. Mi ha stupito che abbiano funzionato le interviste lunghe. All'inizio ero scettico sul replicare il modello alla Lex Fridman in Italia, ma sta funzionando bene.

**Paolo Antinori**

> SÃ¬, l'ultima con la Gompamela mi Ã¨ piaciuta particolarmente. Non mi aspettavo che questo formato avrebbe avuto cosÃ¬ tanto successo.

## Conclusioni e saluti

**Stefano Maestri**

> Abbiamo giÃ  una lunga lista di invitati per il futuro. Le interviste hanno un buon riscontro, quindi continueremo. Ricordo a tutti che le trovate su YouTube e Spotify in una playlist dedicata; sono quelle con l'immagine di colore differente. Grazie per queste 32 puntate. Continueremo a patto di avere i vostri like e commenti per motivarci! Ci vediamo sabato prossimo per la prima puntata dell'anno, dove guarderemo avanti. Auguri di buon anno a tutti e a presto!

**Alessio Soldano**

> Ciao!

**Paolo Antinori**

> Ciao a tutti!