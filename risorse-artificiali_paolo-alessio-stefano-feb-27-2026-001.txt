Stefano Maestri (00:11)
Buongiorno a voi due, buongiorno agli ascoltatori, buongiorno agli ascoltatrici. Se hai uscito dal corpo di Antonello, perfetto. Hai mantenuto solo i capelli più o meno di Antonello, che sei l'unico dei tre che ne ha seriamente, io sono quello che ne ha di meno. Ebbene, no, devo dire che raramente ci riascolto ultimamente. Mi sono riascoltato un pezzo stamattina perché...

Alessio Soldano (00:12)
Ciao!

sono uscito dal corpo di Antonello

Ecco se...

ancora per poco.

Stefano Maestri (00:41)
mio figlio di 6 anni per farmi piacere mi ha detto che voleva sentire in macchina non è vero niente probabilmente ma voleva farmi piacere quindi lo ringraziamo è stata divertente la puntata, non l'avesse sentita può andare non perché non c'era Alessio ma in generale Paolo è stato abbastanza cazzone io anche e quindi avanti così no allora siamo partiti di nuovo

Alessio Soldano (01:06)
Ma fammi capire se

è stato un'ora e 17, non un'ora 10 in macchina da soltarlo?

Stefano Maestri (01:10)
No, ho sentito i primi minuti,

no ho sentito i primi minuti e mi hanno fatto sorridere, basta. No, no, solo i primi minuti.

Alessio Soldano (01:15)
o l'hai ascoltata a 7 per.

Paolo Antinori (01:17)
ma soprattutto hai

schiacciato le campanelline, le stelline, quelle cose lì

Stefano Maestri (01:23)
No,

io le ho già schiacciate le campanelline e le stelline. Invitiamo gli altri ascoltatori. Perché intanto, guardando i dati, abbiamo un sacco di ascoltatori extra a campanelline e stelline che chiameremo gli ascoltatori occasionali, così come i rapporti occasionali. Però...

Però è sempre per restare sullo stesso livello, tanto non ci ascoltano i bambini a parte mio figlio. No, però mettete le stesse linee, stessi campanelline, ci date una mano se siete lì che ascoltate, perché lo vedo che il numero di ore non sono compatibili. Non mi vedo il nostro ascoltatore normale che ci ascolta 2, 3, 4, 5 volte. Sarebbe strano. È vero che forse sono strani chi ci ascolta, però.

Vabbè, questa era una marchetta venuta quasi simpatica però, bravi. Non l'abbiamo preparata, siamo solo così scemi.

Allora no, un sacco di cose, ma parliamo prima di tutto dei disagi di Paolo.

Paolo Antinori (02:36)
Infame, volevo io rompere il tuo flusso invece

tu l'hai rotto a me. Sì, Paolo ha qualche disagio. Ammetto di forse avere un problema e per fare riferimento a fare anche qualcosa di intelligente ovvero fare riferimento a un popolare articolo che è stato ripostato queste ultime settimane che parlava da intitolato AI Vampire, i vampiri dell'AI, che era

Alessio Soldano (02:42)
era già rotto di partenza.

Paolo Antinori (03:05)
a sua volta un riferimento a What We Do In The Shadows per quelli che l'hanno visto e Colin Robson il vampiro dell'energia che è un concetto meraviglioso dovresti guardare la prima puntata solo per quella cosa fa riderissimo l'idea è che questa AI ci sta rubando un po' le energie insomma ci sta rubando un po' l'attenzione, il focus e tutte queste cose qua

È strano perché leggevo di queste cose negli articoli che parlavano di San Francisco in particolare con la visione un po' particolarmente negativa in cui si diceva che le startup più spinte quelle che già prima lavoravano un sacco di ore adesso gli si vuole fare lavorare ancora di più perché gli si dice avete tutti questi agenti che fanno cose per voi l'aspettativa è altissima e quindi nel contesti più aggressivi diciamo il

è decisamente stressante tossico a me viene in mente un pochettino wall for wall street con di caprio, quello stile lì, non faccio fatica immaginarlo però ho detto vabbè ok cioè problema della Silicon Valley, problema di San Francisco, sti cazzi e insomma diciamo che quando ho iniziato a rendermi conto delle potenzialità applicabili

Stefano Maestri (04:06)
Sì.

Paolo Antinori (04:27)
alla mia quotidianità di queste tecnologie ovvero tras... riassunti una frase letteralmente trasformare qualunque idea in una realizzazione da lì a breve questo è quello che è per qualcuno che sa... ha delle aspettative sa vagamente quello che sta facendo il tempo quasi sì

Stefano Maestri (04:44)
quasi qualunque, quasi qualunque

perché l'audio di Linux non puoi risolverlo comunque neanche con l'AI, quello non ci si riesce. Le virtualizzazioni leggere lo so perché ho buttato via

per cui quasi ogni problema, ⁓

Paolo Antinori (05:08)
Ok, grazie per la correzione, sta tutta. Però, insomma, no, il potenziale è di dire come se avessi tre desideri da esprimere per un programmatore, in realtà non è ai tre, è ai tre miliardi e puoi farne quanti ne vuoi. Qual è la risorsa che poi va a mancare a questo punto? Banalmente il tempo, senso che...

Tu puoi fare tutte queste cose che prima rimandavi ad un weekend lungo, a quando la famiglia andava in vacanza e tu potevi concentrarti con calma e invece adesso tecnicamente puoi farla in qualunque momento durante una call di lavoro noiosa o cos'è... Stavo costruendo, non rompere la mia narrativa. Puoi fare in qualunque momento, cosa ti serve? serve... Beh, probabilmente ti serve un abbonamento senza limiti di token perché altrimenti a un certo punto il provider ti dice...

Stefano Maestri (05:43)
fai dal letto con telegram tanto per dire

Paolo Antinori (06:02)
ma hai speso tutti, sì, ma basta. E quello però, problema l'avevamo più o meno risolto grazie al fatto che Stefano lo pagano per vendere account di ZAI e quindi l'ha fatto comprare a me ad Alessio, io l'ho fatto comprare un'altra persona, quindi questo Ponzi scheme sta funzionando. Ok, io gli ho dato l'abbonamento annuale Max Ultra Giga, quello in 4K.

Alessio Soldano (06:02)
Si va bene basta

Stefano Maestri (06:18)
che minimax.

Alessio Soldano (06:21)
Io gli ho dato pochi pochi soldi, cioè 10 euro ogni 3 mesi.

Stefano Maestri (06:28)
Thank you.

Paolo Antinori (06:31)
che comunque ha un prezzo contenuto, 250 euro totali, qualcosa del genere insomma, che è accettabile, e si sta ripagando tutto, cioè io sto abusando di questa cosa quasi costantemente perché fa delle cose. Poi come dicono, giusto per non dare false aspettative, ogni tanto è giù il servizio di ZAI, e loro stessi dicono

Stefano Maestri (06:34)
e sono 15 euro al mese alla fine, fatti i conti più o meno.

Paolo Antinori (07:00)
Noi vi diamo il servizio, costa poco, però gli SLA sono quelli che sono, quindi portate pazienza se ogni tanto siamo offline. Ed è ragionevole. È ragionevole in termini di uno che offre il servizio e uno che lo paga poco. Diventa difficile ragionarci sopra quando sei nel bel mezzo di un ragionamento, di qualcosa che stavi facendo e finalmente hai arrivato al punto e BOOM, non ti risponde più l'AI remota e tu dici mio Dio, comittata la transazione, le informazioni ci sono oppure no?

e lì è un po' di sudori freddi, è di panico, che portano a un eventuale fork. O aspetti, oppure fai quello che ha fatto Stefano nel cuore della notte l'altro giorno. Cosa hai fatto?

Stefano Maestri (07:39)
Sì. ho fatto? io non dico i miei peccati, però. No, scherzo. Allora, no, GLM siamo onesti, io l'ho sponsorizzato e continuo a sponsorizzare perché secondo me come modello è nottivale. Dopo ci arrivo questo, oggettivamente sì, ogni tanto è giù e non è velocissimo, ma la risposta.

io che prendo in giro Paolo ma che ultimamente lavoro con quattro finestre aperte tutte su Claude per fare due cose per volta per progetto ne ho disolto due progetti due cose per volta questa lentezza mi dava fastidio e allora sono andato a farmi l'abbonamento di Minimax Minimax ⁓ 2.5 di cui si dice un gran bene

come modello eccetera, ma poi su quello arrivo perché secondo me il GLM è meglio ma che ha un abbonamento ha un abbonamento normale e poi ha l'abbonamento super fast in cui invece loro hanno un SLA di 100 token per secondo quando l'ho visto non ho potuto resistere 100 token per secondo mi sembrava la cosa dei miei sogni più o meno

Paolo Antinori (08:55)
la

fibra ottica dei modelli.

Stefano Maestri (08:58)
la

fibrotica degli LLM e l'ho preso ed è bellissimo, cioè ad una velocità meravigliosa. Secondo me i risultati in senso stretto dal punto di vista del coding ovviamente sono meglio quelli di Claude Opus che dà una mezza pista a tutti. GLM si avvicina di più ad Opus secondo me di quanto

non lo faccio a minimax è comunque un buon modello che paragonerei però ad un sonnet 4.5 però veloce in un modo incredibile per fare cose minime, minime anche di buon livello va bene e dà una velocità pazzesca e qua viene il punto perché tu dici giustamente no l'elemento tossico del di silicon valley

ma il fatto è che per come sono fatti i coding agent, quelli da riga di comando soprattutto, ne parlavamo con Antonello l'ultima

di come la nostra generazione abbia portato la gamification all'interno dell'industria. Queste hanno portato la gamification all'interno del coding perché c'è proprio il meccanismo di reward. Tu descrivi una cosa e la vedi succedere, magari non sempre esattamente quindi hai voglia di fare l'improvement e sei sempre lì a ciclari su questa cosa perché sai che arriverà mentre paradossalmente quando scrivi codice di tu

ma adesso per gli ascoltatori magari che non scrivono codice magari pm o anche non tecnici, quando scrivi una mail ti devi mettere lì pensare o un documento, mettere lì pensare e quindi il tipo di reward, il tipo di soddisfazione che hai è man mano che la mail si costruisce, è un processo più lento.

Qui la reward è scriverne tante di mail per fare il paragone con la mail e quindi sei sempre lì che cicli e diventa davvero difficile staccarsi anche senza avere la pressione della Silicon Valley nei side project che faccio la sera, che è poi quello che diceva anche Paolo.

Paolo Antinori (11:22)
Sì, sì, esatto. Ci sarebbe da decidere se vuoi citare o spoilerare il riferimento che arriva sempre dall'articolo di AI Vampires su come questo modello sembra che si avvicini a quello del gioco d'Azzardo.

Stefano Maestri (11:41)
Sì, Ne parlavo in pre-intervista con una persona che intervisterò a breve, che me l'ha citato, me l'ha ricordato lui, quindi...

di solito non spoiler le interviste ma ormai siamo qua, intervisteremo breve Gabriele Venturi

Paolo Antinori (12:02)
Io l'ho presa

larga, tu potevi uscire da questa trappola, invece ci sei cascato dentro.

Stefano Maestri (12:06)
No,

tu mi fai... tendi le trappole, io sono bravo a cadere nelle trappole, lo sai, quindi l'hai fatto apposta. Perché dovete sapere che Paolo non è d'accordo con me sul fatto che non spoiler le interviste. Allora, in tutti i modi sta cercando di convincermi del contrario, compreso l'inganno. Però io sono facile ad ingannare, quindi... No, comunque mi ricordava questa cosa per tornare... magari nessuno...

immagino che il nostro ascoltatore medio sappia chi è Gabriele Venturi ma se non lo sapete ascoltate l'intervista che arriverà non so dirvi quando ma arriverà

Alessio Soldano (12:40)
presto lo scoprirete

Paolo Antinori (12:46)
Sono un whistleblower.

Whistlebrother.

Stefano Maestri (12:49)
No, mi

ricordava proprio questa cosa qua di cui poi abbiamo parlato in settimana, questo... C'è proprio un peppar di ricerca su questa cosa, su quanto assomiglia al gioco d'Azzardo, in particolare lo slot machine. Perché...

Ci sono due meccanismi in questa cosa. Il primo è quello del schiaccio in via per andare avanti che è tipico proprio no? Dello slot machine quando schiacci i bottoni per continuare. Quindi ti tiene collegato a questa cosa. E la seconda cosa è proprio l'indeterminismo intrinseco dell'AI per cui tu hai un risultato

che però a volte ti soddisfa, a volte no e hai sempre la volontà anche quando ti soddisfa ma non pienamente di migliorarlo che è un po' come vinco un po' di monetine e le rigioco perché spero di vincere di più il meccanismo con cui viene fatto il paragone è questo poi io non so se sono stati costruiti

per questo motivo sia un effetto collaterale, io voglio pensare che sia un effetto collaterale.

Alessio Soldano (14:00)
sicuramente.

Paolo Antinori (14:02)
La teoria vorrebbe che è un effetto collaterale perché se tu fossi bravo ad usare lo strumento vinceresti sempre. In realtà quando stai facendo vibe coding puro su progetti come il mio in cui non padroneggio tecnologia target, metà dei miei prompt sono mi sento fortunato.

Stefano Maestri (14:09)
Sì.

Alessio Soldano (14:17)
Io non voglio essere autoreferenziale, ma vi dico che tutte queste cose sono la lampada di Aladino e voi sapete perché.

tu descrivi l'idea che hai ma volendo o non lento ti scappa qualcosa e finisce che la lampada ti tira fuori la soluzione che però ha qualche difettuccio perché tu non sei stato bravissimo a descrivere il problema e poi devi lavorarci diciamo. Esatto.

Stefano Maestri (14:46)
e poi mi desideri di assomigliorare.

Paolo Antinori (14:48)
Beh, non

l'avevo mai capito e sai, forse l'avevi anche proposto per scegliere il nome di questo podcast al suo tempo ma non l'avevo colto, mi scuso.

Stefano Maestri (14:57)
E... no, però questa è una notizia che non so se Paolo ha già letto ma che... vai, dimmi. Finisci, scusa.

Paolo Antinori (15:08)
Volevo finire le scursus della scimmia

e della tossicità di questa cosa perché si aggancia comunque delle news che vale la pena citare. Stefano diceva che lui ha deciso di andare in direzione velocità, non aveva tempo di aspettare. Io in realtà il tempo di aspettare ce l'ho nel senso che mi aiuta che ogni tanto vada lento così posso smettermi di concentrare su quella singola attività, staccare la testa dallo schermo e...

anziché vivere la mia vita, fare un'altra attività sullo schermo. Mi aiuta a mi forza il multitasking, l'attesa praticamente, che è una proprietà più che un bug per quello che serve a me.

Qual è lo svantaggio di questa cosa però? Che alcuni dei task che lancio di programmazione in particolare su questo progetto in cui di tanto in tanto devo lanciare dei benchmark per scoprire se troverà mai una soluzione al mio problema oppure no per la natura stessa di questi problemi e netp complessi per cui non c'è un algoritmo noto in un tempo finito quindi devo lanciarlo e vedere come va e in particolare vedere se la soluzione migliora o se a un certo punto si incastra e non va più avanti di così e sono job lenti. Molte volte passavo

del tempo lì a fare a guardare un po come quando avevamo il 56k e scaricavamo gli mp3 sì sì sì e quando avevamo 56k passavamo il tempo a guardare la barra di completamento che ti diceva ci manca 30 secondi 50 mila anni 30 secondi quelle cose classiche di windows e niente ed era tempo un po' perso e quindi ho

Alessio Soldano (16:21)
ma perché sono delle heuristiche,

Paolo Antinori (16:40)
cercato di capire cosa potevo fare per migliorare questa faccenda. Una delle prime ottimizzazioni, ma non è quella di cui andrò a parlare adesso, è quella di rimuovere l'umano dal loop quanto più possibile. Quindi anziché di dover schiacciare con i yes per dire vai avanti, posso leggere questo file, posso provare questo, ho cercato di fornire al mio agente di coding locale dei sottostrumenti che lui poteva utilizzare che erano già permessi da me, quindi non doveva chiedere il mio permesso. E quello ok, è stato

utile quindi non ero più io il collo di bottiglia. Il collo di bottiglia però è l'attività stessa quindi questi servizi lenti. Cosa ho potuto fare con questa direzione? Qui arrivano le storie di Stefano e del suo modello openclaw che gira e sta prendendo una laurea su internet o qualcosa del genere. La cosa di cui ero più invidioso era l'integrazione con Telegram, WhatsApp, non lo so, al punto che mi chiedevo ma

ne vale la pena installare il demonio sul computer per fare questa cosa oppure no? e poi ho pensato ma no dai probabilmente posso semplicemente rubare la funzionalità vado da Gemini o da qualche modello e dico senti devo riempimentare la possibilità di controllare il mio cloud da remoto però visto che siamo nel 2026 sono mica l'unico ad aver avuto questa idea ho guardato

di tab pieno di progetti che fanno questa cosa. me ne ha suggeriti 2 3, uno di questi 3 sembrava quello minimale che faceva poche cose, l'ho guardato e...

Ho detto bene lo installo poi mi sono fermato un istante detto forse non è una buona idea Comunque laddove non mi fido di openclaw fidarmi di un altro random progetto su internet quindi che cosa ho fatto ho chiesto al modello stesso a clod stesso senti Stavo per installare starobba ma forse meglio che prima mi guardi se non fa delle cose losche quindi ho chiesto a clod di dirmi se quel progetto era fidato lui ha fatto una piccola analisi e mi ha detto di sì

Siccome non gli voglio credere gli ho chiesto di farne una più approfondita, quindi ho fatto un deep research. Lui l'ha fatto per bene, ha guardato, mi ha detto sì c'è qualche libreria vecchia, ma normale, niente di strano e soprattutto lo sviluppatore ha una presenza online, quindi in teoria è una persona vera. It's not a robot or a troll, poi fino a un certo punto. Ora, questa non è una garanzia che non ci siano problemi col progetto che ho scelto. Ad ogni modo ho fatto le mie verifiche pigre, diciamo, per verificare che il progetto funzionasse.

Alessio Soldano (19:03)
due diligence.

Paolo Antinori (19:05)
A questo punto l'ho preso, l'ho lanciato e non sono riuscito a farlo andare. Perché non sono riuscito a farlo andare? Perché lui assumeva che io usassi Cloud Code quando io in realtà nel mio setup non uso Cloud Code ma uso un clone di Cloud Code che mi tiene separata la configurazione. E quindi non andava. Che palle! E quindi che cosa fai? Quello che si fa di questi tempi. Chiedi a Cloud Code, senti Cloud Code mi fixi questa cosa? Perché io non uso Cloud Code, uso una variante. Fa certo non c'è problema.

me l'ha fixato e funzionava. detto wow! A questo punto ho detto cosa faccio me lo tengo per me? No, non tenermelo per me. ClockCode per favore crea un task sul progetto originale da cui arrivo dicendogli che non funziona in questi setup.

Lui me l'ha creato, io ho rivisto la definizione dell'issue perché volevo evitare di sbattere in faccia un eventuale AI slope allo sviluppatore di questo progetto che mi è stato utile, quindi il minimo che potevo fare era verificare a mano di non dirgli cazzate e infatti ColoCode non aveva fatto un lavoro perfettissimo a spiegare il contesto, quindi ho corretto quello, però gli ho aperto l'issue. Dopo che gli ho aperto l'issue, gli ho aperto la PR.

gli ho aperto, ha fatto tutto Claude. Io sapevo che cosa volevo, lui ha fatto la fatica. Però pensateci, sono passato da una funzionalità che volevo, l'ho trovata, non funzionava. Il codice, la gente me l'ha fissata e ha fatto anche la parte di contribuirla indietro. La piare è stata emergiata peraltro, anche relativamente in fretta, ma io avrei vissuto anche se non succedeva mai con il mio fork. E niente, e quindi io adesso ho la possibilità di controllare Claude tramite Telegram.

Sono contentissimo innanzitutto perché mi permette di poter mandare avanti le cose lente. Ogni tanto guardo, funziona molto meglio di quanto avrei mai potuto immaginare, la UX. Pensavo che sarebbe stato impossibile, invece funziona. Ovviamente funziona meglio per alcune cose, tipo il mio progetto ha una parte di interfaccia web. Quella parte, ora come ora non la sto controllando. Non che non potrei, ma non sto esponendo il web

essere accessibile da remoto quindi in realtà non lo sto vedendo quindi funziona meglio per il back-end se volete ma di per sé posso farlo e quindi io adesso mentre aspetto mia figlia che esce a scuola o vado al bar oltre che guardare a me e fare altre cose guardo la chat di telegram vedo che c'è il bot che ha finito questa roba e gli dico senti questo fai quest'altro e se alcune di queste attività pensate che richiedono un'interazione attiva è vero alcune non tutte le attività di sviluppo con quello che puoi fare al telefono perché devi dargli un feedback devi leggere attentamente ma molte

Alcuni

altri si ricerca verifica stessa della tua coda delle attività per quale ho iniziato ad usare backlog stamantina ad esempio gli ho fatto back grooming di tutte le mie attività una roba che di solito odio fare l'ho fatta tranquillamente dal telefono mentre ero a Etto gli detto senti prova a controllare se abbiamo delle cose che sono marcate come da fare ma in realtà le abbiamo già fatte ci siamo dimenticati e lui mi ha fatto tutte queste cose ha effettivamente risparmiato ore di stare davanti al laptop in maniera tradizionale

fare tutte queste attività. Io sono contentissimo di questa cosa, sto spamando tutti i miei amici dicendo guardate che si può fare questa roba è facile, potrebbe essere l'inizio di un problema ancora più consistente di addiction, ma la comodità è assolutamente lì. E perché vi faccio tutto sto pippone? Perché questa settimana Anthropic ha ufficialmente rilasciato la stessa funzionalità.

Stefano Maestri (22:37)
non vio web però... però vio

web non vio... vio chat

Paolo Antinori (22:46)
Scusate, il sistema ha rilasciato la stessa funzionità, ha rilasciato la stessa UX, l'app mobile per fare sessioni long run in session di Cloud Code.

versione fatta in telegramma è più casereccia open source se volete la versione è loro più servizio che paghi però diciamo che hanno validato la UX probabilmente in merito di questo va a Pete di OpenClaw che è il primo che ci fatto vedere che poteva essere una buona idea

Stefano Maestri (23:07)
si no?

no no però allora l'ho guardata è un po' diverso il concetto nel senso che a me piace di più la versione tua open-claw style, cioè che si interfacci con il tuo cloud code eccetera, quella che hanno rilasciato in Anthropic è molto simile a quello che fa codex di OpenAI

quindi è un'istanza web di Cloud Code che si clona il tuo repo e vive su...

su un AVS su un Cloud da qualche parte ma non è quella del tuo computer che sia VPS che sia il computer vero mentre invece quello che fai tu è quella cosa lì e perché a me piace di più? perché volendo poi dopo lì è dove metti il taglio della tua sicurezza gli dai accesso a tante cose sul tuo computer

i tuoi file eccetera eccetera infatti non escludo di provare a mettere la stessa cosa che hai tu e cloud code sul vps che ho spegnendo openclaw un attimo però Antropic ha riconosciuto la validità dell'idea di openclaw decisamente perché ha aggiunto l'altra funzionalità ed era la notizia che non so se hai ancora letto perché è di stanotte

e credo che potrebbe farti molto piacere sapere che esiste, hanno aggiunto la memoria di lungo termine su Claude Code, che è esattamente l'altra cosa che ha OpenClaw. Sono fatti delle belle pippe nel senso che hanno fatto una cosa seria e devoluta, hanno messo insieme il concetto di Claude MD, rendendolo però Claude MD è diciamo

ridmi per gli agenti del progetto. L'hanno fatto diventare gerarchico per cui tu puoi avere un CloudMD per ogni componente del tuo progetto per cui ad esempio se hai una parte di interfaccia web e una parte di back-end puoi avere dei CloudMD diversi o che completano il CloudMD di base nello stile di programmazione, nel tipo di linguaggio che usi eccetera eccetera. Hanno giunto

tutta una serie di rules, come le chiamano loro, che assomigliano moltissimo quelle che erano le rules di Cursor e in più hanno giunto il MemoryMD dove Claude, esattamente come fa OpenClaw, durante la sessione capisce quali sono le cose rilevanti e se le sintetizza lui nel MemoryMD.

Paolo Antinori (26:07)
Non ti voglio sputtanare, ma io sto usando da tre giorni sta roba, almeno. Non so che dirti perché MemoryMD lo sto letteralmente usando da un po' Rules...

Stefano Maestri (26:13)
L'annuncio su X di Antropica è stanotte, dodici ore fa.

No,

no, memorymd c'era già ma lo dovevi editare tu o gli dovevi dire di memorizzare con slash memory. Adesso c'è l'automemory che vuol dire che lui durante la sessione si accorge di che cosa stai facendo e si sintetizza le cose fondamentali da mettersi nel memorymd. è quello che hanno annunciato stanotte l'automemory. Le rules, no hai ragione, rules e memorymd è una settimana, dieci giorni che le...

Paolo Antinori (26:25)
Ok.

Ok, perché...

Infatti le

rules le sto usando da questa settimana e mi chiedevo, ma ci sono sempre state e non me le ero sempre perse perché sono comode.

Stefano Maestri (26:56)
No, no, è dalla

2.158, è dalla 2.159 che è quella di stanotte, c'è l'automemory.

Paolo Antinori (27:03)
Ok.

In compenso problema concreto, tutta questa memoria il contesto te lo mangia. Giusto ieri stavo guardando che io quando iniziano un'attività mi brucio un 25 % di contesto tutte le volte e ho detto perché? Quindi sono andato... ehm... sì, in teoria sì, però ho lanciato Context per vedere che cosa c'era dentro e ti fa lo spaccato. E il mio spaccato, adesso vabbe' una curiosità, lo citiamo in podcast, magari qualcun altro ci va dentro a guardare e scopre.

Stefano Maestri (27:15)
Quelle sono gli MCP anche.

Paolo Antinori (27:32)
era... ne sprecava la maggior parte che sprecavo di contesto non erano gli MCP Tools, con mia sorpresa ma erano la collezione di Markdown Files che io ho creato in particolare quelli sotto la cartella slash Claude Docs l'equivalente delle memorie a lungo termine dei poveri prima che Anthropic ci desse questo nuovo meccanismo che ho scoperto questa settimana a quanto pare sono sempre lì e io alcune di quelle

Stefano Maestri (27:37)
mmm

Sì.

Lui se

li legge, i clododox lui se li rilegge tutte le volte mentre il memory no, il memory l'hanno impostato in maniera simile alle skill, hanno un descriptor della memoria e si legge solo quello che serve quando serve

Paolo Antinori (27:59)
è solo che è un'impedimentazione

C'è un indice praticamente,

Sì, sì, è...

Alessio Soldano (28:17)
C'è tipo che

quando arriva in una situazione in cui si chiede cosa fare dice vediamo un po' qual è la linea guida del progetto.

Stefano Maestri (28:20)
sì, corretto se ho qualcosa, se l'ho già

fatta questa cosa in buona sostanza perché tipo si ricorda sessioni di debug, cosa di questo genere, ti tiene l'automemory quindi se trova bug simili o behavior simili cerca di...

di non rinventarsi la ruota ma di capire cosa fatto e che cosa ha funzionato. Sì, cos'è che aveva funzionato? l'esperienza di chi lo usa è che fate... magari gli chiedete di fissare una cosa, lui fa un tentativo, non va a buon fine, fa una cosa, alla fine ci riesce. Invece di fare questi tre tentativi sa già che il tentativo buono è fatto in quel modo ed è il primo che prova quantomeno. Poi se non va in quella situazione ricomincia a tentare, ma...

Alessio Soldano (28:48)
va a vedere alla fine tutto il ragionamento come ne è riuscito.

Stefano Maestri (29:18)
e quindi quella lì è un'altra funzionalità tipica di openclaw quello che manca ma che è facile da implementare è di svegliarlo di svegliarlo ogni tot da solo con un elenco di cose da fare tutto sommato con backlog già più o meno lo potresti cioè tu metti un cron ogni dieci minuti e nel prompt gli dei ci fai i prossimi due tasche che hai di backlog lui lo fa

e hai ottenuto più o meno OpenClo. Poi dopo un altro discorso sono le estensioni OpenClo, tutte le skills che ti puoi scaricare perché in realtà dove c'è la parte di pericolo, di sicurezza soprattutto è nell'installarla qualunque. E OpenClo per scelta, loro hanno fatto questa scelta, ha una grande facilità di estenderlo per le skill, ha proprio un repository che si chiama Cloab.

di skill, di cose che puoi installare e lo puoi fare direttamente lui se glielo chiedi di auto installarsi le cose e questa è la parte di pericolo però i componenti fondamentali che erano quei tre lì l'interfaccia diciamo remota in qualche modo la memoria e lo svegliarsi ogni tanto 2 su 3 li hanno riconosciuti come lo che lo facciamo anche noi

che è in qualche modo una validazione che l'idea di base non era una minchiata.

Paolo Antinori (30:53)
Come vi annunciavo privatamente nella mia to-do list, Nxt c'è da supportare i messaggi vocali perché ogni tanto mi accorgo che mi perdo un po' a scrivere, mi farebbe comodo lanciarli una nota breve a voce. Questa cosa il mio setup non ce l'ha, probabilmente farò girare un modello locale tipo whisper o parakit per convertire.

e lo farò e questo mi ha ricordato peraltro che uno dei tanti problemi personali che adesso il micro software ci permette di risolvere è che odiando i messaggi vocali di whatsapp mi ha sempre dato noia che li devo ascoltare non posso leggerli e adesso lavorerò a scrivermi un convertitore di messaggi vocali in testuali completamente privato deployato probabilmente proverò a usare i modelli gemma di android per farlo girare come app custom android era la cosa a cui stavo lavorando stamattina al bar

Alessio Soldano (31:43)
Avvisami quando lo fai.

Stefano Maestri (31:47)
Sì, no, è molto comodo effettivamente.

Alessio Soldano (31:53)
Adesso io però non

vorrei dire, abbiamo un elenco di rilasci di modelli nuovi che sono usciti in queste settimane che per quanto faccia un polis ad alla spesa inizia ad essere imbarazzante da ignorare. Potremmo magari fare un excursus.

Stefano Maestri (32:01)
Sì.

Sì, sì,

io intanto ricordo a chi preferisce leggere, che io quell'elenco lì lo faccio in newsletter tutte le settimane se volete, però hai ragione e partiamo dalla fine allora, visto che tu ci punzecchi e tu ti pigli la pagliuzza più corta. È uscito Nano Banana 2.

Alessio Soldano (32:36)
Ecco, Citellano Banana 2 proprio a brevissimo. Io ho fatto qualche prova e...

per il momento posso solo dirvi che le immagini che genero sono molto belle.

Paolo Antinori (32:51)
funziona la prima,

funziona adesso, commento di quando è riuscito Gemini 3

Alessio Soldano (32:56)
Sì esatto, due commenti così, uno di impressione molto personale, ho provato a generare qualche immagine di soggetti umani e la primissima sensazione così a pelle è ma questo è un nano banana 2 o una versione nuova di grock? Però vediamo, non so chi ha usato grock magari capisce cosa intendo.

Stefano Maestri (33:25)
io non ho capito, spiegamerò.

Paolo Antinori (33:27)
ce l'abbiamo nella macchina

noi

Alessio Soldano (33:29)
Ma nella macchina non genere le immagini comunque No vabbè ma a parte quello

Era tanto che non uscivano aggiornamenti sulla generazione di immagini da parte di Google, da quando è uscito il Nano Banana Pro. Ci erano stati ultimamente dei alti rilasci di modelli Openweight, quindi bene. Si inserisce all'interno del rilascio più grosso di Gemini 3.1 Pro.

Ribadisco molto fresco non l'ho ancora guardato bene Però in realtà quello di cui volevo parlare io Stefano era anche di tutti gli altri Di glm 5 di quen 3.5 di sonnet 4.6 gpt 5.3 codex sparks minimax 2.5 la citato prima tutto questo per dire che

Stefano Maestri (34:20)
Sì,

Alessio Soldano (34:39)
Intanto si nota una velocità, cioè è aumentato il ritmo dei rilasci se vuoi.

tra l'ultimo state of the art di ognuno dei vendor principali e quello successivo, la sensazione che i tempi tra un rilascio e l'altro si siano accorciati, non so se anche tu hai questa sensazione.

Stefano Maestri (35:05)
Sì, l'esponenziale

rimane, sì,

Alessio Soldano (35:09)
e poi...

C'è tutto un discorso di benchmarking, ci ragionavo giusto l'altra sera, inizia a diventare anche difficile capire come spiegare all'utente ok questo modello che è uscito è meglio di quello che c'era prima.

Per i modelli open weight ho visto che la tendenza è quella di dire ok questo modello rispetto allo state of the art dei modelli closed source si posiziona più o meno qua come dire siamo quasi per dire al livello di opus 4.5 piuttosto che opus 4.6 invece sugli altri il problema è che

I benchmark non sempre sono significativi, ma non ti danno davvero l'idea di quanto sia migliorato un modello rispetto ai precedenti.

Paolo Antinori (36:13)
Scusami

Alessio, era un po' quello che ci chiedevamo tra di noi in queste settimane quando era arrivato l'annuncio di Gemini 3.1 che citiamo lui perché è più facile che le persone l'abbiano incrociato essendo di Google e ci chiedevamo ma che cosa fa di diverso e Stefano ci spiegava e per quanto sia, adesso glielo faccio ripetere, ma per quanto sia interessante il dubbio era sempre boh ok, cioè...

quanto mi impatta direttamente come persona. Stefano scudai ricordaci cosa fa 3.1 rispetto a 3 che era già ottimissimo

Stefano Maestri (36:44)
e là

Allora 3 era già pazzesco e sui benchmark è migliorato tantissimo, cioè 3.1 ne cito uno perché quello che mi ricordo, Archegi 2 che è un benchmark relativamente nuovo Archegi 2 e che dovrebbe testare la capacità EGI del modello, cioè la capacità di essere meglio della media dell'uomo

Alessio Soldano (37:00)
è un benchmark relativamente nuovo tra l'altro

Stefano Maestri (37:15)
gli uomini sulle varie attività.

3.0 era stato salutato come incredibile perché faceva il 48 % o 46 % rispetto ad un chat GPT che faceva 37 % per intenderci no ecco 3.1 fa 86 % che è quasi il doppio tanto tanto che tanto che hanno dovuto fare Archegy 3.0 perché così non ha più senso è a tappo

Paolo Antinori (37:43)
prima non era promosso, adesso è promosso

Stefano Maestri (37:53)
ed è uscito Archegy I3 e se vuoi sulla velocità dei modelli che dicevamo prima con Alessio è incredibile anche, sono andato a vedere questo dato qua per preparare la puntata, la velocità di rilascio dei benchmark anche, cioè non ci stanno dietro con i benchmark, anche la velocità di rilascio dei benchmark è accelerata per forza perché li mandano tappo

Alessio Soldano (38:13)
Sì, perché...

che comunque devi pensare a dei test che siano sufficientemente challenging ma non tra virgolette fuori dal mondo perché deve essere come dire progressiva la capacità di di passare, di migliorare eccetera non riesco a fare tutto

Stefano Maestri (38:43)
E gli altri dati impressionanti, quelli li vediamo anche su Opus 4.6 e su Kimi K25, che è uno degli altri da citare come rilasci, è la capacità di andare multiagente con il sub agent nativo e fare compiti estremamente lunghi.

Cioè, Codex è arrivato a 28 ore di compito svolto correttamente, ti do il prompt, diciamo il contesto, fai questa cosa e 28 ore dopo è arrivato con il risultato corretto, senza altra interazione umana.

Alessio Soldano (39:19)
Sì.

Stefano Maestri (39:31)
Questo qui è l'altro dato a cui si fa molta attenzione in questo momento, la capacità di svolgere compiti lunghi e complessi e magari di parallelizzare. Tipo, Kimi ha spinto tantissimo con il 2.5 su quella roba qua, hanno avuto un miglioramento pazzesco da quel punto di vista. E anche Minimax, anche se io non l'ho provato su Minimax.

Alessio Soldano (39:51)
e tu e...

I light motive che ho visto in questo giro di rilasci sono 1 la tendenza ad allinearsi su un nuovo standard di un milione di token come dimensione della finestra del contesto che più o meno tutti, non tutti però va beh Gemini 3.1 Pro, Quen 3.5, adesso è la nuova op

Stefano Maestri (40:22)
Opus... Opus 4-5...

Alessio Soldano (40:25)
Esatto.

Stefano Maestri (40:26)
4-6 scusa

Alessio Soldano (40:27)
È il nuovo, diciamo, nuovo target, un milione di contesto. E poi l'altra cosa è specializzazioni, reinforcement learning, training, eccetera, specifici per il coding quasi tutti. Che, vabbè, l'abbiamo già detto altre volte, ci sta perché è l'ambito all'interno del quale si stanno vedendo soprattutto i risultati, perché è, tra virgolette, facile, perché

ben verificabile eccetera però

Stefano Maestri (40:57)
ed

è quello che ha più impatto anche.

Alessio Soldano (41:00)
esatto

anche perché ti serve per sviluppare nuovi modelli e quindi di conseguenza

Stefano Maestri (41:04)
o nuovi software,

cioè quello che in questo momento ha più impatto perché essendo i modelli confinati nell'ambito virtuale passatemi il termine, nel cloud eccetera le due cose che hanno più impatto è se riesci a migliorare il workflow di lavoro di una persona ma ancora di più se riesci a scrivere codice o progetti efimeri anche

che vada in quella direzione. Infatti c'è un post di CloudFlare su Wix di questi giorni che adesso non ho sottomano ma l'ho letto che riprende una vecchia idea di Huggins Faces con un progetto che si chiama Small Agent con cui avevo...

giocato e contribuito un po tempo fa, è quello invece di generare chiamate API o MCP, di generare codice e farlo eseguire al volo ai modelli. Questa cosa ovviamente è interessante perché il codice più espressivo di una semplice API. Banalmente ci puoi mettere i fori e gli if nel codice e concatenare più cose.

però ci dice anche che i modelli stanno diventando abbastanza maturi a generare il codice, almeno piccole porzioni di codice, in maniera così affidabile che molti, anche Opus fa questa cosa, molti stanno cominciando a dire va bene l'estensione del modello oltre la reasoning è autoscriversi del codice per risolvere sottoparti del problema in maniera deterministica.

e questo potrebbe essere un ulteriore salto interessante.

Alessio Soldano (42:56)
Invece un'altra cosa che ho notato, che iniziano a vedersi anche dei tentativi per i modelli open weight chiaramente, di esplicitare e di conseguenza tendere a ridurre quanto impatti la quantizzazione sui modelli o l'utilizzo di mixtola expert, diciamo un attimo, aggressivi sul risultato finale, sulla qualità dei risultati ottenuti con l'inferenza.

e mi riferisco ad esempio a Quant 3.5 che nel suo rilascio in realtà ha rilasciato un gruppo di modelli, non solo uno, con dimensioni varie da 400 billion token fino a scendere a 27, con mixture of expert diversi che scendono a 17, a 10, a 3 miliardi di esperti e

e ha fatto i benchmark con tutte queste versioni, fatto vedere quanto perde il modello mano a mano che lo tagli e lo fai diventare più piccolino. Come di nuovo dimostrare che la frontiera è anche nel cercare di ottimizzare la riduzione delle dimensioni per poter ottenere ancora dei risultati accettabili anche con risorse più basse.

Stefano Maestri (44:20)
perché credo che gli open weight stiano scegliendo come target a tendere man mano che i computer diventano più potenti

l'inferenza locale e quindi per loro è interessante andare a ridurre le dimensioni mentre invece gli state of the art delle big tech al momento sono focalizzati e dichiaratamente a raggiungere le gi perché così fanno scopa

Alessio Soldano (44:47)
Sì sì, no matter what, esatto,

sì sì, assolutamente.

Stefano Maestri (44:54)
Lasciami fare una digressione tecnica che ha a che fare anche con questa cosa ma che magari qualche utente si potrebbe chiedere e pensare che le big tech stiano cercando soltanto di fare più soldi con questa manovra in realtà non

ci sono delle giustificazioni e qual è la manovra scusate non ho messo il soggetto vi sarete accorti che tutti vanno verso un million token ma sopra i 200k i token costano molto di più hanno un pricing fino che usi il contesto piccolo e c'è un pricing diverso se usi il contesto grande e uno dice va beh ok vuoi farmi pagare di più perché voglio fare di più sì magari una parte di verità è questa

Alessio Soldano (45:47)
costa anche molto

di più poi fare l'inferenza con i contesti pieni.

Stefano Maestri (45:53)
No, non solo costa di più fare l'inferenza con contesti pieni, ma è proprio quello volevo spiegare. Il contesto va a finire in una memoria, una cache che si chiama KVCache. Ne abbiamo parlato nella puntata domande e risposte che abbiamo fatto tanto tempo fa, se volete andare a pescare.

Qua dico soltanto in maniera intuitiva, cioè il problema è che la quantità di memoria utilizzata non scala in modo lineare alla quantità di token che mette nel contesto non è neanche esponenziale una curva un pochino piegata diciamo. Bards on! Perché il problema del sostanzialmente la Kavicash è che cosa

Paolo Antinori (46:33)
Zotta si dice.

Stefano Maestri (46:44)
fa con i contesti lunghi deve mantenere il contesto appunto delle singole parole con quelle precedenti ma siccome il collegamento delle parole correnti esplode non soltanto perché il contesto indietro più lungo ma perché il contesto dietro più ramificato e potresti avere più più collegamenti con un numero più alto di parole precedenti

perché magari hai detto che ancora e ancora ha il legame con un sacco di roba questa cosa qua fa scalare la dimensione della ram in maniera non lineare ma più che lineare rispetto alla dimensione del contesto quindi per contesti grandi il costo anche per chi fa inferenza aumenta molto e quindi te lo fanno pagare

chiuso la parentesi Tecnicama giusto per capire anche che c'è una complessità dietro diversa da quella a cui siamo abituati cioè noi siamo abituati a prendere più RAM o RAM X prenderò il doppio e sarà X per 2 in realtà non serve il doppio della RAM ma serve tre volte circa la RAM per fare il doppio del contesto.

Ok e dunque io cosa ho provato? Ecco parliamo di questi modelli nuovi che sono usciti. Io ho provato Minimax ⁓ 2.5 e GLM 5. Di GLM c'è anche il paper che è super interessante soprattutto nella parte di training

perché prendono molte delle idee che c'erano in Deep Sick 3.2 e le stendono sulla parte di training non mi c'è dentro qua se avete voglia andatevelo a leggere però perché c'è sia il paper che il loro blog diciamo più divulgativo che si capisce molto bene allora i modelli vanno distinti un po' per

in due modi, Le risposte. Una è la qualità della risposta ma c'è anche un discorso di consistenza delle risposte. Allora, Minimax? Spiegalo. Vai. Spiego io. No, beh, consistenza delle risposte che a stessa domanda ottengo una risposta che ci si avvicini molto.

Alessio Soldano (49:17)
Spieghiamo cosa si intende per consistenza, magari. No, no, spiega tu, spiega tu.

Stefano Maestri (49:31)
banalizzando molto se non la stessa, la stessa è impossibile perché c'è il determinismo ma se faccio due domande uguali con lo stesso contesto mi aspetto che le due risposte siano simili o indistinguibili nella versione ideale

Alessio Soldano (49:51)
se vuoi che non è sufficiente che il modello ti risponda giusto una volta sola, deve risponderti sempre la stessa cosa.

Stefano Maestri (49:56)
detto

in altri termini sì certo non deve rispondere sempre sbagliato se non ha una consistenza brutta mentre invece la qualità della risposta parlando di coding visto che io li ho provati per coding è che il codice generato sia di buona qualità faccia quello che gli è stato chiesto eccetera eccetera allora sulla qualità

diciamo che del caso migliore sono paragonabili e guardando i benchmark si avvicinano molto tutti e due a opus 4.5 quindi la versione precedente di opus sulla consistenza glm è molto molto meglio anche guardando dati in giro ma anche nella sensazione che ne hai nell'utilizzarlo poi c'è una

Terzo parametro è la velocità e Minimax è di una velocità spaventosa, è più veloce di Sonnet. È velocissimo a rispondere e quindi la fase di reward che ho io dalla mia slot machine è velocissima e quindi continuo a cliccare come un...

Paolo Antinori (51:12)
pensando in questi giorni stavo capendo, scoperto anzi parliamo nelle live, ho scoperto perché me l'ha detto Cloud Code ultimamente le cose le scopo da lui principalmente, che quando usi subagents in Cloud Code lui per i subagents sceglie IQ quello che è configurato come IQ per fare le attività

Stefano Maestri (51:34)
sempre

Paolo Antinori (51:34)
Non, lo so non ho verificato però lui mi ha detto questa cosa diciamo che indipendentemente se sia completamente vera oppure no era interessante ed era plausibile e mi faceva ragionare e diceva ok quindi forse allora non sono sempre così contento di Demandare i subagent perché aico ha comunque delle capacità limitate e quindi va bene quando lo si manda sul binari ma se non si esce dai binari forse non è una buona idea e allora stavo dicendo che ne parlavo con degli amici mi dicevo gli dicevo ho scoperto questa cosa forse smetterò di usare un pochettino i subagent

timorito da questa cosa.

e qualcuno di loro giustamente mi ha detto ma non puoi cambiare le carte in tavola non puoi rimappare Aiku a quello che vuoi tu e sì quello è stato il modo possibile non ci avevo pensato io e quindi adesso che tu Stefano parlavi di queste cose stavo dicendo perché non provi a giocare con questa cosa perché non rimappi il tuo Aiku a minimax e vedi se ti dà delle risposte velocissime per delle cose più diciamo che non richiedono super intelligenza e usi il tuo modellone principale per quelle altre

Stefano Maestri (52:12)
Certo.

Alessio Soldano (52:13)
Prima cosa che pensato.

Stefano Maestri (52:35)
No, questa è un'idea interessante molto ed è una delle cose che volevo...

Alessio Soldano (52:46)
Invece ho una domanda filosofica, nel senso che noi stiamo parlando di velocità, che poi avrei bisognerebbe distinguere tra velocità nel processare il prompt e velocità nel generarti la risposta. una cosa, cioè ci sono se vuoi due modi di utilizzare questi coding agent, uno è tra virulette in puro vibe coding, chiedo quando mi è arrivato il risultato passo allo step dopo eccetera, oppure sto lì

e leggo anche tutto il reasoning che il modello sta facendo nel darmi la risposta, che se vuoi ha anche un aspetto di formazione, di learning, non so come dire, e il fatto che il modello sia più veloce, che tu magari non fai neanche in tempo a leggerti tutto il suo flusso e te lo devi guardare dopo, ha una sua rilevanza per voi o cosa?

Stefano Maestri (53:39)
Dipende come lo usi, cioè nel senso che io il control o lo schiaccio raramente. Control o è per vedere tutta la parte di reasoning perché di default ormai Cloud Code ce l'ha disabilitata e compressa. Dipende. Il plan lo leggo, ma una volta che sono contento dal plan che lui faccia il tentativo, no cazzo, non sono riuscito, non passa il test, faccio quel... No!

Alessio Soldano (54:00)
fatti tuoi.

Stefano Maestri (54:07)
Cioè solo quando non c'ho niente da fare, voglio giudicare. È come guardare Twitch, non so.

Paolo Antinori (54:10)
Io vi dico la verità,

io lo leggo ed è come guardare Twitch, esattamente, ma lo leggo perché non devo schiacciare contro l'O, il mio alternativo di Cloud Code che uso lo tiene aperto in automatico, tant'è che mi è successo una cosa curiosa che ci stava nella storia precedente, sono stato bloccato dopo aver...

Scusatemi, mi sto mangiando le parole. Dopo essere riuscito ad aumentare la mia produttività mettendomi Cloud Code su Telegram, sono stato bloccato dall'ulteriore vincolo che ho colpito i limiti di messaggi di Telegram. Generavo talmente troppi messaggi col mio Cloud Code che quindi mi ha cappato Telegram stesso. Perché mi ha cappato Telegram stesso? Probabilmente perché io stavo facendo questa cosa. Su Telegram ricevevo anche tutti i reasoning.

E sono molto interessanti, soprattutto se non sai cosa stai facendo come nel caso del mio progetto. Cioè impari man mano che vai, alcune cose ovviamente sono lui che cerca un concetto, scopre che era nell'altra classe, cioè chi se ne frega. Altre volte invece lui si rispiega le cose da solo e dice allora facciamo così, cosa? Per via di questi motivi. Ed è molto interessante. Curiosità ulteriore. Ho beccato, leggendo tutti questi log di esecuzione,

che deve esserci o qualche errore oppure lui racconta male la storia perché ogni tanto non trova dei file e nella stessa frase dice il file che dovrei guardare è quest'altro che ha esattamente lo stesso nome quindi o è un rendering sbagliato di versioni del file che però lui si mostra il percorso e quindi il percorso è corretto e uguale ma lui intende due punti temporali diversi di quel file oppure c'è un bug e me ne sono accorto leggendo quello che combina

Alessio Soldano (55:53)
problema con i tool

un problema con i tool, dico.

Paolo Antinori (56:00)
problema con i tool, potrebbe essere un problema con il modello o potrebbe essere solo un problema di logging come vi dicevo, magari in realtà lì c'è un hashcode, i due hashcode sono diversi ma il nome del file invece è lo stesso. Comunque li leggo e sono interessanti, però più in generale Alessio mi hai fatto venire in mente che questo problema che tu manifestavi, ovvero, riusciamo a dare retta a tutto quanto il flusso di esecuzione?

La risposta è no, ma questo problema si manifesta forse più visivamente nei progetti di collaborazione di coding, con gli open source in particolare, in cui è aumentata così tanto la produttività per produrre nuovo codice PR che adesso il collo di bottiglia è la revisione di questo codice. I tech lead, i project lead seri che non vogliono accettare qualunque cosa non hanno letteralmente il tempo per stare a leggere tutta la roba che gli arriva.

e alcune delle robe che gli arrivano, alcuni progetti più popolari, era famoso l'esempio del tizio di KURL, è Patumiera e loro sprecano del tempo a leggere Patumiera di high slope o di concetti sbagliati, cattivi idee in generale, che adesso il primo che passa gli lancia addosso e lascia loro l'incombenza di decidere quale rumore, quale segnale.

Stefano Maestri (57:13)
Intanto che parlavamo ho verificato quella cosa che dicevi giusto per dare l'informazione completa e perché mi incuriosiva a me. Allora, pressa agent usa IQ soltanto quando vanno in explore cioè quelli read-only, sabe agent di explore, ma quando va in plan o general purpose lo eredita il modello dalla sessione madre e quindi se sei partito con Opus vuoi con Opus.

Paolo Antinori (57:43)
si è più ragionevole però appunto era comunque affascinante l'idea che ci sia questo livello di ottimizzazione dentro Cloud Code che uno volendo può andare a interferire

Stefano Maestri (57:49)
No, no, quella è affascinante.

No, ero già pronto a giocare con le variabili d'ambiente come mi avevi consigliato tu, ma la parte di explore mi interessa poco.

Paolo Antinori (57:59)
Uhum,

vero.

Stefano Maestri (58:03)
quindi usando il mio e quindi che tanto piace a Paolo

No, ecco, però la velocità è un tema ⁓ velocità è un tema tanto che quelli di GPT ci si sono messi pesanti perché il GPT 5.3 Spark va a livello di velocità di numero di token 6 volte più veloce di 5.3 normale allo stesso prezzo con meno token, quindi a prezzo più alto per token.

Alessio Soldano (58:41)
ma infatti qui la domanda se vuoi è ma fino a che punto uno può sacrificare il l'accuratezza per avere invece velocità in quale tipo di utilizzo

Stefano Maestri (58:54)
Eeeh, quella è una domanda...

Allora, nell'utilizzo generico come assistente personale secondo me assolutamente sì. Nel senso... Cioè se lo uso per spostare file, organizzare dei rettori, farmi le slide, quelle cose lì che Minimax vada come un fulmin e mi interessa di più che sia perfettamente accurato perché tanto poi le rivedo.

sul codice...

Alessio Soldano (59:23)
Perché tu sai già che il

task è sufficientemente facile per cui in ogni caso ce la farà.

Stefano Maestri (59:28)
⁓

esatto sul codice complesso boh non lo so intanto che io sto pensando di di smettere di pagare tutti i cinesi che pago e pagare soltanto un americano cioè opus e fine stavo giusto guardando quanti chiamate mi fa fare la versione 5 pair e sono a livello di minimax quasi quasi

Alessio Soldano (59:53)
proprio a livello di brainstorming.

Stefano Maestri (59:54)
20 gli

do già ad Antropiq, 40 li do a Minimax, li metto insieme sono già 60 con 40 in più mi trovo con Opus 4.6 forse che forse dal mese prossimo faccio questa scelta qua così mi avete fatto tutti i conti in tasca ma quello non posso non darglieli perché mia figlia mi ammazza se smetto di pagare il Ciat GPT

Alessio Soldano (1:00:10)
Poi dai qualcosa anche a CiaGPT.

Paolo Antinori (1:00:20)
Comunque scusami, prima stavi raccontando che per spostare file sul desktop ti va bene un modello veloce, più che uno bravissimo. Mi richiami alla storia, una delle news di questa settimana, la capa della sicurezza di... ⁓ ecco.

Stefano Maestri (1:00:33)
l'abbiamo preparata questa quindi ho riuscito

a posto

Paolo Antinori (1:00:38)
che c'è un post su Twitter, credo, c'è uno screenshot di una chat dove, non vi ricordo più come si chiama, la persona che è a capo della sicurezza in meta gli ha scappato di mano il suo open call nonostante avesse tutte le precauzioni del caso definite e gli ha iniziato a cancellare tutta la mail che trovava e lei racconta come

come in una scena di film d'azione dove corri a cercare di smantellare la bomba prima che sia per esplodere e dovuta correre davanti al computer a cercare di bloccarlo e sei la capa della sicurezza di Facebook che quindi qualcosa ci dovresti capire e le persone che lavorano insieme a te ti avrebbero dovuto dire esattamente come fare a succedere che questo non succedesse ed è successo non lo sanno

Stefano Maestri (1:01:27)
Ecco tra l'altro questo spieghiamo un secondo per gli ascoltatori anche tecnicamente che cosa è successo, poi sono andato a leggere un premesso che doveva mettere dei Garderay la più importante sulla sua mela eccetera. Ma lei pensava di essere a posto perché tra le open claw come anche crowdcode gli puoi dare una sorta di system prompt all'interno del

che è CloudMD per Cloud, di cose che deve sempre rispettare e lei le aveva detto suggerisci soltanto modifiche sulla mail non prendere mai iniziativa, non fare mai cambiamenti. Allora la cosa giusta era dargli delle PIs che non facessero cambiamenti e fossero in sola lettura.

lei si è fidata dal mio dirlo al modello e che cosa è successo tecnicamente questo anche per far capire perché tante volte abbiamo insistito anche nella puntata quando c'era Alex l'abbiamo spiegato bene

tra l'altro credo che ormai sia il nostro ospite più citato, glielo dirò questa cosa. Però lo spiegavamo dal fatto che uno dei motivi per usare Backlog o sistemi simili è che tu fai una sessione, usi tutto il contesto, chiudi, riapri o fai clear in modo da partire da sessione pulite di non arrivare mai al comprimere la sessione perché quando comprimi

potresti perdere un po' di qualità. Quello che è successo lì è esattamente quello che la sua casella di maile era così grande che quando ha cominciato a leggere i messaggi che doveva cancellare erano così tanti, perché evidentemente non faceva zero in box come policy, ne ha letti così tanti che ha riempito il contesto.

ha deciso di comprimere, l'ha riempito ancora, ha deciso di comprimere, l'ha riempito ancora, ha deciso di comprimere e nell'ultima compressione, lei dice, la terza, nella compressione si è persa l'istruzione del non prendere iniziativa e ha deciso che stava riempiendo ancora il contesto e ha ma via, invece di continuare a comprimere, perché non zappo via tutta sta roba che mi libera il contesto? E così ha fatto.

Alessio Soldano (1:03:39)
le sue informazioni sono state diluite nel resto.

Paolo Antinori (1:03:54)
Ho due aneddoti su questa cosa. La prima è ovviamente questi rischi su scala diversa ce li hai anche quando fai Cloud.

e gli sviluppatori saggi di Anthropic ci hanno donato gli hooks per intercettare prima che vengono eseguiti i comandi, i comandi stessi così tu puoi avere dei guardrails strong ovvero non con del testo che ogni tanto può perdersi proprio dei passaggi software tradizionale per cui il codice non va avanti finché non viene fatto questo ragionamento ed è molto importante a mio avviso

perché mi veniva da commentare prima si vede che quella persona in Facebook non aveva mai passato abbastanza tempo a fare vibe coding perché ci incapi inevitabilmente che tu gli decidi di non fare una cosa e lui la fa e a un certo punto li lo devi bastonare e dire adesso mi sono arrabbiato voglio verificare ogni singola cosa che provi a fare ti impedisco di fare quello che ti ho dato di non fare

Alessio Soldano (1:04:49)
che è una lampada di

aladino.

Paolo Antinori (1:04:51)
Tipo la lampada di radino, sì. Ovviamente poi già funziona questa cosa, non ci sono mai contro. È semplicemente un lavoro lungo e laborioso perché ricordi tutti i 99 casi su 100, ma ti dimentichi il centesimo e scopri che in realtà erano 500 i casi. Quindi quel problema in realtà è sempre dietro l'angolo. Però migliorano le cose ed è una cosa su cui faccio molta attenzione per il mio sviluppo e per quello del mio team quando gli spiego queste cose.

Stefano Maestri (1:04:52)
Perché non è appena?

Paolo Antinori (1:05:20)
La seconda cosa invece, che me la sono già dimenticata qual era, era che... sì, contesti, il valore dei contesti e della compressione del contesto. Ho sempre preso sotto gamba questa cosa perché ogni tanto avevo più cose da fare di quello che il contesto mi permetteva e non... avevo la sensazione che non si potesse fare di meno. Devo fare delle cose grosse e lui doveva avere informazioni tutte insieme e prendere o lasciare, quindi l'ho sempre preso come un male accettabile.

e tendenzialmente vedevo che le performance degradavano un pochettino ma era più una sensazione spannometrica quindi magari era tutto un film nella mia testa o così. Questa settimana invece l'ho verificata con mano in una maniera quasi buffa. Non so se mi è impazzito il terminale, mi ha fatto vedere delle cose che non doveva o semplicemente mi è capitato di guardarlo tra una compaction e la fine della compaction.

ma mi ha sputato fuori il system prompt che ha compattato successivo ed era terribile ma non era terribile in cui lui aveva selezionato a caso delle frasi quello potrebbe essere accettabile era proprio sbagliato c'erano ripetizioni di parole parole mangiate insieme cioè proprio come qualcuno che ha picchiato la testa e non ragiona più e questa, vederlo con i miei occhi mi ha fatto capire quanto non ci si possa fare affidamento su quella cosa lì

Stefano Maestri (1:06:39)
quando

è successa questa cosa? questa settimana perché un paio di settimane un paio di settimane fa c'era un bug su Cloud Code sulla compression che hanno fissato nel giro di qualche ora ma in quelle ore si è scatenato il mondo perché non andava più nulla in compaction

Paolo Antinori (1:06:42)
questa settimana potenzialmente, sì, potenzialmente bugging.

Ma guarda, finché

se ne parlo a livello astratto ti dico vabbè ok capisco è meglio se... Quando l'ho vista ho proprio capito che lì io umano non capivo cosa c'era scritto, cioè perché ci deve capire lui, ho proprio capito il punto, non si scherza con quello.

Stefano Maestri (1:07:08)
è

No, infatti bisognerebbe sempre cercare di lavorare a contesto pulito sulle singole issue, portarle in fondo, uscire, rientrare ed è il motivo per cui...

gli strumenti che esternalizzano questa cosa, siano PRD, spec, backlog, quello che è, perché tutto il ragionamento lo fai prima, lo consoli di lì e poi gli dici ok prendi quel pezzettino lui si legge quello che gli serve in contesto e si muove ecco prima

Tanto tempo fa ve l'avevo raccontato, mi ricordo se in podcast o in privato, avevo il mio personale flusso in cui facevo la spec e poi gli facevo creare un work in progress file in modo che lui si tenesse tracce di cosa aveva fatto. Strumenti tipo i vari già citato backlog e altri fanno esattamente quella roba lì ma è veramente fondamentale. Tanto che, lo dicevamo con Paolo, no?

scrivevamo questa cosa, sia io che te, lo usiamo anche per task non di coding, cioè per prendere appunti del prossimo che facciamo con l'aiuto di Cloud Code ma non necessariamente di coding.

Paolo Antinori (1:08:38)
Dico la verità, adesso che ce l'ho sul telefono ancora di più è un'estensione dell'Alexa Siri che non ha mai funzionato bene.

Peraltro, scusami, ho fatto una PR a Backlog MD e me l'hanno approvata, era una classe di CSS la mia PR, però era un bug effettivo che avevo beccato e quindi volevo far presente che si può contribuire ai progetti.

Stefano Maestri (1:08:58)
Gli hanno fatte due anch'io

proprio questa settimana e penso che mi ha detto che le deve guardare, però... Gli hanno fatte due anch'io perché c'erano due cosette che servivano a me personalmente ma che credo siano utili al mondo. E sì, contribuite! Sì no, però contribuite, ho un bel progetto, open, ha tante stelle, più di mille.

Alessio Soldano (1:09:16)
Sempre perché Alex è l'ospite più citato.

Paolo Antinori (1:09:26)
Cliccateci alle stelline

e campanelli al progetto degli altri.

Stefano Maestri (1:09:30)
No, ma anche il nostro, le campanelline vanno messe qua. Poi dopo ci sono le stelle... No, lo so che al prossimo altro non lo diciamo. Le gittà... I punti fragola solo se ce li regalano, perché mi piacciono gli... No, mi piacciono gli zaini. No, scherzo.

Paolo Antinori (1:09:36)
sul nostro non lo dico

Alessio Soldano (1:09:40)
le Guitab Stars.

Paolo Antinori (1:09:42)
anche punti fragola vangalo

quelli della scuola.

Alessio Soldano (1:09:54)
Vogliamo parlare dei piatti

della pizza di Carrefour, non lo so.

Stefano Maestri (1:09:58)
No, potrebbe essere. Ricordiamo che Selunga e Carrefour sono gli sponsor di questa puntata. Va bene, credo che abbiamo già fatto i Pierlo abbastanza. Possiamo, cosa dite, chiudere? Va bene, grazie a tutti e tutte di averci ascoltato. E... campanelline, quelle cose che Paolo non vuole che si dicano. Alla prossima, ciao!

Alessio Soldano (1:10:09)
Sì, sì.

